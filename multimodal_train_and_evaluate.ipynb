{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T14:34:12.683159Z",
     "start_time": "2025-05-22T14:34:12.661961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#auto reload jupyter to update notebook w.r.t changes in other linked files:\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "237aafff1d2b17c1",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T14:34:21.351263Z",
     "start_time": "2025-05-22T14:34:12.703969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "#from xgboost.testing import root_mean_square\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from train_and_evaluate_sklearn import load_train_test_data\n",
    "from preprocessing import preprocess_data"
   ],
   "id": "566940c48a21383a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values after aggregation to median\n",
      "time                0\n",
      "lat                 0\n",
      "lon                 0\n",
      "clf                 0\n",
      "lwp                 0\n",
      "blh                 0\n",
      "cape                0\n",
      "mlspf               0\n",
      "mslhf               0\n",
      "msshf               0\n",
      "q700                0\n",
      "q850                0\n",
      "rh700               0\n",
      "rh850               0\n",
      "sst                 0\n",
      "t700                0\n",
      "t850                0\n",
      "tcwv                0\n",
      "u10                 0\n",
      "u700                0\n",
      "u850                0\n",
      "v10                 0\n",
      "v700                0\n",
      "v850                0\n",
      "w700                0\n",
      "w850                0\n",
      "Terra_descending    0\n",
      "lsm                 0\n",
      "eis                 0\n",
      "lnNd                0\n",
      "dtype: int64\n",
      "Null Values:\n",
      "time                0\n",
      "lat                 0\n",
      "lon                 0\n",
      "clf                 0\n",
      "lwp                 0\n",
      "blh                 0\n",
      "cape                0\n",
      "mlspf               0\n",
      "mslhf               0\n",
      "msshf               0\n",
      "q700                0\n",
      "q850                0\n",
      "rh700               0\n",
      "rh850               0\n",
      "sst                 0\n",
      "t700                0\n",
      "t850                0\n",
      "tcwv                0\n",
      "u10                 0\n",
      "u700                0\n",
      "u850                0\n",
      "v10                 0\n",
      "v700                0\n",
      "v850                0\n",
      "w700                0\n",
      "w850                0\n",
      "Terra_descending    0\n",
      "lsm                 0\n",
      "eis                 0\n",
      "lnNd                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-22T14:34:24.986068Z",
     "start_time": "2025-05-22T14:34:21.378674Z"
    }
   },
   "source": [
    "#Define the predictand\n",
    "predictands = 'both'  # 'clf', 'lwp', or 'both'\n",
    "\n",
    "df_train, df_test, X_train, y_train, X_test, y_test, predictors, predictands = preprocess_data(scalertype='minmax',\n",
    "                                                                                               outlier_method='iqr',\n",
    "                                                                                               scale_predictands=True,\n",
    "                                                                                               selected_predictands=predictands,\n",
    "                                                                                               train_fraction=0.75)\n",
    "#df_train, df_test, X_train, y_train, X_test, y_test, predictors, predictands = load_train_test_data(predictands=predictands)\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "\n",
    "# Convert pandas DataFrames to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "print(f'train_loader: {train_loader} \\n test_loader: {test_loader}' )\n",
    "print(f'size of train_loader: {len(train_loader)} \\n size of test_loader: {len(test_loader)}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (192944, 25), y_train shape: (192944, 2)\n",
      "train_loader: <torch.utils.data.dataloader.DataLoader object at 0x7c8e2a144490> \n",
      " test_loader: <torch.utils.data.dataloader.DataLoader object at 0x7c8f2cd46750>\n",
      "size of train_loader: 3015 \n",
      " size of test_loader: 937\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Neural Network Architecture",
   "id": "d88511ecfee38825"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T14:34:25.041105Z",
     "start_time": "2025-05-22T14:34:24.997418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MultiTargetRegressor(nn.Module):\n",
    "    \"\"\"Neural network for multi-target regression\"\"\"\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            # Input layer to first hidden layer\n",
    "            nn.Linear(input_size, 32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # First hidden layer to second hidden layer\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # second hidden layer to third hidden layer\n",
    "            nn.Linear(16, 10),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # third hidden layer to output layer\n",
    "            nn.Linear(10, output_size)\n",
    "        )\n",
    "\n",
    "        # Initialize weights using Kaiming He initialization for ReLU\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.kaiming_normal_(layer.weight, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Defines forward pass through network\"\"\"\n",
    "        return self.layers(x)"
   ],
   "id": "35a96a4f455b96e8",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T14:34:25.197724Z",
     "start_time": "2025-05-22T14:34:25.161804Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_model_structure(model, input_size, output_size):\n",
    "    neuron_counts = [input_size]  # Start with input size\n",
    "    linear_layers = []\n",
    "\n",
    "    # Collect neuron counts for each nn.Linear layer\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            neuron_counts.append(layer.out_features)\n",
    "            linear_layers.append(layer)\n",
    "\n",
    "    # Print neurons per layer\n",
    "    print(\"Model Structure:\")\n",
    "    print(f\"Input layer: {neuron_counts[0]} neurons\")\n",
    "    for i, n in enumerate(neuron_counts[1:-1], 1):\n",
    "        print(f\"Hidden layer {i}: {n} neurons\")\n",
    "    print(f\"Output layer: {neuron_counts[-1]} neurons\")\n",
    "\n",
    "    # Print total neurons (excluding input layer if you want only trainable neurons)\n",
    "    total_neurons = sum(neuron_counts)\n",
    "    print(f\"\\nTotal number of neurons (including input and output): {total_neurons}\")\n",
    "\n",
    "    # Print number of layers\n",
    "    print(f\"Number of layers (Linear): {len(linear_layers)}\")\n",
    "    print(f\"Number of hidden layers: {len(linear_layers) - 1}\")\n",
    "\n",
    "# Example usage:\n",
    "input_size = X_train.shape[1]\n",
    "output_size = y_train.shape[1]\n",
    "model = MultiTargetRegressor(input_size, output_size)\n",
    "print_model_structure(model, input_size, output_size)\n"
   ],
   "id": "46db43ce6555fda3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:\n",
      "Input layer: 25 neurons\n",
      "Hidden layer 1: 32 neurons\n",
      "Hidden layer 2: 16 neurons\n",
      "Hidden layer 3: 10 neurons\n",
      "Output layer: 2 neurons\n",
      "\n",
      "Total number of neurons (including input and output): 85\n",
      "Number of layers (Linear): 4\n",
      "Number of hidden layers: 3\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T14:34:25.895568Z",
     "start_time": "2025-05-22T14:34:25.277951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Hard to interpret this diagram\n",
    "# Install torchviz if not already installed\n",
    "# !pip install torchviz\n",
    "\n",
    "from torchviz import make_dot\n",
    "import torch\n",
    "\n",
    "def visualize_model(model, input_size):\n",
    "    # Create a dummy input tensor with the correct shape\n",
    "    x = torch.randn(1, input_size, requires_grad=True)\n",
    "    y = model(x)\n",
    "    # Create a visualization of the computation graph\n",
    "    dot = make_dot(y, params=dict(model.named_parameters()))\n",
    "    return dot\n",
    "\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "output_size = y_train.shape[1]\n",
    "model = MultiTargetRegressor(input_size, output_size)\n",
    "\n",
    "# Example usage:\n",
    "dot = visualize_model(model, input_size)\n",
    "#dot.render(\"model_architecture\", format=\"png\")  # Saves to file\n",
    "dot  # Display in Jupyter notebook\n"
   ],
   "id": "5429251d06e4a232",
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"541pt\" height=\"678pt\"\n viewBox=\"0.00 0.00 541.00 678.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 674)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-674 537,-674 537,4 -4,4\"/>\n<!-- 136950033106320 -->\n<g id=\"node1\" class=\"node\">\n<title>136950033106320</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"319,-31 260,-31 260,0 319,0 319,-31\"/>\n<text text-anchor=\"middle\" x=\"289.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> (1, 2)</text>\n</g>\n<!-- 136950032893984 -->\n<g id=\"node2\" class=\"node\">\n<title>136950032893984</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"340,-86 239,-86 239,-67 340,-67 340,-86\"/>\n<text text-anchor=\"middle\" x=\"289.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n</g>\n<!-- 136950032893984&#45;&gt;136950033106320 -->\n<g id=\"edge29\" class=\"edge\">\n<title>136950032893984&#45;&gt;136950033106320</title>\n<path fill=\"none\" stroke=\"black\" d=\"M289.5,-66.79C289.5,-60.07 289.5,-50.4 289.5,-41.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"293,-41.19 289.5,-31.19 286,-41.19 293,-41.19\"/>\n</g>\n<!-- 136950032893552 -->\n<g id=\"node3\" class=\"node\">\n<title>136950032893552</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"224,-141 123,-141 123,-122 224,-122 224,-141\"/>\n<text text-anchor=\"middle\" x=\"173.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 136950032893552&#45;&gt;136950032893984 -->\n<g id=\"edge1\" class=\"edge\">\n<title>136950032893552&#45;&gt;136950032893984</title>\n<path fill=\"none\" stroke=\"black\" d=\"M192.14,-121.98C210.8,-113.46 239.75,-100.23 261.24,-90.41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"262.88,-93.51 270.52,-86.17 259.97,-87.14 262.88,-93.51\"/>\n</g>\n<!-- 136950032738800 -->\n<g id=\"node4\" class=\"node\">\n<title>136950032738800</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"221,-207 126,-207 126,-177 221,-177 221,-207\"/>\n<text text-anchor=\"middle\" x=\"173.5\" y=\"-195\" font-family=\"monospace\" font-size=\"10.00\">layers.6.bias</text>\n<text text-anchor=\"middle\" x=\"173.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\"> (2)</text>\n</g>\n<!-- 136950032738800&#45;&gt;136950032893552 -->\n<g id=\"edge2\" class=\"edge\">\n<title>136950032738800&#45;&gt;136950032893552</title>\n<path fill=\"none\" stroke=\"black\" d=\"M173.5,-176.84C173.5,-169.21 173.5,-159.7 173.5,-151.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"177,-151.27 173.5,-141.27 170,-151.27 177,-151.27\"/>\n</g>\n<!-- 136950032893600 -->\n<g id=\"node5\" class=\"node\">\n<title>136950032893600</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"337,-141 242,-141 242,-122 337,-122 337,-141\"/>\n<text text-anchor=\"middle\" x=\"289.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">ReluBackward0</text>\n</g>\n<!-- 136950032893600&#45;&gt;136950032893984 -->\n<g id=\"edge3\" class=\"edge\">\n<title>136950032893600&#45;&gt;136950032893984</title>\n<path fill=\"none\" stroke=\"black\" d=\"M289.5,-121.75C289.5,-114.8 289.5,-104.85 289.5,-96.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"293,-96.09 289.5,-86.09 286,-96.09 293,-96.09\"/>\n</g>\n<!-- 136950032893696 -->\n<g id=\"node6\" class=\"node\">\n<title>136950032893696</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"340,-201.5 239,-201.5 239,-182.5 340,-182.5 340,-201.5\"/>\n<text text-anchor=\"middle\" x=\"289.5\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n</g>\n<!-- 136950032893696&#45;&gt;136950032893600 -->\n<g id=\"edge4\" class=\"edge\">\n<title>136950032893696&#45;&gt;136950032893600</title>\n<path fill=\"none\" stroke=\"black\" d=\"M289.5,-182.37C289.5,-174.25 289.5,-161.81 289.5,-151.39\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"293,-151.17 289.5,-141.17 286,-151.17 293,-151.17\"/>\n</g>\n<!-- 136950032893408 -->\n<g id=\"node7\" class=\"node\">\n<title>136950032893408</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"200,-267.5 99,-267.5 99,-248.5 200,-248.5 200,-267.5\"/>\n<text text-anchor=\"middle\" x=\"149.5\" y=\"-255.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 136950032893408&#45;&gt;136950032893696 -->\n<g id=\"edge5\" class=\"edge\">\n<title>136950032893408&#45;&gt;136950032893696</title>\n<path fill=\"none\" stroke=\"black\" d=\"M168.38,-248.37C192.28,-237.44 233.67,-218.52 261.32,-205.88\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"262.83,-209.04 270.47,-201.7 259.92,-202.67 262.83,-209.04\"/>\n</g>\n<!-- 136950032738608 -->\n<g id=\"node8\" class=\"node\">\n<title>136950032738608</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"197,-339 102,-339 102,-309 197,-309 197,-339\"/>\n<text text-anchor=\"middle\" x=\"149.5\" y=\"-327\" font-family=\"monospace\" font-size=\"10.00\">layers.4.bias</text>\n<text text-anchor=\"middle\" x=\"149.5\" y=\"-316\" font-family=\"monospace\" font-size=\"10.00\"> (10)</text>\n</g>\n<!-- 136950032738608&#45;&gt;136950032893408 -->\n<g id=\"edge6\" class=\"edge\">\n<title>136950032738608&#45;&gt;136950032893408</title>\n<path fill=\"none\" stroke=\"black\" d=\"M149.5,-308.8C149.5,-299.7 149.5,-287.79 149.5,-277.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"153,-277.84 149.5,-267.84 146,-277.84 153,-277.84\"/>\n</g>\n<!-- 136950032893456 -->\n<g id=\"node9\" class=\"node\">\n<title>136950032893456</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"313,-267.5 218,-267.5 218,-248.5 313,-248.5 313,-267.5\"/>\n<text text-anchor=\"middle\" x=\"265.5\" y=\"-255.5\" font-family=\"monospace\" font-size=\"10.00\">ReluBackward0</text>\n</g>\n<!-- 136950032893456&#45;&gt;136950032893696 -->\n<g id=\"edge7\" class=\"edge\">\n<title>136950032893456&#45;&gt;136950032893696</title>\n<path fill=\"none\" stroke=\"black\" d=\"M268.74,-248.37C272.26,-238.97 278,-223.67 282.55,-211.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"285.93,-212.5 286.16,-201.91 279.37,-210.04 285.93,-212.5\"/>\n</g>\n<!-- 136950032893168 -->\n<g id=\"node10\" class=\"node\">\n<title>136950032893168</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"316,-333.5 215,-333.5 215,-314.5 316,-314.5 316,-333.5\"/>\n<text text-anchor=\"middle\" x=\"265.5\" y=\"-321.5\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n</g>\n<!-- 136950032893168&#45;&gt;136950032893456 -->\n<g id=\"edge8\" class=\"edge\">\n<title>136950032893168&#45;&gt;136950032893456</title>\n<path fill=\"none\" stroke=\"black\" d=\"M265.5,-314.37C265.5,-305.16 265.5,-290.29 265.5,-278.27\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"269,-277.91 265.5,-267.91 262,-277.91 269,-277.91\"/>\n</g>\n<!-- 136950032892976 -->\n<g id=\"node11\" class=\"node\">\n<title>136950032892976</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"153,-399.5 52,-399.5 52,-380.5 153,-380.5 153,-399.5\"/>\n<text text-anchor=\"middle\" x=\"102.5\" y=\"-387.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 136950032892976&#45;&gt;136950032893168 -->\n<g id=\"edge9\" class=\"edge\">\n<title>136950032892976&#45;&gt;136950032893168</title>\n<path fill=\"none\" stroke=\"black\" d=\"M124.48,-380.37C152.75,-369.27 202.04,-349.92 234.21,-337.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"235.58,-340.51 243.61,-333.6 233.02,-333.99 235.58,-340.51\"/>\n</g>\n<!-- 136950032738416 -->\n<g id=\"node12\" class=\"node\">\n<title>136950032738416</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"150,-471 55,-471 55,-441 150,-441 150,-471\"/>\n<text text-anchor=\"middle\" x=\"102.5\" y=\"-459\" font-family=\"monospace\" font-size=\"10.00\">layers.2.bias</text>\n<text text-anchor=\"middle\" x=\"102.5\" y=\"-448\" font-family=\"monospace\" font-size=\"10.00\"> (16)</text>\n</g>\n<!-- 136950032738416&#45;&gt;136950032892976 -->\n<g id=\"edge10\" class=\"edge\">\n<title>136950032738416&#45;&gt;136950032892976</title>\n<path fill=\"none\" stroke=\"black\" d=\"M102.5,-440.8C102.5,-431.7 102.5,-419.79 102.5,-409.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"106,-409.84 102.5,-399.84 99,-409.84 106,-409.84\"/>\n</g>\n<!-- 136950032893024 -->\n<g id=\"node13\" class=\"node\">\n<title>136950032893024</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"266,-399.5 171,-399.5 171,-380.5 266,-380.5 266,-399.5\"/>\n<text text-anchor=\"middle\" x=\"218.5\" y=\"-387.5\" font-family=\"monospace\" font-size=\"10.00\">ReluBackward0</text>\n</g>\n<!-- 136950032893024&#45;&gt;136950032893168 -->\n<g id=\"edge11\" class=\"edge\">\n<title>136950032893024&#45;&gt;136950032893168</title>\n<path fill=\"none\" stroke=\"black\" d=\"M224.84,-380.37C232.02,-370.59 243.89,-354.42 252.96,-342.08\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"255.86,-344.04 258.96,-333.91 250.22,-339.89 255.86,-344.04\"/>\n</g>\n<!-- 136950032892880 -->\n<g id=\"node14\" class=\"node\">\n<title>136950032892880</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"269,-465.5 168,-465.5 168,-446.5 269,-446.5 269,-465.5\"/>\n<text text-anchor=\"middle\" x=\"218.5\" y=\"-453.5\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n</g>\n<!-- 136950032892880&#45;&gt;136950032893024 -->\n<g id=\"edge12\" class=\"edge\">\n<title>136950032892880&#45;&gt;136950032893024</title>\n<path fill=\"none\" stroke=\"black\" d=\"M218.5,-446.37C218.5,-437.16 218.5,-422.29 218.5,-410.27\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"222,-409.91 218.5,-399.91 215,-409.91 222,-409.91\"/>\n</g>\n<!-- 136950032892592 -->\n<g id=\"node15\" class=\"node\">\n<title>136950032892592</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-531.5 0,-531.5 0,-512.5 101,-512.5 101,-531.5\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-519.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 136950032892592&#45;&gt;136950032892880 -->\n<g id=\"edge13\" class=\"edge\">\n<title>136950032892592&#45;&gt;136950032892880</title>\n<path fill=\"none\" stroke=\"black\" d=\"M73.16,-512.37C102.3,-501.27 153.09,-481.92 186.25,-469.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"187.84,-472.43 195.93,-465.6 185.34,-465.89 187.84,-472.43\"/>\n</g>\n<!-- 136950032738224 -->\n<g id=\"node16\" class=\"node\">\n<title>136950032738224</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"98,-603.5 3,-603.5 3,-573.5 98,-573.5 98,-603.5\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-591.5\" font-family=\"monospace\" font-size=\"10.00\">layers.0.bias</text>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-580.5\" font-family=\"monospace\" font-size=\"10.00\"> (32)</text>\n</g>\n<!-- 136950032738224&#45;&gt;136950032892592 -->\n<g id=\"edge14\" class=\"edge\">\n<title>136950032738224&#45;&gt;136950032892592</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-573.19C50.5,-563.91 50.5,-551.73 50.5,-541.69\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-541.54 50.5,-531.54 47,-541.54 54,-541.54\"/>\n</g>\n<!-- 136950032892640 -->\n<g id=\"node17\" class=\"node\">\n<title>136950032892640</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"220,-531.5 119,-531.5 119,-512.5 220,-512.5 220,-531.5\"/>\n<text text-anchor=\"middle\" x=\"169.5\" y=\"-519.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 136950032892640&#45;&gt;136950032892880 -->\n<g id=\"edge15\" class=\"edge\">\n<title>136950032892640&#45;&gt;136950032892880</title>\n<path fill=\"none\" stroke=\"black\" d=\"M176.11,-512.37C183.59,-502.59 195.97,-486.42 205.43,-474.08\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"208.38,-475.97 211.68,-465.91 202.82,-471.72 208.38,-475.97\"/>\n</g>\n<!-- 136950033106704 -->\n<g id=\"node18\" class=\"node\">\n<title>136950033106704</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"202,-604 137,-604 137,-573 202,-573 202,-604\"/>\n<text text-anchor=\"middle\" x=\"169.5\" y=\"-580\" font-family=\"monospace\" font-size=\"10.00\"> (1, 25)</text>\n</g>\n<!-- 136950033106704&#45;&gt;136950032892640 -->\n<g id=\"edge16\" class=\"edge\">\n<title>136950033106704&#45;&gt;136950032892640</title>\n<path fill=\"none\" stroke=\"black\" d=\"M169.5,-572.86C169.5,-563.68 169.5,-551.75 169.5,-541.86\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"173,-541.82 169.5,-531.82 166,-541.82 173,-541.82\"/>\n</g>\n<!-- 136950032892688 -->\n<g id=\"node19\" class=\"node\">\n<title>136950032892688</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"315,-531.5 238,-531.5 238,-512.5 315,-512.5 315,-531.5\"/>\n<text text-anchor=\"middle\" x=\"276.5\" y=\"-519.5\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n</g>\n<!-- 136950032892688&#45;&gt;136950032892880 -->\n<g id=\"edge17\" class=\"edge\">\n<title>136950032892688&#45;&gt;136950032892880</title>\n<path fill=\"none\" stroke=\"black\" d=\"M268.68,-512.37C259.65,-502.4 244.59,-485.79 233.33,-473.36\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"235.88,-470.96 226.57,-465.91 230.69,-475.67 235.88,-470.96\"/>\n</g>\n<!-- 136950032892304 -->\n<g id=\"node20\" class=\"node\">\n<title>136950032892304</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"327,-598 226,-598 226,-579 327,-579 327,-598\"/>\n<text text-anchor=\"middle\" x=\"276.5\" y=\"-586\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 136950032892304&#45;&gt;136950032892688 -->\n<g id=\"edge18\" class=\"edge\">\n<title>136950032892304&#45;&gt;136950032892688</title>\n<path fill=\"none\" stroke=\"black\" d=\"M276.5,-578.8C276.5,-569.32 276.5,-553.88 276.5,-541.64\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"280,-541.56 276.5,-531.56 273,-541.56 280,-541.56\"/>\n</g>\n<!-- 136950032738128 -->\n<g id=\"node21\" class=\"node\">\n<title>136950032738128</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"330,-670 223,-670 223,-640 330,-640 330,-670\"/>\n<text text-anchor=\"middle\" x=\"276.5\" y=\"-658\" font-family=\"monospace\" font-size=\"10.00\">layers.0.weight</text>\n<text text-anchor=\"middle\" x=\"276.5\" y=\"-647\" font-family=\"monospace\" font-size=\"10.00\"> (32, 25)</text>\n</g>\n<!-- 136950032738128&#45;&gt;136950032892304 -->\n<g id=\"edge19\" class=\"edge\">\n<title>136950032738128&#45;&gt;136950032892304</title>\n<path fill=\"none\" stroke=\"black\" d=\"M276.5,-639.69C276.5,-630.41 276.5,-618.23 276.5,-608.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"280,-608.04 276.5,-598.04 273,-608.04 280,-608.04\"/>\n</g>\n<!-- 136950032893072 -->\n<g id=\"node22\" class=\"node\">\n<title>136950032893072</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"361,-399.5 284,-399.5 284,-380.5 361,-380.5 361,-399.5\"/>\n<text text-anchor=\"middle\" x=\"322.5\" y=\"-387.5\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n</g>\n<!-- 136950032893072&#45;&gt;136950032893168 -->\n<g id=\"edge20\" class=\"edge\">\n<title>136950032893072&#45;&gt;136950032893168</title>\n<path fill=\"none\" stroke=\"black\" d=\"M314.81,-380.37C306.02,-370.5 291.43,-354.11 280.39,-341.72\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"282.7,-339.05 273.43,-333.91 277.47,-343.7 282.7,-339.05\"/>\n</g>\n<!-- 136950032892352 -->\n<g id=\"node23\" class=\"node\">\n<title>136950032892352</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"412,-465.5 311,-465.5 311,-446.5 412,-446.5 412,-465.5\"/>\n<text text-anchor=\"middle\" x=\"361.5\" y=\"-453.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 136950032892352&#45;&gt;136950032893072 -->\n<g id=\"edge21\" class=\"edge\">\n<title>136950032892352&#45;&gt;136950032893072</title>\n<path fill=\"none\" stroke=\"black\" d=\"M356.24,-446.37C350.4,-436.78 340.81,-421.05 333.35,-408.8\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"336.12,-406.62 327.93,-399.91 330.14,-410.27 336.12,-406.62\"/>\n</g>\n<!-- 136950032738320 -->\n<g id=\"node24\" class=\"node\">\n<title>136950032738320</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"440,-537 333,-537 333,-507 440,-507 440,-537\"/>\n<text text-anchor=\"middle\" x=\"386.5\" y=\"-525\" font-family=\"monospace\" font-size=\"10.00\">layers.2.weight</text>\n<text text-anchor=\"middle\" x=\"386.5\" y=\"-514\" font-family=\"monospace\" font-size=\"10.00\"> (16, 32)</text>\n</g>\n<!-- 136950032738320&#45;&gt;136950032892352 -->\n<g id=\"edge22\" class=\"edge\">\n<title>136950032738320&#45;&gt;136950032892352</title>\n<path fill=\"none\" stroke=\"black\" d=\"M380.95,-506.8C377.32,-497.5 372.54,-485.27 368.63,-475.26\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"371.85,-473.89 364.95,-465.84 365.33,-476.43 371.85,-473.89\"/>\n</g>\n<!-- 136950032893744 -->\n<g id=\"node25\" class=\"node\">\n<title>136950032893744</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"408,-267.5 331,-267.5 331,-248.5 408,-248.5 408,-267.5\"/>\n<text text-anchor=\"middle\" x=\"369.5\" y=\"-255.5\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n</g>\n<!-- 136950032893744&#45;&gt;136950032893696 -->\n<g id=\"edge23\" class=\"edge\">\n<title>136950032893744&#45;&gt;136950032893696</title>\n<path fill=\"none\" stroke=\"black\" d=\"M358.71,-248.37C345.83,-238.06 324.06,-220.65 308.37,-208.09\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"310.37,-205.21 300.37,-201.7 306,-210.68 310.37,-205.21\"/>\n</g>\n<!-- 136950032892496 -->\n<g id=\"node26\" class=\"node\">\n<title>136950032892496</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"459,-333.5 358,-333.5 358,-314.5 459,-314.5 459,-333.5\"/>\n<text text-anchor=\"middle\" x=\"408.5\" y=\"-321.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 136950032892496&#45;&gt;136950032893744 -->\n<g id=\"edge24\" class=\"edge\">\n<title>136950032892496&#45;&gt;136950032893744</title>\n<path fill=\"none\" stroke=\"black\" d=\"M403.24,-314.37C397.4,-304.78 387.81,-289.05 380.35,-276.8\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"383.12,-274.62 374.93,-267.91 377.14,-278.27 383.12,-274.62\"/>\n</g>\n<!-- 136950032738512 -->\n<g id=\"node27\" class=\"node\">\n<title>136950032738512</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"486,-405 379,-405 379,-375 486,-375 486,-405\"/>\n<text text-anchor=\"middle\" x=\"432.5\" y=\"-393\" font-family=\"monospace\" font-size=\"10.00\">layers.4.weight</text>\n<text text-anchor=\"middle\" x=\"432.5\" y=\"-382\" font-family=\"monospace\" font-size=\"10.00\"> (10, 16)</text>\n</g>\n<!-- 136950032738512&#45;&gt;136950032892496 -->\n<g id=\"edge25\" class=\"edge\">\n<title>136950032738512&#45;&gt;136950032892496</title>\n<path fill=\"none\" stroke=\"black\" d=\"M427.17,-374.8C423.69,-365.5 419.1,-353.27 415.35,-343.26\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"418.61,-341.98 411.82,-333.84 412.05,-344.44 418.61,-341.98\"/>\n</g>\n<!-- 136950032893648 -->\n<g id=\"node28\" class=\"node\">\n<title>136950032893648</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"463,-141 386,-141 386,-122 463,-122 463,-141\"/>\n<text text-anchor=\"middle\" x=\"424.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n</g>\n<!-- 136950032893648&#45;&gt;136950032893984 -->\n<g id=\"edge26\" class=\"edge\">\n<title>136950032893648&#45;&gt;136950032893984</title>\n<path fill=\"none\" stroke=\"black\" d=\"M402.81,-121.98C380.7,-113.3 346.18,-99.75 321.05,-89.88\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"322.17,-86.57 311.58,-86.17 319.61,-93.08 322.17,-86.57\"/>\n</g>\n<!-- 136950032892928 -->\n<g id=\"node29\" class=\"node\">\n<title>136950032892928</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"506,-201.5 405,-201.5 405,-182.5 506,-182.5 506,-201.5\"/>\n<text text-anchor=\"middle\" x=\"455.5\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 136950032892928&#45;&gt;136950032893648 -->\n<g id=\"edge27\" class=\"edge\">\n<title>136950032892928&#45;&gt;136950032893648</title>\n<path fill=\"none\" stroke=\"black\" d=\"M450.93,-182.37C446.44,-173.9 439.47,-160.74 433.81,-150.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"436.87,-148.36 429.09,-141.17 430.68,-151.64 436.87,-148.36\"/>\n</g>\n<!-- 136950032738704 -->\n<g id=\"node30\" class=\"node\">\n<title>136950032738704</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"533,-273 426,-273 426,-243 533,-243 533,-273\"/>\n<text text-anchor=\"middle\" x=\"479.5\" y=\"-261\" font-family=\"monospace\" font-size=\"10.00\">layers.6.weight</text>\n<text text-anchor=\"middle\" x=\"479.5\" y=\"-250\" font-family=\"monospace\" font-size=\"10.00\"> (2, 10)</text>\n</g>\n<!-- 136950032738704&#45;&gt;136950032892928 -->\n<g id=\"edge28\" class=\"edge\">\n<title>136950032738704&#45;&gt;136950032892928</title>\n<path fill=\"none\" stroke=\"black\" d=\"M474.17,-242.8C470.69,-233.5 466.1,-221.27 462.35,-211.26\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"465.61,-209.98 458.82,-201.84 459.05,-212.44 465.61,-209.98\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7c8e2a193b50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T14:34:25.982733Z",
     "start_time": "2025-05-22T14:34:25.950168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# If not installed, uncomment the next line:\n",
    "# !pip install torchsummary\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "def visualize_model_summary(model, input_size):\n",
    "    # input_size should be a tuple without batch size, e.g. (number_of_features,)\n",
    "    summary(model, input_size)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "input_size = X_train.shape[1]\n",
    "output_size = y_train.shape[1]\n",
    "model = MultiTargetRegressor(input_size, output_size)\n",
    "\n",
    "visualize_model_summary(model, input_size=(X_train.shape[1],))\n"
   ],
   "id": "b3cde278ae0feeb0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                   [-1, 32]             832\n",
      "              ReLU-2                   [-1, 32]               0\n",
      "            Linear-3                   [-1, 16]             528\n",
      "              ReLU-4                   [-1, 16]               0\n",
      "            Linear-5                   [-1, 10]             170\n",
      "              ReLU-6                   [-1, 10]               0\n",
      "            Linear-7                    [-1, 2]              22\n",
      "================================================================\n",
      "Total params: 1,552\n",
      "Trainable params: 1,552\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.01\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Model Training Function:",
   "id": "a786d8c007b1e06"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T14:43:10.725462Z",
     "start_time": "2025-05-22T14:43:10.668195Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(model, train_loader, test_loader, num_epochs=100):\n",
    "    \"\"\"Training loop with validation monitoring\"\"\"\n",
    "    # Loss function and optimizer\n",
    "    learning_rate = 0.005\n",
    "    loss_function = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5)\n",
    "\n",
    "    # Track losses for visualization\n",
    "    train_losses, val_losses = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        epoch_train_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()  # Reset gradients\n",
    "            outputs = model(X_batch)  # Forward pass\n",
    "            loss = loss_function(outputs, y_batch)  # Compute loss\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Update weights\n",
    "            epoch_train_loss += loss.item()\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        epoch_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in test_loader:\n",
    "                outputs = model(X_batch)\n",
    "                loss = loss_function(outputs, y_batch)\n",
    "                epoch_val_loss += loss.item()\n",
    "\n",
    "        # Calculate average losses\n",
    "        train_loss = epoch_train_loss / len(train_loader)\n",
    "        val_loss = epoch_val_loss / len(test_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # Update learning rate\n",
    "        scheduler.step(val_loss)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | LR: {scheduler.get_last_lr()[0]:.6f}')\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}')\n",
    "\n",
    "    return train_losses, val_losses\n"
   ],
   "id": "1e9fb176a0a77840",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T14:46:01.721972Z",
     "start_time": "2025-05-22T14:43:14.939778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#TIME CONSUMING STEP\n",
    "#Model Training\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "output_size = y_train.shape[1]\n",
    "model = MultiTargetRegressor(input_size, output_size)\n",
    "\n",
    "# Train model\n",
    "train_losses, val_losses = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    num_epochs=30\n",
    ")\n",
    "\n",
    "\n",
    "#"
   ],
   "id": "f7ddddfc66b070aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 | Train Loss: 0.0521 | Val Loss: 0.0457 | LR: 0.005000\n",
      "Epoch 1/30 | Train Loss: 0.0521 | Val Loss: 0.0457\n",
      "Epoch 2/30 | Train Loss: 0.0463 | Val Loss: 0.0452 | LR: 0.005000\n",
      "Epoch 2/30 | Train Loss: 0.0463 | Val Loss: 0.0452\n",
      "Epoch 3/30 | Train Loss: 0.0452 | Val Loss: 0.0440 | LR: 0.005000\n",
      "Epoch 3/30 | Train Loss: 0.0452 | Val Loss: 0.0440\n",
      "Epoch 4/30 | Train Loss: 0.0447 | Val Loss: 0.0434 | LR: 0.005000\n",
      "Epoch 4/30 | Train Loss: 0.0447 | Val Loss: 0.0434\n",
      "Epoch 5/30 | Train Loss: 0.0443 | Val Loss: 0.0437 | LR: 0.005000\n",
      "Epoch 5/30 | Train Loss: 0.0443 | Val Loss: 0.0437\n",
      "Epoch 6/30 | Train Loss: 0.0440 | Val Loss: 0.0439 | LR: 0.005000\n",
      "Epoch 6/30 | Train Loss: 0.0440 | Val Loss: 0.0439\n",
      "Epoch 7/30 | Train Loss: 0.0437 | Val Loss: 0.0437 | LR: 0.005000\n",
      "Epoch 7/30 | Train Loss: 0.0437 | Val Loss: 0.0437\n",
      "Epoch 8/30 | Train Loss: 0.0436 | Val Loss: 0.0426 | LR: 0.005000\n",
      "Epoch 8/30 | Train Loss: 0.0436 | Val Loss: 0.0426\n",
      "Epoch 9/30 | Train Loss: 0.0433 | Val Loss: 0.0431 | LR: 0.005000\n",
      "Epoch 9/30 | Train Loss: 0.0433 | Val Loss: 0.0431\n",
      "Epoch 10/30 | Train Loss: 0.0431 | Val Loss: 0.0423 | LR: 0.005000\n",
      "Epoch 10/30 | Train Loss: 0.0431 | Val Loss: 0.0423\n",
      "Epoch 11/30 | Train Loss: 0.0431 | Val Loss: 0.0440 | LR: 0.005000\n",
      "Epoch 11/30 | Train Loss: 0.0431 | Val Loss: 0.0440\n",
      "Epoch 12/30 | Train Loss: 0.0430 | Val Loss: 0.0422 | LR: 0.005000\n",
      "Epoch 12/30 | Train Loss: 0.0430 | Val Loss: 0.0422\n",
      "Epoch 13/30 | Train Loss: 0.0428 | Val Loss: 0.0419 | LR: 0.005000\n",
      "Epoch 13/30 | Train Loss: 0.0428 | Val Loss: 0.0419\n",
      "Epoch 14/30 | Train Loss: 0.0428 | Val Loss: 0.0433 | LR: 0.005000\n",
      "Epoch 14/30 | Train Loss: 0.0428 | Val Loss: 0.0433\n",
      "Epoch 15/30 | Train Loss: 0.0428 | Val Loss: 0.0420 | LR: 0.005000\n",
      "Epoch 15/30 | Train Loss: 0.0428 | Val Loss: 0.0420\n",
      "Epoch 16/30 | Train Loss: 0.0426 | Val Loss: 0.0438 | LR: 0.005000\n",
      "Epoch 16/30 | Train Loss: 0.0426 | Val Loss: 0.0438\n",
      "Epoch 17/30 | Train Loss: 0.0426 | Val Loss: 0.0417 | LR: 0.005000\n",
      "Epoch 17/30 | Train Loss: 0.0426 | Val Loss: 0.0417\n",
      "Epoch 18/30 | Train Loss: 0.0424 | Val Loss: 0.0428 | LR: 0.005000\n",
      "Epoch 18/30 | Train Loss: 0.0424 | Val Loss: 0.0428\n",
      "Epoch 19/30 | Train Loss: 0.0424 | Val Loss: 0.0417 | LR: 0.005000\n",
      "Epoch 19/30 | Train Loss: 0.0424 | Val Loss: 0.0417\n",
      "Epoch 20/30 | Train Loss: 0.0424 | Val Loss: 0.0421 | LR: 0.005000\n",
      "Epoch 20/30 | Train Loss: 0.0424 | Val Loss: 0.0421\n",
      "Epoch 21/30 | Train Loss: 0.0424 | Val Loss: 0.0426 | LR: 0.005000\n",
      "Epoch 21/30 | Train Loss: 0.0424 | Val Loss: 0.0426\n",
      "Epoch 22/30 | Train Loss: 0.0424 | Val Loss: 0.0417 | LR: 0.005000\n",
      "Epoch 22/30 | Train Loss: 0.0424 | Val Loss: 0.0417\n",
      "Epoch 23/30 | Train Loss: 0.0423 | Val Loss: 0.0429 | LR: 0.000500\n",
      "Epoch 23/30 | Train Loss: 0.0423 | Val Loss: 0.0429\n",
      "Epoch 24/30 | Train Loss: 0.0410 | Val Loss: 0.0410 | LR: 0.000500\n",
      "Epoch 24/30 | Train Loss: 0.0410 | Val Loss: 0.0410\n",
      "Epoch 25/30 | Train Loss: 0.0409 | Val Loss: 0.0410 | LR: 0.000500\n",
      "Epoch 25/30 | Train Loss: 0.0409 | Val Loss: 0.0410\n",
      "Epoch 26/30 | Train Loss: 0.0409 | Val Loss: 0.0410 | LR: 0.000500\n",
      "Epoch 26/30 | Train Loss: 0.0409 | Val Loss: 0.0410\n",
      "Epoch 27/30 | Train Loss: 0.0408 | Val Loss: 0.0409 | LR: 0.000500\n",
      "Epoch 27/30 | Train Loss: 0.0408 | Val Loss: 0.0409\n",
      "Epoch 28/30 | Train Loss: 0.0408 | Val Loss: 0.0410 | LR: 0.000500\n",
      "Epoch 28/30 | Train Loss: 0.0408 | Val Loss: 0.0410\n",
      "Epoch 29/30 | Train Loss: 0.0408 | Val Loss: 0.0410 | LR: 0.000500\n",
      "Epoch 29/30 | Train Loss: 0.0408 | Val Loss: 0.0410\n",
      "Epoch 30/30 | Train Loss: 0.0408 | Val Loss: 0.0409 | LR: 0.000500\n",
      "Epoch 30/30 | Train Loss: 0.0408 | Val Loss: 0.0409\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T10:32:05.546774Z",
     "start_time": "2025-05-22T10:32:01.621181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#VERY TIME CONSUMING STEP\n",
    "#HYPER-PARAMETER TUNING: GRID SEARCH\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define your hyperparameter grid\n",
    "param_grid = {\n",
    "    'lr': [0.01, 0.001],\n",
    "    'batch_size': [32, 64],\n",
    "    'hidden1': [128, 256]\n",
    "}\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_params = None\n",
    "\n",
    "for lr, batch_size, hidden1 in product(param_grid['lr'], param_grid['batch_size'], param_grid['hidden1']):\n",
    "    # Prepare data loaders with batch_size\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    # Define model with current hidden layer size\n",
    "    model = MultiTargetRegressor(input_size, output_size)\n",
    "    # Optionally, modify your model to accept hidden1 as a parameter\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Train for a few epochs (e.g., 5 for speed)\n",
    "    for epoch in range(5):\n",
    "        model.train()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            val_loss += loss.item()\n",
    "    val_loss /= len(test_loader)\n",
    "\n",
    "    # Save best\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_params = {'lr': lr, 'batch_size': batch_size, 'hidden1': hidden1}\n",
    "\n",
    "print(\"Best params:\", best_params)\n",
    "print(\"Best validation loss:\", best_val_loss)\n"
   ],
   "id": "aab9916eaa3b2042",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 37\u001B[0m\n\u001B[1;32m     35\u001B[0m         loss \u001B[38;5;241m=\u001B[39m criterion(outputs, y_batch)\n\u001B[1;32m     36\u001B[0m         loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m---> 37\u001B[0m         optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     39\u001B[0m \u001B[38;5;66;03m# Evaluate on validation set\u001B[39;00m\n\u001B[1;32m     40\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n",
      "File \u001B[0;32m~/Installed/miniconda3/envs/calisma/lib/python3.11/site-packages/torch/optim/optimizer.py:493\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    488\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    489\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    490\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    491\u001B[0m             )\n\u001B[0;32m--> 493\u001B[0m out \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    494\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[1;32m    496\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[0;32m~/Installed/miniconda3/envs/calisma/lib/python3.11/site-packages/torch/optim/optimizer.py:91\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     89\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m     90\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n\u001B[0;32m---> 91\u001B[0m     ret \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     92\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     93\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n",
      "File \u001B[0;32m~/Installed/miniconda3/envs/calisma/lib/python3.11/site-packages/torch/optim/adam.py:244\u001B[0m, in \u001B[0;36mAdam.step\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    232\u001B[0m     beta1, beta2 \u001B[38;5;241m=\u001B[39m group[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbetas\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    234\u001B[0m     has_complex \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_group(\n\u001B[1;32m    235\u001B[0m         group,\n\u001B[1;32m    236\u001B[0m         params_with_grad,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    241\u001B[0m         state_steps,\n\u001B[1;32m    242\u001B[0m     )\n\u001B[0;32m--> 244\u001B[0m     adam(\n\u001B[1;32m    245\u001B[0m         params_with_grad,\n\u001B[1;32m    246\u001B[0m         grads,\n\u001B[1;32m    247\u001B[0m         exp_avgs,\n\u001B[1;32m    248\u001B[0m         exp_avg_sqs,\n\u001B[1;32m    249\u001B[0m         max_exp_avg_sqs,\n\u001B[1;32m    250\u001B[0m         state_steps,\n\u001B[1;32m    251\u001B[0m         amsgrad\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mamsgrad\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m    252\u001B[0m         has_complex\u001B[38;5;241m=\u001B[39mhas_complex,\n\u001B[1;32m    253\u001B[0m         beta1\u001B[38;5;241m=\u001B[39mbeta1,\n\u001B[1;32m    254\u001B[0m         beta2\u001B[38;5;241m=\u001B[39mbeta2,\n\u001B[1;32m    255\u001B[0m         lr\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlr\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m    256\u001B[0m         weight_decay\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mweight_decay\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m    257\u001B[0m         eps\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124meps\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m    258\u001B[0m         maximize\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmaximize\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m    259\u001B[0m         foreach\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mforeach\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m    260\u001B[0m         capturable\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcapturable\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m    261\u001B[0m         differentiable\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m    262\u001B[0m         fused\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfused\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m    263\u001B[0m         grad_scale\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgrad_scale\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m    264\u001B[0m         found_inf\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfound_inf\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m    265\u001B[0m     )\n\u001B[1;32m    267\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[0;32m~/Installed/miniconda3/envs/calisma/lib/python3.11/site-packages/torch/optim/optimizer.py:154\u001B[0m, in \u001B[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m disabled_func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    153\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 154\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/Installed/miniconda3/envs/calisma/lib/python3.11/site-packages/torch/optim/adam.py:876\u001B[0m, in \u001B[0;36madam\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[1;32m    873\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    874\u001B[0m     func \u001B[38;5;241m=\u001B[39m _single_tensor_adam\n\u001B[0;32m--> 876\u001B[0m func(\n\u001B[1;32m    877\u001B[0m     params,\n\u001B[1;32m    878\u001B[0m     grads,\n\u001B[1;32m    879\u001B[0m     exp_avgs,\n\u001B[1;32m    880\u001B[0m     exp_avg_sqs,\n\u001B[1;32m    881\u001B[0m     max_exp_avg_sqs,\n\u001B[1;32m    882\u001B[0m     state_steps,\n\u001B[1;32m    883\u001B[0m     amsgrad\u001B[38;5;241m=\u001B[39mamsgrad,\n\u001B[1;32m    884\u001B[0m     has_complex\u001B[38;5;241m=\u001B[39mhas_complex,\n\u001B[1;32m    885\u001B[0m     beta1\u001B[38;5;241m=\u001B[39mbeta1,\n\u001B[1;32m    886\u001B[0m     beta2\u001B[38;5;241m=\u001B[39mbeta2,\n\u001B[1;32m    887\u001B[0m     lr\u001B[38;5;241m=\u001B[39mlr,\n\u001B[1;32m    888\u001B[0m     weight_decay\u001B[38;5;241m=\u001B[39mweight_decay,\n\u001B[1;32m    889\u001B[0m     eps\u001B[38;5;241m=\u001B[39meps,\n\u001B[1;32m    890\u001B[0m     maximize\u001B[38;5;241m=\u001B[39mmaximize,\n\u001B[1;32m    891\u001B[0m     capturable\u001B[38;5;241m=\u001B[39mcapturable,\n\u001B[1;32m    892\u001B[0m     differentiable\u001B[38;5;241m=\u001B[39mdifferentiable,\n\u001B[1;32m    893\u001B[0m     grad_scale\u001B[38;5;241m=\u001B[39mgrad_scale,\n\u001B[1;32m    894\u001B[0m     found_inf\u001B[38;5;241m=\u001B[39mfound_inf,\n\u001B[1;32m    895\u001B[0m )\n",
      "File \u001B[0;32m~/Installed/miniconda3/envs/calisma/lib/python3.11/site-packages/torch/optim/adam.py:425\u001B[0m, in \u001B[0;36m_single_tensor_adam\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001B[0m\n\u001B[1;32m    422\u001B[0m \u001B[38;5;66;03m# Decay the first and second moment running average coefficient\u001B[39;00m\n\u001B[1;32m    423\u001B[0m exp_avg\u001B[38;5;241m.\u001B[39mlerp_(grad, \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m device_beta1)\n\u001B[0;32m--> 425\u001B[0m exp_avg_sq\u001B[38;5;241m.\u001B[39mmul_(beta2)\u001B[38;5;241m.\u001B[39maddcmul_(grad, grad\u001B[38;5;241m.\u001B[39mconj(), value\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m beta2)\n\u001B[1;32m    427\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m capturable \u001B[38;5;129;01mor\u001B[39;00m differentiable:\n\u001B[1;32m    428\u001B[0m     step \u001B[38;5;241m=\u001B[39m step_t\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T11:10:59.672216Z",
     "start_time": "2025-05-22T10:36:17.453001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#VERY TIME CONSUMING STEP\n",
    "#HYPER-PARAMETER TUNING: RANDOM SEARCH\n",
    "\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# Define the hyperparameter space\n",
    "param_space = {\n",
    "    'lr': [1e-3, 5e-4],#, 1e-4, 5e-5],\n",
    "    'batch_size': [16, 32, 64],#, 128],\n",
    "    'num_epochs': [20],\n",
    "    # more hyperparameters as needed\n",
    "}\n",
    "\n",
    "n_trials = 10  # Number of random samples\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_params = None\n",
    "\n",
    "for trial in range(n_trials):\n",
    "    # Randomly sample hyperparameters\n",
    "    lr = random.choice(param_space['lr'])\n",
    "    batch_size = random.choice(param_space['batch_size'])\n",
    "    num_epochs = random.choice(param_space['num_epochs'])\n",
    "\n",
    "    # Create new dataloaders for this batch size\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    # Initialize model\n",
    "    model = MultiTargetRegressor(input_size, output_size)\n",
    "\n",
    "    # Set optimizer with sampled learning rate\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Train model (use your train_model function)\n",
    "    train_losses, val_losses = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        test_loader=test_loader,\n",
    "        num_epochs=num_epochs\n",
    "    )\n",
    "\n",
    "    # Use the last validation loss as the metric\n",
    "    final_val_loss = val_losses[-1]\n",
    "\n",
    "    print(f\"Trial {trial+1}: lr={lr}, batch_size={batch_size}, num_epochs={num_epochs}, val_loss={final_val_loss:.4f}\")\n",
    "\n",
    "    # Track the best hyperparameters\n",
    "    if final_val_loss < best_val_loss:\n",
    "        best_val_loss = final_val_loss\n",
    "        best_params = {\n",
    "            'lr': lr,\n",
    "            'batch_size': batch_size,\n",
    "            'num_epochs': num_epochs\n",
    "        }\n",
    "\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "print(\"Best validation loss:\", best_val_loss)\n"
   ],
   "id": "4686c18c0136136a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sparashar/Installed/miniconda3/envs/calisma/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Train Loss: 0.6257 | Val Loss: 0.5796\n",
      "Epoch 2/20 | Train Loss: 0.5986 | Val Loss: 0.5750\n",
      "Epoch 3/20 | Train Loss: 0.5926 | Val Loss: 0.5656\n",
      "Epoch 4/20 | Train Loss: 0.5887 | Val Loss: 0.5591\n",
      "Epoch 5/20 | Train Loss: 0.5880 | Val Loss: 0.5595\n",
      "Epoch 6/20 | Train Loss: 0.5872 | Val Loss: 0.5708\n",
      "Epoch 7/20 | Train Loss: 0.5843 | Val Loss: 0.5594\n",
      "Epoch 8/20 | Train Loss: 0.5829 | Val Loss: 0.5614\n",
      "Epoch 9/20 | Train Loss: 0.5821 | Val Loss: 0.5490\n",
      "Epoch 10/20 | Train Loss: 0.5815 | Val Loss: 0.5665\n",
      "Epoch 11/20 | Train Loss: 0.5821 | Val Loss: 0.5599\n",
      "Epoch 12/20 | Train Loss: 0.5804 | Val Loss: 0.5552\n",
      "Epoch 13/20 | Train Loss: 0.5808 | Val Loss: 0.5565\n",
      "Epoch 14/20 | Train Loss: 0.5791 | Val Loss: 0.5682\n",
      "Epoch 15/20 | Train Loss: 0.5785 | Val Loss: 0.5807\n",
      "Epoch 16/20 | Train Loss: 0.5488 | Val Loss: 0.5371\n",
      "Epoch 17/20 | Train Loss: 0.5449 | Val Loss: 0.5338\n",
      "Epoch 18/20 | Train Loss: 0.5439 | Val Loss: 0.5328\n",
      "Epoch 19/20 | Train Loss: 0.5435 | Val Loss: 0.5341\n",
      "Epoch 20/20 | Train Loss: 0.5432 | Val Loss: 0.5346\n",
      "Trial 1: lr=0.001, batch_size=16, num_epochs=20, val_loss=0.5346\n",
      "Epoch 1/20 | Train Loss: 0.6161 | Val Loss: 0.5705\n",
      "Epoch 2/20 | Train Loss: 0.5858 | Val Loss: 0.5583\n",
      "Epoch 3/20 | Train Loss: 0.5787 | Val Loss: 0.5576\n",
      "Epoch 4/20 | Train Loss: 0.5751 | Val Loss: 0.5504\n",
      "Epoch 5/20 | Train Loss: 0.5731 | Val Loss: 0.5461\n",
      "Epoch 6/20 | Train Loss: 0.5709 | Val Loss: 0.5666\n",
      "Epoch 7/20 | Train Loss: 0.5688 | Val Loss: 0.5498\n",
      "Epoch 8/20 | Train Loss: 0.5684 | Val Loss: 0.5536\n",
      "Epoch 9/20 | Train Loss: 0.5679 | Val Loss: 0.5502\n",
      "Epoch 10/20 | Train Loss: 0.5677 | Val Loss: 0.5465\n",
      "Epoch 11/20 | Train Loss: 0.5658 | Val Loss: 0.5487\n",
      "Epoch 12/20 | Train Loss: 0.5423 | Val Loss: 0.5298\n",
      "Epoch 13/20 | Train Loss: 0.5388 | Val Loss: 0.5341\n",
      "Epoch 14/20 | Train Loss: 0.5377 | Val Loss: 0.5283\n",
      "Epoch 15/20 | Train Loss: 0.5372 | Val Loss: 0.5316\n",
      "Epoch 16/20 | Train Loss: 0.5368 | Val Loss: 0.5288\n",
      "Epoch 17/20 | Train Loss: 0.5365 | Val Loss: 0.5322\n",
      "Epoch 18/20 | Train Loss: 0.5365 | Val Loss: 0.5335\n",
      "Epoch 19/20 | Train Loss: 0.5360 | Val Loss: 0.5293\n",
      "Epoch 20/20 | Train Loss: 0.5358 | Val Loss: 0.5335\n",
      "Trial 2: lr=0.001, batch_size=32, num_epochs=20, val_loss=0.5335\n",
      "Epoch 1/20 | Train Loss: 0.6180 | Val Loss: 0.5872\n",
      "Epoch 2/20 | Train Loss: 0.5864 | Val Loss: 0.5586\n",
      "Epoch 3/20 | Train Loss: 0.5786 | Val Loss: 0.5587\n",
      "Epoch 4/20 | Train Loss: 0.5749 | Val Loss: 0.5673\n",
      "Epoch 5/20 | Train Loss: 0.5721 | Val Loss: 0.5873\n",
      "Epoch 6/20 | Train Loss: 0.5698 | Val Loss: 0.5450\n",
      "Epoch 7/20 | Train Loss: 0.5697 | Val Loss: 0.5498\n",
      "Epoch 8/20 | Train Loss: 0.5686 | Val Loss: 0.5484\n",
      "Epoch 9/20 | Train Loss: 0.5680 | Val Loss: 0.5571\n",
      "Epoch 10/20 | Train Loss: 0.5671 | Val Loss: 0.5469\n",
      "Epoch 11/20 | Train Loss: 0.5663 | Val Loss: 0.5451\n",
      "Epoch 12/20 | Train Loss: 0.5656 | Val Loss: 0.5494\n",
      "Epoch 13/20 | Train Loss: 0.5430 | Val Loss: 0.5327\n",
      "Epoch 14/20 | Train Loss: 0.5399 | Val Loss: 0.5327\n",
      "Epoch 15/20 | Train Loss: 0.5391 | Val Loss: 0.5315\n",
      "Epoch 16/20 | Train Loss: 0.5386 | Val Loss: 0.5319\n",
      "Epoch 17/20 | Train Loss: 0.5382 | Val Loss: 0.5340\n",
      "Epoch 18/20 | Train Loss: 0.5380 | Val Loss: 0.5357\n",
      "Epoch 19/20 | Train Loss: 0.5377 | Val Loss: 0.5318\n",
      "Epoch 20/20 | Train Loss: 0.5375 | Val Loss: 0.5335\n",
      "Trial 3: lr=0.0005, batch_size=32, num_epochs=20, val_loss=0.5335\n",
      "Epoch 1/20 | Train Loss: 0.6096 | Val Loss: 0.5675\n",
      "Epoch 2/20 | Train Loss: 0.5809 | Val Loss: 0.5551\n",
      "Epoch 3/20 | Train Loss: 0.5734 | Val Loss: 0.5619\n",
      "Epoch 4/20 | Train Loss: 0.5686 | Val Loss: 0.5597\n",
      "Epoch 5/20 | Train Loss: 0.5658 | Val Loss: 0.5494\n",
      "Epoch 6/20 | Train Loss: 0.5639 | Val Loss: 0.5495\n",
      "Epoch 7/20 | Train Loss: 0.5616 | Val Loss: 0.5530\n",
      "Epoch 8/20 | Train Loss: 0.5607 | Val Loss: 0.5560\n",
      "Epoch 9/20 | Train Loss: 0.5602 | Val Loss: 0.5477\n",
      "Epoch 10/20 | Train Loss: 0.5588 | Val Loss: 0.5534\n",
      "Epoch 11/20 | Train Loss: 0.5580 | Val Loss: 0.5403\n",
      "Epoch 12/20 | Train Loss: 0.5570 | Val Loss: 0.5486\n",
      "Epoch 13/20 | Train Loss: 0.5570 | Val Loss: 0.5487\n",
      "Epoch 14/20 | Train Loss: 0.5558 | Val Loss: 0.5483\n",
      "Epoch 15/20 | Train Loss: 0.5564 | Val Loss: 0.5504\n",
      "Epoch 16/20 | Train Loss: 0.5553 | Val Loss: 0.5473\n",
      "Epoch 17/20 | Train Loss: 0.5554 | Val Loss: 0.5566\n",
      "Epoch 18/20 | Train Loss: 0.5355 | Val Loss: 0.5368\n",
      "Epoch 19/20 | Train Loss: 0.5328 | Val Loss: 0.5319\n",
      "Epoch 20/20 | Train Loss: 0.5320 | Val Loss: 0.5363\n",
      "Trial 4: lr=0.001, batch_size=64, num_epochs=20, val_loss=0.5363\n",
      "Epoch 1/20 | Train Loss: 0.6121 | Val Loss: 0.5657\n",
      "Epoch 2/20 | Train Loss: 0.5872 | Val Loss: 0.5705\n",
      "Epoch 3/20 | Train Loss: 0.5805 | Val Loss: 0.5544\n",
      "Epoch 4/20 | Train Loss: 0.5772 | Val Loss: 0.5591\n",
      "Epoch 5/20 | Train Loss: 0.5742 | Val Loss: 0.5879\n",
      "Epoch 6/20 | Train Loss: 0.5721 | Val Loss: 0.5533\n",
      "Epoch 7/20 | Train Loss: 0.5713 | Val Loss: 0.5570\n",
      "Epoch 8/20 | Train Loss: 0.5703 | Val Loss: 0.5518\n",
      "Epoch 9/20 | Train Loss: 0.5678 | Val Loss: 0.5475\n",
      "Epoch 10/20 | Train Loss: 0.5673 | Val Loss: 0.5445\n",
      "Epoch 11/20 | Train Loss: 0.5659 | Val Loss: 0.5561\n",
      "Epoch 12/20 | Train Loss: 0.5656 | Val Loss: 0.5498\n",
      "Epoch 13/20 | Train Loss: 0.5649 | Val Loss: 0.5604\n",
      "Epoch 14/20 | Train Loss: 0.5654 | Val Loss: 0.5482\n",
      "Epoch 15/20 | Train Loss: 0.5643 | Val Loss: 0.5617\n",
      "Epoch 16/20 | Train Loss: 0.5638 | Val Loss: 0.5593\n",
      "Epoch 17/20 | Train Loss: 0.5401 | Val Loss: 0.5335\n",
      "Epoch 18/20 | Train Loss: 0.5376 | Val Loss: 0.5310\n",
      "Epoch 19/20 | Train Loss: 0.5368 | Val Loss: 0.5338\n",
      "Epoch 20/20 | Train Loss: 0.5364 | Val Loss: 0.5296\n",
      "Trial 5: lr=0.001, batch_size=32, num_epochs=20, val_loss=0.5296\n",
      "Epoch 1/20 | Train Loss: 0.6138 | Val Loss: 0.5678\n",
      "Epoch 2/20 | Train Loss: 0.5886 | Val Loss: 0.5630\n",
      "Epoch 3/20 | Train Loss: 0.5819 | Val Loss: 0.5525\n",
      "Epoch 4/20 | Train Loss: 0.5786 | Val Loss: 0.5655\n",
      "Epoch 5/20 | Train Loss: 0.5764 | Val Loss: 0.5601\n",
      "Epoch 6/20 | Train Loss: 0.5745 | Val Loss: 0.5513\n",
      "Epoch 7/20 | Train Loss: 0.5733 | Val Loss: 0.5478\n",
      "Epoch 8/20 | Train Loss: 0.5726 | Val Loss: 0.5484\n",
      "Epoch 9/20 | Train Loss: 0.5711 | Val Loss: 0.5584\n",
      "Epoch 10/20 | Train Loss: 0.5714 | Val Loss: 0.5700\n",
      "Epoch 11/20 | Train Loss: 0.5699 | Val Loss: 0.5516\n",
      "Epoch 12/20 | Train Loss: 0.5685 | Val Loss: 0.5525\n",
      "Epoch 13/20 | Train Loss: 0.5676 | Val Loss: 0.5627\n",
      "Epoch 14/20 | Train Loss: 0.5454 | Val Loss: 0.5377\n",
      "Epoch 15/20 | Train Loss: 0.5425 | Val Loss: 0.5355\n",
      "Epoch 16/20 | Train Loss: 0.5419 | Val Loss: 0.5383\n",
      "Epoch 17/20 | Train Loss: 0.5412 | Val Loss: 0.5329\n",
      "Epoch 18/20 | Train Loss: 0.5410 | Val Loss: 0.5334\n",
      "Epoch 19/20 | Train Loss: 0.5406 | Val Loss: 0.5332\n",
      "Epoch 20/20 | Train Loss: 0.5404 | Val Loss: 0.5345\n",
      "Trial 6: lr=0.0005, batch_size=32, num_epochs=20, val_loss=0.5345\n",
      "Epoch 1/20 | Train Loss: 0.6110 | Val Loss: 0.5636\n",
      "Epoch 2/20 | Train Loss: 0.5814 | Val Loss: 0.5597\n",
      "Epoch 3/20 | Train Loss: 0.5742 | Val Loss: 0.5647\n",
      "Epoch 4/20 | Train Loss: 0.5691 | Val Loss: 0.5619\n",
      "Epoch 5/20 | Train Loss: 0.5658 | Val Loss: 0.5503\n",
      "Epoch 6/20 | Train Loss: 0.5638 | Val Loss: 0.5512\n",
      "Epoch 7/20 | Train Loss: 0.5623 | Val Loss: 0.5621\n",
      "Epoch 8/20 | Train Loss: 0.5611 | Val Loss: 0.5521\n",
      "Epoch 9/20 | Train Loss: 0.5595 | Val Loss: 0.5529\n",
      "Epoch 10/20 | Train Loss: 0.5595 | Val Loss: 0.5526\n",
      "Epoch 11/20 | Train Loss: 0.5582 | Val Loss: 0.5443\n",
      "Epoch 12/20 | Train Loss: 0.5577 | Val Loss: 0.5439\n",
      "Epoch 13/20 | Train Loss: 0.5571 | Val Loss: 0.5541\n",
      "Epoch 14/20 | Train Loss: 0.5571 | Val Loss: 0.5489\n",
      "Epoch 15/20 | Train Loss: 0.5571 | Val Loss: 0.5509\n",
      "Epoch 16/20 | Train Loss: 0.5558 | Val Loss: 0.5566\n",
      "Epoch 17/20 | Train Loss: 0.5552 | Val Loss: 0.5534\n",
      "Epoch 18/20 | Train Loss: 0.5551 | Val Loss: 0.5424\n",
      "Epoch 19/20 | Train Loss: 0.5548 | Val Loss: 0.5437\n",
      "Epoch 20/20 | Train Loss: 0.5541 | Val Loss: 0.5654\n",
      "Trial 7: lr=0.0005, batch_size=64, num_epochs=20, val_loss=0.5654\n",
      "Epoch 1/20 | Train Loss: 0.6253 | Val Loss: 0.5637\n",
      "Epoch 2/20 | Train Loss: 0.5960 | Val Loss: 0.5652\n",
      "Epoch 3/20 | Train Loss: 0.5908 | Val Loss: 0.6147\n",
      "Epoch 4/20 | Train Loss: 0.5868 | Val Loss: 0.5646\n",
      "Epoch 5/20 | Train Loss: 0.5846 | Val Loss: 0.5763\n",
      "Epoch 6/20 | Train Loss: 0.5823 | Val Loss: 0.5525\n",
      "Epoch 7/20 | Train Loss: 0.5816 | Val Loss: 0.5590\n",
      "Epoch 8/20 | Train Loss: 0.5810 | Val Loss: 0.5719\n",
      "Epoch 9/20 | Train Loss: 0.5801 | Val Loss: 0.5722\n",
      "Epoch 10/20 | Train Loss: 0.5785 | Val Loss: 0.5564\n",
      "Epoch 11/20 | Train Loss: 0.5778 | Val Loss: 0.5844\n",
      "Epoch 12/20 | Train Loss: 0.5770 | Val Loss: 0.5765\n",
      "Epoch 13/20 | Train Loss: 0.5467 | Val Loss: 0.5351\n",
      "Epoch 14/20 | Train Loss: 0.5432 | Val Loss: 0.5367\n",
      "Epoch 15/20 | Train Loss: 0.5424 | Val Loss: 0.5366\n",
      "Epoch 16/20 | Train Loss: 0.5417 | Val Loss: 0.5361\n",
      "Epoch 17/20 | Train Loss: 0.5414 | Val Loss: 0.5363\n",
      "Epoch 18/20 | Train Loss: 0.5411 | Val Loss: 0.5327\n",
      "Epoch 19/20 | Train Loss: 0.5409 | Val Loss: 0.5329\n",
      "Epoch 20/20 | Train Loss: 0.5407 | Val Loss: 0.5346\n",
      "Trial 8: lr=0.001, batch_size=16, num_epochs=20, val_loss=0.5346\n",
      "Epoch 1/20 | Train Loss: 0.6247 | Val Loss: 0.5887\n",
      "Epoch 2/20 | Train Loss: 0.5986 | Val Loss: 0.5669\n",
      "Epoch 3/20 | Train Loss: 0.5925 | Val Loss: 0.5722\n",
      "Epoch 4/20 | Train Loss: 0.5886 | Val Loss: 0.5591\n",
      "Epoch 5/20 | Train Loss: 0.5866 | Val Loss: 0.5709\n",
      "Epoch 6/20 | Train Loss: 0.5857 | Val Loss: 0.6164\n",
      "Epoch 7/20 | Train Loss: 0.5834 | Val Loss: 0.5645\n",
      "Epoch 8/20 | Train Loss: 0.5815 | Val Loss: 0.5595\n",
      "Epoch 9/20 | Train Loss: 0.5814 | Val Loss: 0.5667\n",
      "Epoch 10/20 | Train Loss: 0.5802 | Val Loss: 0.5518\n",
      "Epoch 11/20 | Train Loss: 0.5817 | Val Loss: 0.5539\n",
      "Epoch 12/20 | Train Loss: 0.5800 | Val Loss: 0.5688\n",
      "Epoch 13/20 | Train Loss: 0.5788 | Val Loss: 0.5479\n",
      "Epoch 14/20 | Train Loss: 0.5790 | Val Loss: 0.5505\n",
      "Epoch 15/20 | Train Loss: 0.5786 | Val Loss: 0.5569\n",
      "Epoch 16/20 | Train Loss: 0.5781 | Val Loss: 0.5855\n",
      "Epoch 17/20 | Train Loss: 0.5788 | Val Loss: 0.5842\n",
      "Epoch 18/20 | Train Loss: 0.5767 | Val Loss: 0.5640\n",
      "Epoch 19/20 | Train Loss: 0.5774 | Val Loss: 0.5692\n",
      "Epoch 20/20 | Train Loss: 0.5472 | Val Loss: 0.5358\n",
      "Trial 9: lr=0.0005, batch_size=16, num_epochs=20, val_loss=0.5358\n",
      "Epoch 1/20 | Train Loss: 0.6208 | Val Loss: 0.5790\n",
      "Epoch 2/20 | Train Loss: 0.5869 | Val Loss: 0.5635\n",
      "Epoch 3/20 | Train Loss: 0.5807 | Val Loss: 0.5580\n",
      "Epoch 4/20 | Train Loss: 0.5766 | Val Loss: 0.5511\n",
      "Epoch 5/20 | Train Loss: 0.5734 | Val Loss: 0.5606\n",
      "Epoch 6/20 | Train Loss: 0.5720 | Val Loss: 0.5648\n",
      "Epoch 7/20 | Train Loss: 0.5709 | Val Loss: 0.5526\n",
      "Epoch 8/20 | Train Loss: 0.5705 | Val Loss: 0.5473\n",
      "Epoch 9/20 | Train Loss: 0.5690 | Val Loss: 0.5626\n",
      "Epoch 10/20 | Train Loss: 0.5684 | Val Loss: 0.5520\n",
      "Epoch 11/20 | Train Loss: 0.5674 | Val Loss: 0.5549\n",
      "Epoch 12/20 | Train Loss: 0.5678 | Val Loss: 0.5470\n",
      "Epoch 13/20 | Train Loss: 0.5670 | Val Loss: 0.5534\n",
      "Epoch 14/20 | Train Loss: 0.5669 | Val Loss: 0.5618\n",
      "Epoch 15/20 | Train Loss: 0.5656 | Val Loss: 0.5481\n",
      "Epoch 16/20 | Train Loss: 0.5646 | Val Loss: 0.5429\n",
      "Epoch 17/20 | Train Loss: 0.5637 | Val Loss: 0.5635\n",
      "Epoch 18/20 | Train Loss: 0.5642 | Val Loss: 0.5429\n",
      "Epoch 19/20 | Train Loss: 0.5631 | Val Loss: 0.5476\n",
      "Epoch 20/20 | Train Loss: 0.5629 | Val Loss: 0.5541\n",
      "Trial 10: lr=0.001, batch_size=32, num_epochs=20, val_loss=0.5541\n",
      "Best hyperparameters: {'lr': 0.001, 'batch_size': 32, 'num_epochs': 20}\n",
      "Best validation loss: 0.529636619832776\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Best Hyperparameters when predictand = both:\n",
    "Best hyperparameters: {'lr': 5e-05, 'batch_size': 64, 'num_epochs': 10}\n",
    "Best validation loss: 0.3247509590034411\n",
    "\n"
   ],
   "id": "786ecf52debf133d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Model Evaluation:",
   "id": "2de8f68ac000e0a5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T14:47:47.538036Z",
     "start_time": "2025-05-22T14:47:47.484118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(model, X_test_tensor, y_test):\n",
    "    \"\"\"Generate predictions and calculate metrics\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_tensor = model(X_test_tensor)\n",
    "\n",
    "    # Convert to numpy for sklearn metrics\n",
    "    y_pred = y_pred_tensor.numpy()\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)  # Method #2 from search results\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Display metrics\n",
    "    print(\"\\nFinal Model Evaluation:\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")  # Added from search result [1][2]\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"R: {r2:.4f}\")\n",
    "\n",
    "    return y_pred"
   ],
   "id": "8fb2ae85b752b57c",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Visualisation",
   "id": "d434549c427ddb89"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T14:47:49.951675Z",
     "start_time": "2025-05-22T14:47:49.903577Z"
    }
   },
   "cell_type": "code",
   "source": [
    " def plot_loss_curves(train_losses, val_losses):\n",
    "    \"\"\"Plot training and validation loss curves\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.title(f'Loss Curves when predictands = {predictands}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MSE Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ],
   "id": "80aff5cd849a7ca8",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Execution",
   "id": "1f6a550e4a0d52bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T14:47:52.199606Z",
     "start_time": "2025-05-22T14:47:51.812710Z"
    }
   },
   "cell_type": "code",
   "source": [
    " #Visualize training progress\n",
    "plot_loss_curves(train_losses=train_losses, val_losses=val_losses)\n",
    "\n",
    "# Final evaluation\n",
    "evaluate_model(model=model, X_test_tensor=X_test_tensor, y_test=y_test)\n",
    "#y_pred = evaluate_model(model, X_test_tensor, y_test)"
   ],
   "id": "6211a66b46e6c7b3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Model Evaluation:\n",
      "MSE: 0.0409\n",
      "RMSE: 0.2021\n",
      "MAE: 0.1556\n",
      "R: 0.4154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9294296 , 0.19028214],\n",
       "       [0.92506003, 0.17991763],\n",
       "       [0.8467846 , 0.17842083],\n",
       "       ...,\n",
       "       [0.70963424, 0.42032397],\n",
       "       [0.7418136 , 0.4298802 ],\n",
       "       [0.35272008, 0.20174925]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T14:58:20.614138Z",
     "start_time": "2025-05-22T14:58:19.074835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def feature_importance(model, X, y, metric, n_repeats=5):\n",
    "    baseline_score = metric(y, model(X).detach().numpy())\n",
    "    importances = np.zeros(X.shape[1])\n",
    "\n",
    "    for col in range(X.shape[1]):\n",
    "        scores = []\n",
    "        for _ in range(n_repeats):\n",
    "            X_permuted = X.clone()\n",
    "            idx = torch.randperm(X.shape[0])\n",
    "            X_permuted[:, col] = X_permuted[idx, col]\n",
    "            score = metric(y, model(X_permuted).detach().numpy())\n",
    "            scores.append(score)\n",
    "        importances[col] = np.mean(scores) - baseline_score\n",
    "    return importances\n",
    "\n",
    "# Usage:\n",
    "model.eval()\n",
    "importances = feature_importance(\n",
    "    model, X_test_tensor, y_test.values, mean_squared_error\n",
    ")\n",
    "for i, imp in enumerate(importances):\n",
    "    print(f\"{i} {predictors[i]}: Significance {imp:.4f}\")"
   ],
   "id": "d2f55f0bf48a76e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 blh: Significance 0.0080\n",
      "1 cape: Significance 0.0022\n",
      "2 mlspf: Significance 0.0039\n",
      "3 mslhf: Significance 0.0021\n",
      "4 msshf: Significance 0.0047\n",
      "5 q700: Significance 0.0156\n",
      "6 q850: Significance 0.0167\n",
      "7 rh700: Significance 0.0083\n",
      "8 rh850: Significance 0.0381\n",
      "9 sst: Significance 0.0104\n",
      "10 t700: Significance 0.0031\n",
      "11 t850: Significance 0.0273\n",
      "12 tcwv: Significance 0.0119\n",
      "13 u10: Significance 0.0016\n",
      "14 u700: Significance 0.0010\n",
      "15 u850: Significance 0.0028\n",
      "16 v10: Significance 0.0015\n",
      "17 v700: Significance 0.0003\n",
      "18 v850: Significance 0.0013\n",
      "19 w700: Significance 0.0000\n",
      "20 w850: Significance 0.0005\n",
      "21 Terra_descending: Significance 0.0013\n",
      "22 lsm: Significance 0.0002\n",
      "23 eis: Significance 0.0201\n",
      "24 lnNd: Significance 0.0205\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T15:40:24.638940Z",
     "start_time": "2025-05-22T15:32:49.672643Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b42cfac2ac7254e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 blh: SHAP Importance 0.0446\n",
      "1 cape: SHAP Importance 0.0237\n"
     ]
    }
   ],
   "execution_count": 23
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
