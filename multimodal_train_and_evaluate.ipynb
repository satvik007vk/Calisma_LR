{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T15:20:09.152194Z",
     "start_time": "2025-04-18T15:20:09.095179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#auto reload jupyter to update notebook w.r.t changes in other linked files:\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "237aafff1d2b17c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T15:20:10.613476Z",
     "start_time": "2025-04-18T15:20:10.559026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "#from xgboost.testing import root_mean_square\n",
    "\n",
    "from train_and_evaluate import load_train_test_data\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np"
   ],
   "id": "566940c48a21383a",
   "outputs": [],
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-18T15:20:16.071207Z",
     "start_time": "2025-04-18T15:20:12.583168Z"
    }
   },
   "source": [
    "#Define the predictand\n",
    "predictand = 'both'\n",
    "df_train, df_test, X_train, y_train, X_test, y_test, predictors, predictands = load_train_test_data(predictand=predictand)\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "\n",
    "# Convert pandas DataFrames to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "print(f'train_loader: {train_loader} \\n test_loader: {test_loader}' )\n",
    "print(f'size of train_loader: {len(train_loader)} \\n size of test_loader: {len(test_loader)}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and test data loaded successfully! Missing values dropped.\n",
      "X_train shape: (211871, 25), y_train shape: (211871, 2)\n",
      "train_loader: <torch.utils.data.dataloader.DataLoader object at 0x7991a7f97d10> \n",
      " test_loader: <torch.utils.data.dataloader.DataLoader object at 0x7991a7dd7c10>\n",
      "size of train_loader: 6621 \n",
      " size of test_loader: 1438\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Neural Network Architecture",
   "id": "d88511ecfee38825"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T15:20:28.590977Z",
     "start_time": "2025-04-18T15:20:28.539628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MultiTargetRegressor(nn.Module):\n",
    "    \"\"\"Neural network for multi-target regression\"\"\"\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            # Input layer to first hidden layer\n",
    "            nn.Linear(input_size, 16),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # First hidden layer to second hidden layer\n",
    "            nn.Linear(16, 10),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Second hidden layer to output layer\n",
    "            nn.Linear(10, output_size)\n",
    "        )\n",
    "\n",
    "        # Initialize weights using Kaiming He initialization for ReLU\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.kaiming_normal_(layer.weight, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Defines forward pass through network\"\"\"\n",
    "        return self.layers(x)"
   ],
   "id": "35a96a4f455b96e8",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T15:20:32.442023Z",
     "start_time": "2025-04-18T15:20:32.396939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_model_structure(model, input_size, output_size):\n",
    "    neuron_counts = [input_size]  # Start with input size\n",
    "    linear_layers = []\n",
    "\n",
    "    # Collect neuron counts for each nn.Linear layer\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            neuron_counts.append(layer.out_features)\n",
    "            linear_layers.append(layer)\n",
    "\n",
    "    # Print neurons per layer\n",
    "    print(\"Model Structure:\")\n",
    "    print(f\"Input layer: {neuron_counts[0]} neurons\")\n",
    "    for i, n in enumerate(neuron_counts[1:-1], 1):\n",
    "        print(f\"Hidden layer {i}: {n} neurons\")\n",
    "    print(f\"Output layer: {neuron_counts[-1]} neurons\")\n",
    "\n",
    "    # Print total neurons (excluding input layer if you want only trainable neurons)\n",
    "    total_neurons = sum(neuron_counts)\n",
    "    print(f\"\\nTotal number of neurons (including input and output): {total_neurons}\")\n",
    "\n",
    "    # Print number of layers\n",
    "    print(f\"Number of layers (Linear): {len(linear_layers)}\")\n",
    "    print(f\"Number of hidden layers: {len(linear_layers) - 1}\")\n",
    "\n",
    "# Example usage:\n",
    "input_size = X_train.shape[1]\n",
    "output_size = y_train.shape[1]\n",
    "model = MultiTargetRegressor(input_size, output_size)\n",
    "print_model_structure(model, input_size, output_size)\n"
   ],
   "id": "46db43ce6555fda3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:\n",
      "Input layer: 25 neurons\n",
      "Hidden layer 1: 16 neurons\n",
      "Hidden layer 2: 10 neurons\n",
      "Output layer: 2 neurons\n",
      "\n",
      "Total number of neurons (including input and output): 53\n",
      "Number of layers (Linear): 3\n",
      "Number of hidden layers: 2\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T09:39:31.595221Z",
     "start_time": "2025-04-18T09:39:31.529726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Install torchviz if not already installed\n",
    "# !pip install torchviz\n",
    "\n",
    "from torchviz import make_dot\n",
    "import torch\n",
    "\n",
    "def visualize_model(model, input_size):\n",
    "    # Create a dummy input tensor with the correct shape\n",
    "    x = torch.randn(1, input_size, requires_grad=True)\n",
    "    y = model(x)\n",
    "    # Create a visualization of the computation graph\n",
    "    dot = make_dot(y, params=dict(model.named_parameters()))\n",
    "    return dot\n",
    "\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "output_size = y_train.shape[1]\n",
    "model = MultiTargetRegressor(input_size, output_size)\n",
    "\n",
    "# Example usage:\n",
    "dot = visualize_model(model, input_size)\n",
    "#dot.render(\"model_architecture\", format=\"png\")  # Saves to file\n",
    "dot  # Display in Jupyter notebook\n"
   ],
   "id": "5429251d06e4a232",
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"494pt\" height=\"546pt\"\n viewBox=\"0.00 0.00 494.00 546.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 542)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-542 490,-542 490,4 -4,4\"/>\n<!-- 133666178879504 -->\n<g id=\"node1\" class=\"node\">\n<title>133666178879504</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"272,-31 213,-31 213,0 272,0 272,-31\"/>\n<text text-anchor=\"middle\" x=\"242.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> (1, 2)</text>\n</g>\n<!-- 133666164560112 -->\n<g id=\"node2\" class=\"node\">\n<title>133666164560112</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"293,-86 192,-86 192,-67 293,-67 293,-86\"/>\n<text text-anchor=\"middle\" x=\"242.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n</g>\n<!-- 133666164560112&#45;&gt;133666178879504 -->\n<g id=\"edge22\" class=\"edge\">\n<title>133666164560112&#45;&gt;133666178879504</title>\n<path fill=\"none\" stroke=\"black\" d=\"M242.5,-66.79C242.5,-60.07 242.5,-50.4 242.5,-41.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"246,-41.19 242.5,-31.19 239,-41.19 246,-41.19\"/>\n</g>\n<!-- 133666209494880 -->\n<g id=\"node3\" class=\"node\">\n<title>133666209494880</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"177,-141 76,-141 76,-122 177,-122 177,-141\"/>\n<text text-anchor=\"middle\" x=\"126.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 133666209494880&#45;&gt;133666164560112 -->\n<g id=\"edge1\" class=\"edge\">\n<title>133666209494880&#45;&gt;133666164560112</title>\n<path fill=\"none\" stroke=\"black\" d=\"M145.14,-121.98C163.8,-113.46 192.75,-100.23 214.24,-90.41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"215.88,-93.51 223.52,-86.17 212.97,-87.14 215.88,-93.51\"/>\n</g>\n<!-- 133666585709552 -->\n<g id=\"node4\" class=\"node\">\n<title>133666585709552</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"174,-207 79,-207 79,-177 174,-177 174,-207\"/>\n<text text-anchor=\"middle\" x=\"126.5\" y=\"-195\" font-family=\"monospace\" font-size=\"10.00\">layers.4.bias</text>\n<text text-anchor=\"middle\" x=\"126.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\"> (2)</text>\n</g>\n<!-- 133666585709552&#45;&gt;133666209494880 -->\n<g id=\"edge2\" class=\"edge\">\n<title>133666585709552&#45;&gt;133666209494880</title>\n<path fill=\"none\" stroke=\"black\" d=\"M126.5,-176.84C126.5,-169.21 126.5,-159.7 126.5,-151.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"130,-151.27 126.5,-141.27 123,-151.27 130,-151.27\"/>\n</g>\n<!-- 133666209496704 -->\n<g id=\"node5\" class=\"node\">\n<title>133666209496704</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"290,-141 195,-141 195,-122 290,-122 290,-141\"/>\n<text text-anchor=\"middle\" x=\"242.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">ReluBackward0</text>\n</g>\n<!-- 133666209496704&#45;&gt;133666164560112 -->\n<g id=\"edge3\" class=\"edge\">\n<title>133666209496704&#45;&gt;133666164560112</title>\n<path fill=\"none\" stroke=\"black\" d=\"M242.5,-121.75C242.5,-114.8 242.5,-104.85 242.5,-96.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"246,-96.09 242.5,-86.09 239,-96.09 246,-96.09\"/>\n</g>\n<!-- 133666209493392 -->\n<g id=\"node6\" class=\"node\">\n<title>133666209493392</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"293,-201.5 192,-201.5 192,-182.5 293,-182.5 293,-201.5\"/>\n<text text-anchor=\"middle\" x=\"242.5\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n</g>\n<!-- 133666209493392&#45;&gt;133666209496704 -->\n<g id=\"edge4\" class=\"edge\">\n<title>133666209493392&#45;&gt;133666209496704</title>\n<path fill=\"none\" stroke=\"black\" d=\"M242.5,-182.37C242.5,-174.25 242.5,-161.81 242.5,-151.39\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"246,-151.17 242.5,-141.17 239,-151.17 246,-151.17\"/>\n</g>\n<!-- 133666209493008 -->\n<g id=\"node7\" class=\"node\">\n<title>133666209493008</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"153,-267.5 52,-267.5 52,-248.5 153,-248.5 153,-267.5\"/>\n<text text-anchor=\"middle\" x=\"102.5\" y=\"-255.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 133666209493008&#45;&gt;133666209493392 -->\n<g id=\"edge5\" class=\"edge\">\n<title>133666209493008&#45;&gt;133666209493392</title>\n<path fill=\"none\" stroke=\"black\" d=\"M121.38,-248.37C145.28,-237.44 186.67,-218.52 214.32,-205.88\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"215.83,-209.04 223.47,-201.7 212.92,-202.67 215.83,-209.04\"/>\n</g>\n<!-- 133666585708880 -->\n<g id=\"node8\" class=\"node\">\n<title>133666585708880</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"150,-339 55,-339 55,-309 150,-309 150,-339\"/>\n<text text-anchor=\"middle\" x=\"102.5\" y=\"-327\" font-family=\"monospace\" font-size=\"10.00\">layers.2.bias</text>\n<text text-anchor=\"middle\" x=\"102.5\" y=\"-316\" font-family=\"monospace\" font-size=\"10.00\"> (64)</text>\n</g>\n<!-- 133666585708880&#45;&gt;133666209493008 -->\n<g id=\"edge6\" class=\"edge\">\n<title>133666585708880&#45;&gt;133666209493008</title>\n<path fill=\"none\" stroke=\"black\" d=\"M102.5,-308.8C102.5,-299.7 102.5,-287.79 102.5,-277.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"106,-277.84 102.5,-267.84 99,-277.84 106,-277.84\"/>\n</g>\n<!-- 133666209495888 -->\n<g id=\"node9\" class=\"node\">\n<title>133666209495888</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"266,-267.5 171,-267.5 171,-248.5 266,-248.5 266,-267.5\"/>\n<text text-anchor=\"middle\" x=\"218.5\" y=\"-255.5\" font-family=\"monospace\" font-size=\"10.00\">ReluBackward0</text>\n</g>\n<!-- 133666209495888&#45;&gt;133666209493392 -->\n<g id=\"edge7\" class=\"edge\">\n<title>133666209495888&#45;&gt;133666209493392</title>\n<path fill=\"none\" stroke=\"black\" d=\"M221.74,-248.37C225.26,-238.97 231,-223.67 235.55,-211.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"238.93,-212.5 239.16,-201.91 232.37,-210.04 238.93,-212.5\"/>\n</g>\n<!-- 133666165292288 -->\n<g id=\"node10\" class=\"node\">\n<title>133666165292288</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"269,-333.5 168,-333.5 168,-314.5 269,-314.5 269,-333.5\"/>\n<text text-anchor=\"middle\" x=\"218.5\" y=\"-321.5\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n</g>\n<!-- 133666165292288&#45;&gt;133666209495888 -->\n<g id=\"edge8\" class=\"edge\">\n<title>133666165292288&#45;&gt;133666209495888</title>\n<path fill=\"none\" stroke=\"black\" d=\"M218.5,-314.37C218.5,-305.16 218.5,-290.29 218.5,-278.27\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"222,-277.91 218.5,-267.91 215,-277.91 222,-277.91\"/>\n</g>\n<!-- 133666165291376 -->\n<g id=\"node11\" class=\"node\">\n<title>133666165291376</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-399.5 0,-399.5 0,-380.5 101,-380.5 101,-399.5\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-387.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 133666165291376&#45;&gt;133666165292288 -->\n<g id=\"edge9\" class=\"edge\">\n<title>133666165291376&#45;&gt;133666165292288</title>\n<path fill=\"none\" stroke=\"black\" d=\"M73.16,-380.37C102.3,-369.27 153.09,-349.92 186.25,-337.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"187.84,-340.43 195.93,-333.6 185.34,-333.89 187.84,-340.43\"/>\n</g>\n<!-- 133666585716272 -->\n<g id=\"node12\" class=\"node\">\n<title>133666585716272</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"98,-471.5 3,-471.5 3,-441.5 98,-441.5 98,-471.5\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-459.5\" font-family=\"monospace\" font-size=\"10.00\">layers.0.bias</text>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-448.5\" font-family=\"monospace\" font-size=\"10.00\"> (128)</text>\n</g>\n<!-- 133666585716272&#45;&gt;133666165291376 -->\n<g id=\"edge10\" class=\"edge\">\n<title>133666585716272&#45;&gt;133666165291376</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-441.19C50.5,-431.91 50.5,-419.73 50.5,-409.69\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-409.54 50.5,-399.54 47,-409.54 54,-409.54\"/>\n</g>\n<!-- 133666165286528 -->\n<g id=\"node13\" class=\"node\">\n<title>133666165286528</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"220,-399.5 119,-399.5 119,-380.5 220,-380.5 220,-399.5\"/>\n<text text-anchor=\"middle\" x=\"169.5\" y=\"-387.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 133666165286528&#45;&gt;133666165292288 -->\n<g id=\"edge11\" class=\"edge\">\n<title>133666165286528&#45;&gt;133666165292288</title>\n<path fill=\"none\" stroke=\"black\" d=\"M176.11,-380.37C183.59,-370.59 195.97,-354.42 205.43,-342.08\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"208.38,-343.97 211.68,-333.91 202.82,-339.72 208.38,-343.97\"/>\n</g>\n<!-- 133666178876144 -->\n<g id=\"node14\" class=\"node\">\n<title>133666178876144</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"202,-472 137,-472 137,-441 202,-441 202,-472\"/>\n<text text-anchor=\"middle\" x=\"169.5\" y=\"-448\" font-family=\"monospace\" font-size=\"10.00\"> (1, 25)</text>\n</g>\n<!-- 133666178876144&#45;&gt;133666165286528 -->\n<g id=\"edge12\" class=\"edge\">\n<title>133666178876144&#45;&gt;133666165286528</title>\n<path fill=\"none\" stroke=\"black\" d=\"M169.5,-440.86C169.5,-431.68 169.5,-419.75 169.5,-409.86\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"173,-409.82 169.5,-399.82 166,-409.82 173,-409.82\"/>\n</g>\n<!-- 133666165284512 -->\n<g id=\"node15\" class=\"node\">\n<title>133666165284512</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"315,-399.5 238,-399.5 238,-380.5 315,-380.5 315,-399.5\"/>\n<text text-anchor=\"middle\" x=\"276.5\" y=\"-387.5\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n</g>\n<!-- 133666165284512&#45;&gt;133666165292288 -->\n<g id=\"edge13\" class=\"edge\">\n<title>133666165284512&#45;&gt;133666165292288</title>\n<path fill=\"none\" stroke=\"black\" d=\"M268.68,-380.37C259.65,-370.4 244.59,-353.79 233.33,-341.36\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"235.88,-338.96 226.57,-333.91 230.69,-343.67 235.88,-338.96\"/>\n</g>\n<!-- 133666165284032 -->\n<g id=\"node16\" class=\"node\">\n<title>133666165284032</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"327,-466 226,-466 226,-447 327,-447 327,-466\"/>\n<text text-anchor=\"middle\" x=\"276.5\" y=\"-454\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 133666165284032&#45;&gt;133666165284512 -->\n<g id=\"edge14\" class=\"edge\">\n<title>133666165284032&#45;&gt;133666165284512</title>\n<path fill=\"none\" stroke=\"black\" d=\"M276.5,-446.8C276.5,-437.32 276.5,-421.88 276.5,-409.64\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"280,-409.56 276.5,-399.56 273,-409.56 280,-409.56\"/>\n</g>\n<!-- 133666585708496 -->\n<g id=\"node17\" class=\"node\">\n<title>133666585708496</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"330,-538 223,-538 223,-508 330,-508 330,-538\"/>\n<text text-anchor=\"middle\" x=\"276.5\" y=\"-526\" font-family=\"monospace\" font-size=\"10.00\">layers.0.weight</text>\n<text text-anchor=\"middle\" x=\"276.5\" y=\"-515\" font-family=\"monospace\" font-size=\"10.00\"> (128, 25)</text>\n</g>\n<!-- 133666585708496&#45;&gt;133666165284032 -->\n<g id=\"edge15\" class=\"edge\">\n<title>133666585708496&#45;&gt;133666165284032</title>\n<path fill=\"none\" stroke=\"black\" d=\"M276.5,-507.69C276.5,-498.41 276.5,-486.23 276.5,-476.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"280,-476.04 276.5,-466.04 273,-476.04 280,-476.04\"/>\n</g>\n<!-- 133666209496848 -->\n<g id=\"node18\" class=\"node\">\n<title>133666209496848</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"361,-267.5 284,-267.5 284,-248.5 361,-248.5 361,-267.5\"/>\n<text text-anchor=\"middle\" x=\"322.5\" y=\"-255.5\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n</g>\n<!-- 133666209496848&#45;&gt;133666209493392 -->\n<g id=\"edge16\" class=\"edge\">\n<title>133666209496848&#45;&gt;133666209493392</title>\n<path fill=\"none\" stroke=\"black\" d=\"M311.71,-248.37C298.83,-238.06 277.06,-220.65 261.37,-208.09\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"263.37,-205.21 253.37,-201.7 259,-210.68 263.37,-205.21\"/>\n</g>\n<!-- 133666165291856 -->\n<g id=\"node19\" class=\"node\">\n<title>133666165291856</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"412,-333.5 311,-333.5 311,-314.5 412,-314.5 412,-333.5\"/>\n<text text-anchor=\"middle\" x=\"361.5\" y=\"-321.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 133666165291856&#45;&gt;133666209496848 -->\n<g id=\"edge17\" class=\"edge\">\n<title>133666165291856&#45;&gt;133666209496848</title>\n<path fill=\"none\" stroke=\"black\" d=\"M356.24,-314.37C350.4,-304.78 340.81,-289.05 333.35,-276.8\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"336.12,-274.62 327.93,-267.91 330.14,-278.27 336.12,-274.62\"/>\n</g>\n<!-- 133666795643696 -->\n<g id=\"node20\" class=\"node\">\n<title>133666795643696</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"440,-405 333,-405 333,-375 440,-375 440,-405\"/>\n<text text-anchor=\"middle\" x=\"386.5\" y=\"-393\" font-family=\"monospace\" font-size=\"10.00\">layers.2.weight</text>\n<text text-anchor=\"middle\" x=\"386.5\" y=\"-382\" font-family=\"monospace\" font-size=\"10.00\"> (64, 128)</text>\n</g>\n<!-- 133666795643696&#45;&gt;133666165291856 -->\n<g id=\"edge18\" class=\"edge\">\n<title>133666795643696&#45;&gt;133666165291856</title>\n<path fill=\"none\" stroke=\"black\" d=\"M380.95,-374.8C377.32,-365.5 372.54,-353.27 368.63,-343.26\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"371.85,-341.89 364.95,-333.84 365.33,-344.43 371.85,-341.89\"/>\n</g>\n<!-- 133666209493776 -->\n<g id=\"node21\" class=\"node\">\n<title>133666209493776</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"416,-141 339,-141 339,-122 416,-122 416,-141\"/>\n<text text-anchor=\"middle\" x=\"377.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n</g>\n<!-- 133666209493776&#45;&gt;133666164560112 -->\n<g id=\"edge19\" class=\"edge\">\n<title>133666209493776&#45;&gt;133666164560112</title>\n<path fill=\"none\" stroke=\"black\" d=\"M355.81,-121.98C333.7,-113.3 299.18,-99.75 274.05,-89.88\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"275.17,-86.57 264.58,-86.17 272.61,-93.08 275.17,-86.57\"/>\n</g>\n<!-- 133666209495936 -->\n<g id=\"node22\" class=\"node\">\n<title>133666209495936</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"459,-201.5 358,-201.5 358,-182.5 459,-182.5 459,-201.5\"/>\n<text text-anchor=\"middle\" x=\"408.5\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 133666209495936&#45;&gt;133666209493776 -->\n<g id=\"edge20\" class=\"edge\">\n<title>133666209495936&#45;&gt;133666209493776</title>\n<path fill=\"none\" stroke=\"black\" d=\"M403.93,-182.37C399.44,-173.9 392.47,-160.74 386.81,-150.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"389.87,-148.36 382.09,-141.17 383.68,-151.64 389.87,-148.36\"/>\n</g>\n<!-- 133666585709360 -->\n<g id=\"node23\" class=\"node\">\n<title>133666585709360</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"486,-273 379,-273 379,-243 486,-243 486,-273\"/>\n<text text-anchor=\"middle\" x=\"432.5\" y=\"-261\" font-family=\"monospace\" font-size=\"10.00\">layers.4.weight</text>\n<text text-anchor=\"middle\" x=\"432.5\" y=\"-250\" font-family=\"monospace\" font-size=\"10.00\"> (2, 64)</text>\n</g>\n<!-- 133666585709360&#45;&gt;133666209495936 -->\n<g id=\"edge21\" class=\"edge\">\n<title>133666585709360&#45;&gt;133666209495936</title>\n<path fill=\"none\" stroke=\"black\" d=\"M427.17,-242.8C423.69,-233.5 419.1,-221.27 415.35,-211.26\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"418.61,-209.98 411.82,-201.84 412.05,-212.44 418.61,-209.98\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7991951af350>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T09:39:40.134154Z",
     "start_time": "2025-04-18T09:39:40.122253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# If not installed, uncomment the next line:\n",
    "# !pip install torchsummary\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "def visualize_model_summary(model, input_size):\n",
    "    # input_size should be a tuple without batch size, e.g. (number_of_features,)\n",
    "    summary(model, input_size)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "input_size = X_train.shape[1]\n",
    "output_size = y_train.shape[1]\n",
    "model = MultiTargetRegressor(input_size, output_size)\n",
    "\n",
    "visualize_model_summary(model, input_size=(X_train.shape[1],))\n"
   ],
   "id": "b3cde278ae0feeb0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 128]           3,328\n",
      "              ReLU-2                  [-1, 128]               0\n",
      "            Linear-3                   [-1, 64]           8,256\n",
      "              ReLU-4                   [-1, 64]               0\n",
      "            Linear-5                    [-1, 2]             130\n",
      "================================================================\n",
      "Total params: 11,714\n",
      "Trainable params: 11,714\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.04\n",
      "Estimated Total Size (MB): 0.05\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Model Training Function:",
   "id": "a786d8c007b1e06"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T14:45:32.206822Z",
     "start_time": "2025-04-18T14:45:32.194633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(model, train_loader, test_loader, num_epochs=100):\n",
    "    \"\"\"Training loop with validation monitoring\"\"\"\n",
    "    # Loss function and optimizer\n",
    "    criterion = nn.MSELoss()  # Mean Squared Error for regression\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5, verbose=True)\n",
    "\n",
    "    # Track losses for visualization\n",
    "    train_losses, val_losses = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        epoch_train_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()  # Reset gradients\n",
    "            outputs = model(X_batch)  # Forward pass\n",
    "            loss = criterion(outputs, y_batch)  # Compute loss\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Update weights\n",
    "            epoch_train_loss += loss.item()\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        epoch_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in test_loader:\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                epoch_val_loss += loss.item()\n",
    "\n",
    "        # Calculate average losses\n",
    "        train_loss = epoch_train_loss / len(train_loader)\n",
    "        val_loss = epoch_val_loss / len(test_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # Update learning rate\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}')\n",
    "\n",
    "    return train_losses, val_losses\n"
   ],
   "id": "1e9fb176a0a77840",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T15:24:46.245402Z",
     "start_time": "2025-04-18T15:20:52.878344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Model Training\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "output_size = y_train.shape[1]\n",
    "model = MultiTargetRegressor(input_size, output_size)\n",
    "\n",
    "# Train model\n",
    "train_losses, val_losses = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    num_epochs=30\n",
    ")\n",
    "\n",
    "#"
   ],
   "id": "f7ddddfc66b070aa",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sparashar/Installed/miniconda3/envs/calisma/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 | Train Loss: 0.6889 | Val Loss: 0.5866\n",
      "Epoch 2/30 | Train Loss: 0.6039 | Val Loss: 0.5742\n",
      "Epoch 3/30 | Train Loss: 0.5912 | Val Loss: 0.5645\n",
      "Epoch 4/30 | Train Loss: 0.5840 | Val Loss: 0.5671\n",
      "Epoch 5/30 | Train Loss: 0.5797 | Val Loss: 0.5652\n",
      "Epoch 6/30 | Train Loss: 0.5768 | Val Loss: 0.5580\n",
      "Epoch 7/30 | Train Loss: 0.5745 | Val Loss: 0.5572\n",
      "Epoch 8/30 | Train Loss: 0.5726 | Val Loss: 0.5547\n",
      "Epoch 9/30 | Train Loss: 0.5713 | Val Loss: 0.5517\n",
      "Epoch 10/30 | Train Loss: 0.5702 | Val Loss: 0.5506\n",
      "Epoch 11/30 | Train Loss: 0.5692 | Val Loss: 0.5480\n",
      "Epoch 12/30 | Train Loss: 0.5680 | Val Loss: 0.5474\n",
      "Epoch 13/30 | Train Loss: 0.5674 | Val Loss: 0.5504\n",
      "Epoch 14/30 | Train Loss: 0.5666 | Val Loss: 0.5481\n",
      "Epoch 15/30 | Train Loss: 0.5662 | Val Loss: 0.5455\n",
      "Epoch 16/30 | Train Loss: 0.5654 | Val Loss: 0.5462\n",
      "Epoch 17/30 | Train Loss: 0.5649 | Val Loss: 0.5451\n",
      "Epoch 18/30 | Train Loss: 0.5643 | Val Loss: 0.5498\n",
      "Epoch 19/30 | Train Loss: 0.5638 | Val Loss: 0.5452\n",
      "Epoch 20/30 | Train Loss: 0.5636 | Val Loss: 0.5502\n",
      "Epoch 21/30 | Train Loss: 0.5630 | Val Loss: 0.5409\n",
      "Epoch 22/30 | Train Loss: 0.5622 | Val Loss: 0.5444\n",
      "Epoch 23/30 | Train Loss: 0.5616 | Val Loss: 0.5450\n",
      "Epoch 24/30 | Train Loss: 0.5610 | Val Loss: 0.5426\n",
      "Epoch 25/30 | Train Loss: 0.5603 | Val Loss: 0.5478\n",
      "Epoch 26/30 | Train Loss: 0.5601 | Val Loss: 0.5556\n",
      "Epoch 27/30 | Train Loss: 0.5595 | Val Loss: 0.5438\n",
      "Epoch 28/30 | Train Loss: 0.5549 | Val Loss: 0.5416\n",
      "Epoch 29/30 | Train Loss: 0.5542 | Val Loss: 0.5397\n",
      "Epoch 30/30 | Train Loss: 0.5540 | Val Loss: 0.5410\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T10:31:37.451190Z",
     "start_time": "2025-04-18T10:26:47.215223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define your hyperparameter grid\n",
    "param_grid = {\n",
    "    'lr': [0.01, 0.001],\n",
    "    'batch_size': [32, 64],\n",
    "    'hidden1': [128, 256]\n",
    "}\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_params = None\n",
    "\n",
    "for lr, batch_size, hidden1 in product(param_grid['lr'], param_grid['batch_size'], param_grid['hidden1']):\n",
    "    # Prepare data loaders with batch_size\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    # Define model with current hidden layer size\n",
    "    model = MultiTargetRegressor(input_size, output_size)\n",
    "    # Optionally, modify your model to accept hidden1 as a parameter\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Train for a few epochs (e.g., 5 for speed)\n",
    "    for epoch in range(5):\n",
    "        model.train()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            val_loss += loss.item()\n",
    "    val_loss /= len(test_loader)\n",
    "\n",
    "    # Save best\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_params = {'lr': lr, 'batch_size': batch_size, 'hidden1': hidden1}\n",
    "\n",
    "print(\"Best params:\", best_params)\n",
    "print(\"Best validation loss:\", best_val_loss)\n"
   ],
   "id": "aab9916eaa3b2042",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'lr': 0.001, 'batch_size': 32, 'hidden1': 128}\n",
      "Best validation loss: 0.3227386912416187\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T11:04:32.182570Z",
     "start_time": "2025-04-18T10:32:07.105094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# Define the hyperparameter space\n",
    "param_space = {\n",
    "    'lr': [1e-3, 5e-4, 1e-4, 5e-5],\n",
    "    'batch_size': [16, 32, 64, 128],\n",
    "    'num_epochs': [10, 20, 30],\n",
    "    # Add more hyperparameters as needed\n",
    "}\n",
    "\n",
    "n_trials = 10  # Number of random samples\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_params = None\n",
    "\n",
    "for trial in range(n_trials):\n",
    "    # Randomly sample hyperparameters\n",
    "    lr = random.choice(param_space['lr'])\n",
    "    batch_size = random.choice(param_space['batch_size'])\n",
    "    num_epochs = random.choice(param_space['num_epochs'])\n",
    "\n",
    "    # Create new dataloaders for this batch size\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    # Initialize model\n",
    "    model = MultiTargetRegressor(input_size, output_size)\n",
    "\n",
    "    # Set optimizer with sampled learning rate\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Train model (use your train_model function)\n",
    "    train_losses, val_losses = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        test_loader=test_loader,\n",
    "        num_epochs=num_epochs\n",
    "    )\n",
    "\n",
    "    # Use the last validation loss as the metric\n",
    "    final_val_loss = val_losses[-1]\n",
    "\n",
    "    print(f\"Trial {trial+1}: lr={lr}, batch_size={batch_size}, num_epochs={num_epochs}, val_loss={final_val_loss:.4f}\")\n",
    "\n",
    "    # Track the best hyperparameters\n",
    "    if final_val_loss < best_val_loss:\n",
    "        best_val_loss = final_val_loss\n",
    "        best_params = {\n",
    "            'lr': lr,\n",
    "            'batch_size': batch_size,\n",
    "            'num_epochs': num_epochs\n",
    "        }\n",
    "\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "print(\"Best validation loss:\", best_val_loss)\n"
   ],
   "id": "4686c18c0136136a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sparashar/Installed/miniconda3/envs/calisma/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 | Train Loss: 0.3935 | Val Loss: 0.3502\n",
      "Epoch 2/30 | Train Loss: 0.3534 | Val Loss: 0.3271\n",
      "Epoch 3/30 | Train Loss: 0.3437 | Val Loss: 0.3257\n",
      "Epoch 4/30 | Train Loss: 0.3372 | Val Loss: 0.3281\n",
      "Epoch 5/30 | Train Loss: 0.3329 | Val Loss: 0.3223\n",
      "Epoch 6/30 | Train Loss: 0.3290 | Val Loss: 0.3257\n",
      "Epoch 7/30 | Train Loss: 0.3258 | Val Loss: 0.3290\n",
      "Epoch 8/30 | Train Loss: 0.3232 | Val Loss: 0.3324\n",
      "Epoch 9/30 | Train Loss: 0.3211 | Val Loss: 0.3279\n",
      "Epoch 10/30 | Train Loss: 0.3188 | Val Loss: 0.3263\n",
      "Epoch 11/30 | Train Loss: 0.3168 | Val Loss: 0.3356\n",
      "Epoch 12/30 | Train Loss: 0.3044 | Val Loss: 0.3258\n",
      "Epoch 13/30 | Train Loss: 0.3014 | Val Loss: 0.3263\n",
      "Epoch 14/30 | Train Loss: 0.3003 | Val Loss: 0.3260\n",
      "Epoch 15/30 | Train Loss: 0.2995 | Val Loss: 0.3262\n",
      "Epoch 16/30 | Train Loss: 0.2989 | Val Loss: 0.3284\n",
      "Epoch 17/30 | Train Loss: 0.2984 | Val Loss: 0.3280\n",
      "Epoch 18/30 | Train Loss: 0.2964 | Val Loss: 0.3278\n",
      "Epoch 19/30 | Train Loss: 0.2962 | Val Loss: 0.3276\n",
      "Epoch 20/30 | Train Loss: 0.2960 | Val Loss: 0.3278\n",
      "Epoch 21/30 | Train Loss: 0.2960 | Val Loss: 0.3284\n",
      "Epoch 22/30 | Train Loss: 0.2959 | Val Loss: 0.3282\n",
      "Epoch 23/30 | Train Loss: 0.2958 | Val Loss: 0.3282\n",
      "Epoch 24/30 | Train Loss: 0.2956 | Val Loss: 0.3282\n",
      "Epoch 25/30 | Train Loss: 0.2956 | Val Loss: 0.3283\n",
      "Epoch 26/30 | Train Loss: 0.2956 | Val Loss: 0.3282\n",
      "Epoch 27/30 | Train Loss: 0.2956 | Val Loss: 0.3283\n",
      "Epoch 28/30 | Train Loss: 0.2956 | Val Loss: 0.3282\n",
      "Epoch 29/30 | Train Loss: 0.2956 | Val Loss: 0.3282\n",
      "Epoch 30/30 | Train Loss: 0.2955 | Val Loss: 0.3282\n",
      "Trial 1: lr=0.0005, batch_size=32, num_epochs=30, val_loss=0.3282\n",
      "Epoch 1/20 | Train Loss: 0.3886 | Val Loss: 0.3365\n",
      "Epoch 2/20 | Train Loss: 0.3526 | Val Loss: 0.3320\n",
      "Epoch 3/20 | Train Loss: 0.3427 | Val Loss: 0.3275\n",
      "Epoch 4/20 | Train Loss: 0.3365 | Val Loss: 0.3229\n",
      "Epoch 5/20 | Train Loss: 0.3321 | Val Loss: 0.3251\n",
      "Epoch 6/20 | Train Loss: 0.3287 | Val Loss: 0.3216\n",
      "Epoch 7/20 | Train Loss: 0.3256 | Val Loss: 0.3240\n",
      "Epoch 8/20 | Train Loss: 0.3230 | Val Loss: 0.3235\n",
      "Epoch 9/20 | Train Loss: 0.3207 | Val Loss: 0.3322\n",
      "Epoch 10/20 | Train Loss: 0.3185 | Val Loss: 0.3260\n",
      "Epoch 11/20 | Train Loss: 0.3169 | Val Loss: 0.3293\n",
      "Epoch 12/20 | Train Loss: 0.3151 | Val Loss: 0.3308\n",
      "Epoch 13/20 | Train Loss: 0.3023 | Val Loss: 0.3239\n",
      "Epoch 14/20 | Train Loss: 0.2992 | Val Loss: 0.3247\n",
      "Epoch 15/20 | Train Loss: 0.2981 | Val Loss: 0.3275\n",
      "Epoch 16/20 | Train Loss: 0.2973 | Val Loss: 0.3269\n",
      "Epoch 17/20 | Train Loss: 0.2967 | Val Loss: 0.3272\n",
      "Epoch 18/20 | Train Loss: 0.2961 | Val Loss: 0.3272\n",
      "Epoch 19/20 | Train Loss: 0.2940 | Val Loss: 0.3280\n",
      "Epoch 20/20 | Train Loss: 0.2938 | Val Loss: 0.3278\n",
      "Trial 2: lr=0.0005, batch_size=32, num_epochs=20, val_loss=0.3278\n",
      "Epoch 1/20 | Train Loss: 0.4073 | Val Loss: 0.3395\n",
      "Epoch 2/20 | Train Loss: 0.3589 | Val Loss: 0.3312\n",
      "Epoch 3/20 | Train Loss: 0.3480 | Val Loss: 0.3332\n",
      "Epoch 4/20 | Train Loss: 0.3417 | Val Loss: 0.3281\n",
      "Epoch 5/20 | Train Loss: 0.3363 | Val Loss: 0.3305\n",
      "Epoch 6/20 | Train Loss: 0.3324 | Val Loss: 0.3256\n",
      "Epoch 7/20 | Train Loss: 0.3290 | Val Loss: 0.3317\n",
      "Epoch 8/20 | Train Loss: 0.3261 | Val Loss: 0.3273\n",
      "Epoch 9/20 | Train Loss: 0.3239 | Val Loss: 0.3296\n",
      "Epoch 10/20 | Train Loss: 0.3213 | Val Loss: 0.3262\n",
      "Epoch 11/20 | Train Loss: 0.3194 | Val Loss: 0.3285\n",
      "Epoch 12/20 | Train Loss: 0.3175 | Val Loss: 0.3271\n",
      "Epoch 13/20 | Train Loss: 0.3061 | Val Loss: 0.3235\n",
      "Epoch 14/20 | Train Loss: 0.3038 | Val Loss: 0.3253\n",
      "Epoch 15/20 | Train Loss: 0.3029 | Val Loss: 0.3259\n",
      "Epoch 16/20 | Train Loss: 0.3023 | Val Loss: 0.3274\n",
      "Epoch 17/20 | Train Loss: 0.3018 | Val Loss: 0.3270\n",
      "Epoch 18/20 | Train Loss: 0.3013 | Val Loss: 0.3284\n",
      "Epoch 19/20 | Train Loss: 0.3008 | Val Loss: 0.3276\n",
      "Epoch 20/20 | Train Loss: 0.2992 | Val Loss: 0.3277\n",
      "Trial 3: lr=0.0005, batch_size=64, num_epochs=20, val_loss=0.3277\n",
      "Epoch 1/30 | Train Loss: 0.3820 | Val Loss: 0.3366\n",
      "Epoch 2/30 | Train Loss: 0.3506 | Val Loss: 0.3307\n",
      "Epoch 3/30 | Train Loss: 0.3415 | Val Loss: 0.3247\n",
      "Epoch 4/30 | Train Loss: 0.3354 | Val Loss: 0.3290\n",
      "Epoch 5/30 | Train Loss: 0.3308 | Val Loss: 0.3240\n",
      "Epoch 6/30 | Train Loss: 0.3276 | Val Loss: 0.3271\n",
      "Epoch 7/30 | Train Loss: 0.3246 | Val Loss: 0.3261\n",
      "Epoch 8/30 | Train Loss: 0.3219 | Val Loss: 0.3302\n",
      "Epoch 9/30 | Train Loss: 0.3200 | Val Loss: 0.3245\n",
      "Epoch 10/30 | Train Loss: 0.3179 | Val Loss: 0.3261\n",
      "Epoch 11/30 | Train Loss: 0.3157 | Val Loss: 0.3292\n",
      "Epoch 12/30 | Train Loss: 0.3010 | Val Loss: 0.3249\n",
      "Epoch 13/30 | Train Loss: 0.2974 | Val Loss: 0.3262\n",
      "Epoch 14/30 | Train Loss: 0.2960 | Val Loss: 0.3264\n",
      "Epoch 15/30 | Train Loss: 0.2951 | Val Loss: 0.3269\n",
      "Epoch 16/30 | Train Loss: 0.2944 | Val Loss: 0.3272\n",
      "Epoch 17/30 | Train Loss: 0.2938 | Val Loss: 0.3291\n",
      "Epoch 18/30 | Train Loss: 0.2913 | Val Loss: 0.3286\n",
      "Epoch 19/30 | Train Loss: 0.2911 | Val Loss: 0.3288\n",
      "Epoch 20/30 | Train Loss: 0.2909 | Val Loss: 0.3287\n",
      "Epoch 21/30 | Train Loss: 0.2908 | Val Loss: 0.3292\n",
      "Epoch 22/30 | Train Loss: 0.2908 | Val Loss: 0.3290\n",
      "Epoch 23/30 | Train Loss: 0.2907 | Val Loss: 0.3297\n",
      "Epoch 24/30 | Train Loss: 0.2904 | Val Loss: 0.3294\n",
      "Epoch 25/30 | Train Loss: 0.2904 | Val Loss: 0.3293\n",
      "Epoch 26/30 | Train Loss: 0.2904 | Val Loss: 0.3293\n",
      "Epoch 27/30 | Train Loss: 0.2903 | Val Loss: 0.3293\n",
      "Epoch 28/30 | Train Loss: 0.2903 | Val Loss: 0.3293\n",
      "Epoch 29/30 | Train Loss: 0.2903 | Val Loss: 0.3293\n",
      "Epoch 30/30 | Train Loss: 0.2903 | Val Loss: 0.3293\n",
      "Trial 4: lr=5e-05, batch_size=16, num_epochs=30, val_loss=0.3293\n",
      "Epoch 1/30 | Train Loss: 0.3825 | Val Loss: 0.3311\n",
      "Epoch 2/30 | Train Loss: 0.3505 | Val Loss: 0.3321\n",
      "Epoch 3/30 | Train Loss: 0.3419 | Val Loss: 0.3259\n",
      "Epoch 4/30 | Train Loss: 0.3360 | Val Loss: 0.3237\n",
      "Epoch 5/30 | Train Loss: 0.3318 | Val Loss: 0.3215\n",
      "Epoch 6/30 | Train Loss: 0.3286 | Val Loss: 0.3317\n",
      "Epoch 7/30 | Train Loss: 0.3259 | Val Loss: 0.3234\n",
      "Epoch 8/30 | Train Loss: 0.3235 | Val Loss: 0.3274\n",
      "Epoch 9/30 | Train Loss: 0.3209 | Val Loss: 0.3262\n",
      "Epoch 10/30 | Train Loss: 0.3191 | Val Loss: 0.3279\n",
      "Epoch 11/30 | Train Loss: 0.3171 | Val Loss: 0.3296\n",
      "Epoch 12/30 | Train Loss: 0.3027 | Val Loss: 0.3239\n",
      "Epoch 13/30 | Train Loss: 0.2992 | Val Loss: 0.3262\n",
      "Epoch 14/30 | Train Loss: 0.2980 | Val Loss: 0.3258\n",
      "Epoch 15/30 | Train Loss: 0.2971 | Val Loss: 0.3256\n",
      "Epoch 16/30 | Train Loss: 0.2965 | Val Loss: 0.3268\n",
      "Epoch 17/30 | Train Loss: 0.2959 | Val Loss: 0.3284\n",
      "Epoch 18/30 | Train Loss: 0.2935 | Val Loss: 0.3280\n",
      "Epoch 19/30 | Train Loss: 0.2932 | Val Loss: 0.3274\n",
      "Epoch 20/30 | Train Loss: 0.2931 | Val Loss: 0.3280\n",
      "Epoch 21/30 | Train Loss: 0.2930 | Val Loss: 0.3280\n",
      "Epoch 22/30 | Train Loss: 0.2929 | Val Loss: 0.3281\n",
      "Epoch 23/30 | Train Loss: 0.2929 | Val Loss: 0.3280\n",
      "Epoch 24/30 | Train Loss: 0.2926 | Val Loss: 0.3282\n",
      "Epoch 25/30 | Train Loss: 0.2925 | Val Loss: 0.3283\n",
      "Epoch 26/30 | Train Loss: 0.2925 | Val Loss: 0.3283\n",
      "Epoch 27/30 | Train Loss: 0.2925 | Val Loss: 0.3283\n",
      "Epoch 28/30 | Train Loss: 0.2925 | Val Loss: 0.3283\n",
      "Epoch 29/30 | Train Loss: 0.2925 | Val Loss: 0.3283\n",
      "Epoch 30/30 | Train Loss: 0.2925 | Val Loss: 0.3283\n",
      "Trial 5: lr=0.0005, batch_size=16, num_epochs=30, val_loss=0.3283\n",
      "Epoch 1/10 | Train Loss: 0.3947 | Val Loss: 0.3391\n",
      "Epoch 2/10 | Train Loss: 0.3568 | Val Loss: 0.3295\n",
      "Epoch 3/10 | Train Loss: 0.3464 | Val Loss: 0.3268\n",
      "Epoch 4/10 | Train Loss: 0.3398 | Val Loss: 0.3279\n",
      "Epoch 5/10 | Train Loss: 0.3351 | Val Loss: 0.3230\n",
      "Epoch 6/10 | Train Loss: 0.3308 | Val Loss: 0.3283\n",
      "Epoch 7/10 | Train Loss: 0.3277 | Val Loss: 0.3223\n",
      "Epoch 8/10 | Train Loss: 0.3245 | Val Loss: 0.3238\n",
      "Epoch 9/10 | Train Loss: 0.3224 | Val Loss: 0.3273\n",
      "Epoch 10/10 | Train Loss: 0.3198 | Val Loss: 0.3261\n",
      "Trial 6: lr=0.0005, batch_size=64, num_epochs=10, val_loss=0.3261\n",
      "Epoch 1/20 | Train Loss: 0.3869 | Val Loss: 0.3354\n",
      "Epoch 2/20 | Train Loss: 0.3521 | Val Loss: 0.3299\n",
      "Epoch 3/20 | Train Loss: 0.3420 | Val Loss: 0.3241\n",
      "Epoch 4/20 | Train Loss: 0.3361 | Val Loss: 0.3237\n",
      "Epoch 5/20 | Train Loss: 0.3320 | Val Loss: 0.3236\n",
      "Epoch 6/20 | Train Loss: 0.3282 | Val Loss: 0.3259\n",
      "Epoch 7/20 | Train Loss: 0.3254 | Val Loss: 0.3252\n",
      "Epoch 8/20 | Train Loss: 0.3229 | Val Loss: 0.3274\n",
      "Epoch 9/20 | Train Loss: 0.3203 | Val Loss: 0.3264\n",
      "Epoch 10/20 | Train Loss: 0.3186 | Val Loss: 0.3275\n",
      "Epoch 11/20 | Train Loss: 0.3167 | Val Loss: 0.3250\n",
      "Epoch 12/20 | Train Loss: 0.3043 | Val Loss: 0.3240\n",
      "Epoch 13/20 | Train Loss: 0.3012 | Val Loss: 0.3252\n",
      "Epoch 14/20 | Train Loss: 0.3001 | Val Loss: 0.3246\n",
      "Epoch 15/20 | Train Loss: 0.2993 | Val Loss: 0.3260\n",
      "Epoch 16/20 | Train Loss: 0.2987 | Val Loss: 0.3268\n",
      "Epoch 17/20 | Train Loss: 0.2981 | Val Loss: 0.3296\n",
      "Epoch 18/20 | Train Loss: 0.2962 | Val Loss: 0.3274\n",
      "Epoch 19/20 | Train Loss: 0.2959 | Val Loss: 0.3275\n",
      "Epoch 20/20 | Train Loss: 0.2958 | Val Loss: 0.3278\n",
      "Trial 7: lr=5e-05, batch_size=32, num_epochs=20, val_loss=0.3278\n",
      "Epoch 1/20 | Train Loss: 0.4020 | Val Loss: 0.3442\n",
      "Epoch 2/20 | Train Loss: 0.3579 | Val Loss: 0.3340\n",
      "Epoch 3/20 | Train Loss: 0.3476 | Val Loss: 0.3310\n",
      "Epoch 4/20 | Train Loss: 0.3405 | Val Loss: 0.3258\n",
      "Epoch 5/20 | Train Loss: 0.3356 | Val Loss: 0.3243\n",
      "Epoch 6/20 | Train Loss: 0.3314 | Val Loss: 0.3260\n",
      "Epoch 7/20 | Train Loss: 0.3282 | Val Loss: 0.3291\n",
      "Epoch 8/20 | Train Loss: 0.3255 | Val Loss: 0.3235\n",
      "Epoch 9/20 | Train Loss: 0.3232 | Val Loss: 0.3214\n",
      "Epoch 10/20 | Train Loss: 0.3207 | Val Loss: 0.3265\n",
      "Epoch 11/20 | Train Loss: 0.3186 | Val Loss: 0.3281\n",
      "Epoch 12/20 | Train Loss: 0.3171 | Val Loss: 0.3261\n",
      "Epoch 13/20 | Train Loss: 0.3152 | Val Loss: 0.3300\n",
      "Epoch 14/20 | Train Loss: 0.3136 | Val Loss: 0.3248\n",
      "Epoch 15/20 | Train Loss: 0.3124 | Val Loss: 0.3300\n",
      "Epoch 16/20 | Train Loss: 0.3010 | Val Loss: 0.3248\n",
      "Epoch 17/20 | Train Loss: 0.2988 | Val Loss: 0.3253\n",
      "Epoch 18/20 | Train Loss: 0.2979 | Val Loss: 0.3269\n",
      "Epoch 19/20 | Train Loss: 0.2972 | Val Loss: 0.3279\n",
      "Epoch 20/20 | Train Loss: 0.2967 | Val Loss: 0.3265\n",
      "Trial 8: lr=0.0001, batch_size=64, num_epochs=20, val_loss=0.3265\n",
      "Epoch 1/30 | Train Loss: 0.3985 | Val Loss: 0.3363\n",
      "Epoch 2/30 | Train Loss: 0.3561 | Val Loss: 0.3311\n",
      "Epoch 3/30 | Train Loss: 0.3451 | Val Loss: 0.3258\n",
      "Epoch 4/30 | Train Loss: 0.3390 | Val Loss: 0.3272\n",
      "Epoch 5/30 | Train Loss: 0.3346 | Val Loss: 0.3265\n",
      "Epoch 6/30 | Train Loss: 0.3308 | Val Loss: 0.3223\n",
      "Epoch 7/30 | Train Loss: 0.3277 | Val Loss: 0.3256\n",
      "Epoch 8/30 | Train Loss: 0.3249 | Val Loss: 0.3272\n",
      "Epoch 9/30 | Train Loss: 0.3222 | Val Loss: 0.3234\n",
      "Epoch 10/30 | Train Loss: 0.3200 | Val Loss: 0.3292\n",
      "Epoch 11/30 | Train Loss: 0.3180 | Val Loss: 0.3278\n",
      "Epoch 12/30 | Train Loss: 0.3162 | Val Loss: 0.3293\n",
      "Epoch 13/30 | Train Loss: 0.3056 | Val Loss: 0.3234\n",
      "Epoch 14/30 | Train Loss: 0.3029 | Val Loss: 0.3239\n",
      "Epoch 15/30 | Train Loss: 0.3020 | Val Loss: 0.3255\n",
      "Epoch 16/30 | Train Loss: 0.3013 | Val Loss: 0.3247\n",
      "Epoch 17/30 | Train Loss: 0.3007 | Val Loss: 0.3258\n",
      "Epoch 18/30 | Train Loss: 0.3005 | Val Loss: 0.3266\n",
      "Epoch 19/30 | Train Loss: 0.2986 | Val Loss: 0.3260\n",
      "Epoch 20/30 | Train Loss: 0.2984 | Val Loss: 0.3260\n",
      "Epoch 21/30 | Train Loss: 0.2984 | Val Loss: 0.3261\n",
      "Epoch 22/30 | Train Loss: 0.2983 | Val Loss: 0.3261\n",
      "Epoch 23/30 | Train Loss: 0.2983 | Val Loss: 0.3266\n",
      "Epoch 24/30 | Train Loss: 0.2982 | Val Loss: 0.3263\n",
      "Epoch 25/30 | Train Loss: 0.2980 | Val Loss: 0.3263\n",
      "Epoch 26/30 | Train Loss: 0.2980 | Val Loss: 0.3263\n",
      "Epoch 27/30 | Train Loss: 0.2980 | Val Loss: 0.3263\n",
      "Epoch 28/30 | Train Loss: 0.2980 | Val Loss: 0.3263\n",
      "Epoch 29/30 | Train Loss: 0.2979 | Val Loss: 0.3263\n",
      "Epoch 30/30 | Train Loss: 0.2980 | Val Loss: 0.3263\n",
      "Trial 9: lr=5e-05, batch_size=64, num_epochs=30, val_loss=0.3263\n",
      "Epoch 1/10 | Train Loss: 0.4002 | Val Loss: 0.3419\n",
      "Epoch 2/10 | Train Loss: 0.3583 | Val Loss: 0.3316\n",
      "Epoch 3/10 | Train Loss: 0.3470 | Val Loss: 0.3273\n",
      "Epoch 4/10 | Train Loss: 0.3408 | Val Loss: 0.3249\n",
      "Epoch 5/10 | Train Loss: 0.3359 | Val Loss: 0.3342\n",
      "Epoch 6/10 | Train Loss: 0.3322 | Val Loss: 0.3269\n",
      "Epoch 7/10 | Train Loss: 0.3290 | Val Loss: 0.3242\n",
      "Epoch 8/10 | Train Loss: 0.3262 | Val Loss: 0.3260\n",
      "Epoch 9/10 | Train Loss: 0.3234 | Val Loss: 0.3331\n",
      "Epoch 10/10 | Train Loss: 0.3215 | Val Loss: 0.3248\n",
      "Trial 10: lr=5e-05, batch_size=64, num_epochs=10, val_loss=0.3248\n",
      "Best hyperparameters: {'lr': 5e-05, 'batch_size': 64, 'num_epochs': 10}\n",
      "Best validation loss: 0.3247509590034411\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Best Hyperparameters when predictand = both:\n",
    "Best hyperparameters: {'lr': 5e-05, 'batch_size': 64, 'num_epochs': 10}\n",
    "Best validation loss: 0.3247509590034411\n",
    "\n"
   ],
   "id": "786ecf52debf133d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Model Evaluation:",
   "id": "2de8f68ac000e0a5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T14:56:37.658924Z",
     "start_time": "2025-04-18T14:56:37.652039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(model, X_test_tensor, y_test):\n",
    "    \"\"\"Generate predictions and calculate metrics\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_tensor = model(X_test_tensor)\n",
    "\n",
    "    # Convert to numpy for sklearn metrics\n",
    "    y_pred = y_pred_tensor.numpy()\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)  # Method #2 from search results\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Display metrics\n",
    "    print(\"\\nFinal Model Evaluation:\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")  # Added from search result [1][2]\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"R²: {r2:.4f}\")\n",
    "\n",
    "    return y_pred"
   ],
   "id": "8fb2ae85b752b57c",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Visualisation",
   "id": "d434549c427ddb89"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T14:57:21.710872Z",
     "start_time": "2025-04-18T14:57:21.695764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_loss_curves(train_losses, val_losses):\n",
    "    \"\"\"Plot training and validation loss curves\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.title('Loss Curves')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MSE Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ],
   "id": "80aff5cd849a7ca8",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Execution",
   "id": "1f6a550e4a0d52bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T14:57:24.770025Z",
     "start_time": "2025-04-18T14:57:24.551030Z"
    }
   },
   "cell_type": "code",
   "source": [
    " #Visualize training progress\n",
    "plot_loss_curves(train_losses=train_losses, val_losses=val_losses)\n",
    "\n",
    "# Final evaluation\n",
    "evaluate_model(model=model, X_test_tensor=X_test_tensor, y_test=y_test)\n",
    "#y_pred = evaluate_model(model, X_test_tensor, y_test)"
   ],
   "id": "6211a66b46e6c7b3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Model Evaluation:\n",
      "MSE: 0.3250\n",
      "RMSE: 0.5701\n",
      "MAE: 0.3923\n",
      "R²: 0.4013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.7385144 ,  0.37993875],\n",
       "       [ 0.7562384 ,  1.0785763 ],\n",
       "       [ 0.6835478 ,  0.6038401 ],\n",
       "       ...,\n",
       "       [ 0.65580374,  0.627517  ],\n",
       "       [ 0.72915334,  0.21867003],\n",
       "       [ 0.34052426, -0.39038962]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
