{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T07:38:31.587337Z",
     "start_time": "2025-05-08T07:38:31.504158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#auto reload jupyter to update notebook w.r.t changes in other linked files:\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "237aafff1d2b17c1",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T07:38:42.301998Z",
     "start_time": "2025-05-08T07:38:32.866113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "#from xgboost.testing import root_mean_square\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from train_and_evaluate import load_train_test_data\n",
    "from preprocessing import preprocess_data"
   ],
   "id": "566940c48a21383a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values after aggregation to median\n",
      "time                0\n",
      "lat                 0\n",
      "lon                 0\n",
      "clf                 0\n",
      "lwp                 0\n",
      "blh                 0\n",
      "cape                0\n",
      "mlspf               0\n",
      "mslhf               0\n",
      "msshf               0\n",
      "q700                0\n",
      "q850                0\n",
      "rh700               0\n",
      "rh850               0\n",
      "sst                 0\n",
      "t700                0\n",
      "t850                0\n",
      "tcwv                0\n",
      "u10                 0\n",
      "u700                0\n",
      "u850                0\n",
      "v10                 0\n",
      "v700                0\n",
      "v850                0\n",
      "w700                0\n",
      "w850                0\n",
      "Terra_descending    0\n",
      "lsm                 0\n",
      "eis                 0\n",
      "lnNd                0\n",
      "dtype: int64\n",
      "Null Values:\n",
      "time                0\n",
      "lat                 0\n",
      "lon                 0\n",
      "clf                 0\n",
      "lwp                 0\n",
      "blh                 0\n",
      "cape                0\n",
      "mlspf               0\n",
      "mslhf               0\n",
      "msshf               0\n",
      "q700                0\n",
      "q850                0\n",
      "rh700               0\n",
      "rh850               0\n",
      "sst                 0\n",
      "t700                0\n",
      "t850                0\n",
      "tcwv                0\n",
      "u10                 0\n",
      "u700                0\n",
      "u850                0\n",
      "v10                 0\n",
      "v700                0\n",
      "v850                0\n",
      "w700                0\n",
      "w850                0\n",
      "Terra_descending    0\n",
      "lsm                 0\n",
      "eis                 0\n",
      "lnNd                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-08T08:14:52.154280Z",
     "start_time": "2025-05-08T08:14:49.779323Z"
    }
   },
   "source": [
    "#Define the predictand\n",
    "predictands = 'lwp'\n",
    "\n",
    "df_train, df_test, X_train, y_train, X_test, y_test, predictors, predictands = preprocess_data(scalertype='standard',\n",
    "                    outlier_method='iqr',\n",
    "                    scale_predictands=True,\n",
    "                    selected_predictands=None)\n",
    "#df_train, df_test, X_train, y_train, X_test, y_test, predictors, predictands = load_train_test_data(predictands=predictands)\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "\n",
    "# Convert pandas DataFrames to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "print(f'train_loader: {train_loader} \\n test_loader: {test_loader}' )\n",
    "print(f'size of train_loader: {len(train_loader)} \\n size of test_loader: {len(test_loader)}')"
   ],
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"list\") to str",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#Define the predictand\u001B[39;00m\n\u001B[1;32m      2\u001B[0m predictands \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlwp\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m----> 4\u001B[0m df_train, df_test, X_train, y_train, X_test, y_test, predictors, predictands \u001B[38;5;241m=\u001B[39m preprocess_data(scalertype\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstandard\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m      5\u001B[0m                     outlier_method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124miqr\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m      6\u001B[0m                     scale_predictands\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m      7\u001B[0m                     selected_predictands\u001B[38;5;241m=\u001B[39mpredictands)\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m#df_train, df_test, X_train, y_train, X_test, y_test, predictors, predictands = load_train_test_data(predictands=predictands)\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX_train shape: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mX_train\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, y_train shape: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00my_train\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/KIT/lab_rotation/calisma_all/Calisma_LR/preprocessing.py:179\u001B[0m, in \u001B[0;36mpreprocess_data\u001B[0;34m(filepath, scalertype, outlier_method, scale_predictands, selected_predictands)\u001B[0m\n\u001B[1;32m    176\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    177\u001B[0m     predictands \u001B[38;5;241m=\u001B[39m selected_predictands\n\u001B[0;32m--> 179\u001B[0m predictors \u001B[38;5;241m=\u001B[39m [col \u001B[38;5;28;01mfor\u001B[39;00m col \u001B[38;5;129;01min\u001B[39;00m df\u001B[38;5;241m.\u001B[39mcolumns \u001B[38;5;28;01mif\u001B[39;00m col \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m predictands \u001B[38;5;241m+\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtime\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlat\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlon\u001B[39m\u001B[38;5;124m'\u001B[39m]]\n\u001B[1;32m    181\u001B[0m \u001B[38;5;66;03m# Remove outliers\u001B[39;00m\n\u001B[1;32m    182\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m outlier_method \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124miqr\u001B[39m\u001B[38;5;124m'\u001B[39m:\n",
      "File \u001B[0;32m~/KIT/lab_rotation/calisma_all/Calisma_LR/preprocessing.py:179\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    176\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    177\u001B[0m     predictands \u001B[38;5;241m=\u001B[39m selected_predictands\n\u001B[0;32m--> 179\u001B[0m predictors \u001B[38;5;241m=\u001B[39m [col \u001B[38;5;28;01mfor\u001B[39;00m col \u001B[38;5;129;01min\u001B[39;00m df\u001B[38;5;241m.\u001B[39mcolumns \u001B[38;5;28;01mif\u001B[39;00m col \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m predictands \u001B[38;5;241m+\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtime\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlat\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlon\u001B[39m\u001B[38;5;124m'\u001B[39m]]\n\u001B[1;32m    181\u001B[0m \u001B[38;5;66;03m# Remove outliers\u001B[39;00m\n\u001B[1;32m    182\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m outlier_method \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124miqr\u001B[39m\u001B[38;5;124m'\u001B[39m:\n",
      "\u001B[0;31mTypeError\u001B[0m: can only concatenate str (not \"list\") to str"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Neural Network Architecture",
   "id": "d88511ecfee38825"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T07:46:35.981815Z",
     "start_time": "2025-05-08T07:46:35.942253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MultiTargetRegressor(nn.Module):\n",
    "    \"\"\"Neural network for multi-target regression\"\"\"\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            # Input layer to first hidden layer\n",
    "            nn.Linear(input_size, 32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # First hidden layer to second hidden layer\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # First hidden layer to second hidden layer\n",
    "            nn.Linear(16, 10),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Second hidden layer to output layer\n",
    "            nn.Linear(10, output_size)\n",
    "        )\n",
    "\n",
    "        # Initialize weights using Kaiming He initialization for ReLU\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.kaiming_normal_(layer.weight, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Defines forward pass through network\"\"\"\n",
    "        return self.layers(x)"
   ],
   "id": "35a96a4f455b96e8",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T07:46:39.909260Z",
     "start_time": "2025-05-08T07:46:39.874851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_model_structure(model, input_size, output_size):\n",
    "    neuron_counts = [input_size]  # Start with input size\n",
    "    linear_layers = []\n",
    "\n",
    "    # Collect neuron counts for each nn.Linear layer\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            neuron_counts.append(layer.out_features)\n",
    "            linear_layers.append(layer)\n",
    "\n",
    "    # Print neurons per layer\n",
    "    print(\"Model Structure:\")\n",
    "    print(f\"Input layer: {neuron_counts[0]} neurons\")\n",
    "    for i, n in enumerate(neuron_counts[1:-1], 1):\n",
    "        print(f\"Hidden layer {i}: {n} neurons\")\n",
    "    print(f\"Output layer: {neuron_counts[-1]} neurons\")\n",
    "\n",
    "    # Print total neurons (excluding input layer if you want only trainable neurons)\n",
    "    total_neurons = sum(neuron_counts)\n",
    "    print(f\"\\nTotal number of neurons (including input and output): {total_neurons}\")\n",
    "\n",
    "    # Print number of layers\n",
    "    print(f\"Number of layers (Linear): {len(linear_layers)}\")\n",
    "    print(f\"Number of hidden layers: {len(linear_layers) - 1}\")\n",
    "\n",
    "# Example usage:\n",
    "input_size = X_train.shape[1]\n",
    "output_size = y_train.shape[1]\n",
    "model = MultiTargetRegressor(input_size, output_size)\n",
    "print_model_structure(model, input_size, output_size)\n"
   ],
   "id": "46db43ce6555fda3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:\n",
      "Input layer: 25 neurons\n",
      "Hidden layer 1: 32 neurons\n",
      "Hidden layer 2: 16 neurons\n",
      "Hidden layer 3: 10 neurons\n",
      "Output layer: 2 neurons\n",
      "\n",
      "Total number of neurons (including input and output): 85\n",
      "Number of layers (Linear): 4\n",
      "Number of hidden layers: 3\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T07:46:57.461629Z",
     "start_time": "2025-05-08T07:46:57.057709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Install torchviz if not already installed\n",
    "# !pip install torchviz\n",
    "\n",
    "from torchviz import make_dot\n",
    "import torch\n",
    "\n",
    "def visualize_model(model, input_size):\n",
    "    # Create a dummy input tensor with the correct shape\n",
    "    x = torch.randn(1, input_size, requires_grad=True)\n",
    "    y = model(x)\n",
    "    # Create a visualization of the computation graph\n",
    "    dot = make_dot(y, params=dict(model.named_parameters()))\n",
    "    return dot\n",
    "\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "output_size = y_train.shape[1]\n",
    "model = MultiTargetRegressor(input_size, output_size)\n",
    "\n",
    "# Example usage:\n",
    "dot = visualize_model(model, input_size)\n",
    "#dot.render(\"model_architecture\", format=\"png\")  # Saves to file\n",
    "dot  # Display in Jupyter notebook\n"
   ],
   "id": "5429251d06e4a232",
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"541pt\" height=\"678pt\"\n viewBox=\"0.00 0.00 541.00 678.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 674)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-674 537,-674 537,4 -4,4\"/>\n<!-- 131328393321296 -->\n<g id=\"node1\" class=\"node\">\n<title>131328393321296</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"319,-31 260,-31 260,0 319,0 319,-31\"/>\n<text text-anchor=\"middle\" x=\"289.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> (1, 2)</text>\n</g>\n<!-- 131328391322816 -->\n<g id=\"node2\" class=\"node\">\n<title>131328391322816</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"340,-86 239,-86 239,-67 340,-67 340,-86\"/>\n<text text-anchor=\"middle\" x=\"289.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n</g>\n<!-- 131328391322816&#45;&gt;131328393321296 -->\n<g id=\"edge29\" class=\"edge\">\n<title>131328391322816&#45;&gt;131328393321296</title>\n<path fill=\"none\" stroke=\"black\" d=\"M289.5,-66.79C289.5,-60.07 289.5,-50.4 289.5,-41.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"293,-41.19 289.5,-31.19 286,-41.19 293,-41.19\"/>\n</g>\n<!-- 131328391322384 -->\n<g id=\"node3\" class=\"node\">\n<title>131328391322384</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"224,-141 123,-141 123,-122 224,-122 224,-141\"/>\n<text text-anchor=\"middle\" x=\"173.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 131328391322384&#45;&gt;131328391322816 -->\n<g id=\"edge1\" class=\"edge\">\n<title>131328391322384&#45;&gt;131328391322816</title>\n<path fill=\"none\" stroke=\"black\" d=\"M192.14,-121.98C210.8,-113.46 239.75,-100.23 261.24,-90.41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"262.88,-93.51 270.52,-86.17 259.97,-87.14 262.88,-93.51\"/>\n</g>\n<!-- 131328391407632 -->\n<g id=\"node4\" class=\"node\">\n<title>131328391407632</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"221,-207 126,-207 126,-177 221,-177 221,-207\"/>\n<text text-anchor=\"middle\" x=\"173.5\" y=\"-195\" font-family=\"monospace\" font-size=\"10.00\">layers.6.bias</text>\n<text text-anchor=\"middle\" x=\"173.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\"> (2)</text>\n</g>\n<!-- 131328391407632&#45;&gt;131328391322384 -->\n<g id=\"edge2\" class=\"edge\">\n<title>131328391407632&#45;&gt;131328391322384</title>\n<path fill=\"none\" stroke=\"black\" d=\"M173.5,-176.84C173.5,-169.21 173.5,-159.7 173.5,-151.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"177,-151.27 173.5,-141.27 170,-151.27 177,-151.27\"/>\n</g>\n<!-- 131328391322432 -->\n<g id=\"node5\" class=\"node\">\n<title>131328391322432</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"337,-141 242,-141 242,-122 337,-122 337,-141\"/>\n<text text-anchor=\"middle\" x=\"289.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">ReluBackward0</text>\n</g>\n<!-- 131328391322432&#45;&gt;131328391322816 -->\n<g id=\"edge3\" class=\"edge\">\n<title>131328391322432&#45;&gt;131328391322816</title>\n<path fill=\"none\" stroke=\"black\" d=\"M289.5,-121.75C289.5,-114.8 289.5,-104.85 289.5,-96.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"293,-96.09 289.5,-86.09 286,-96.09 293,-96.09\"/>\n</g>\n<!-- 131328391322528 -->\n<g id=\"node6\" class=\"node\">\n<title>131328391322528</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"340,-201.5 239,-201.5 239,-182.5 340,-182.5 340,-201.5\"/>\n<text text-anchor=\"middle\" x=\"289.5\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n</g>\n<!-- 131328391322528&#45;&gt;131328391322432 -->\n<g id=\"edge4\" class=\"edge\">\n<title>131328391322528&#45;&gt;131328391322432</title>\n<path fill=\"none\" stroke=\"black\" d=\"M289.5,-182.37C289.5,-174.25 289.5,-161.81 289.5,-151.39\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"293,-151.17 289.5,-141.17 286,-151.17 293,-151.17\"/>\n</g>\n<!-- 131328391322240 -->\n<g id=\"node7\" class=\"node\">\n<title>131328391322240</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"200,-267.5 99,-267.5 99,-248.5 200,-248.5 200,-267.5\"/>\n<text text-anchor=\"middle\" x=\"149.5\" y=\"-255.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 131328391322240&#45;&gt;131328391322528 -->\n<g id=\"edge5\" class=\"edge\">\n<title>131328391322240&#45;&gt;131328391322528</title>\n<path fill=\"none\" stroke=\"black\" d=\"M168.38,-248.37C192.28,-237.44 233.67,-218.52 261.32,-205.88\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"262.83,-209.04 270.47,-201.7 259.92,-202.67 262.83,-209.04\"/>\n</g>\n<!-- 131328391407440 -->\n<g id=\"node8\" class=\"node\">\n<title>131328391407440</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"197,-339 102,-339 102,-309 197,-309 197,-339\"/>\n<text text-anchor=\"middle\" x=\"149.5\" y=\"-327\" font-family=\"monospace\" font-size=\"10.00\">layers.4.bias</text>\n<text text-anchor=\"middle\" x=\"149.5\" y=\"-316\" font-family=\"monospace\" font-size=\"10.00\"> (10)</text>\n</g>\n<!-- 131328391407440&#45;&gt;131328391322240 -->\n<g id=\"edge6\" class=\"edge\">\n<title>131328391407440&#45;&gt;131328391322240</title>\n<path fill=\"none\" stroke=\"black\" d=\"M149.5,-308.8C149.5,-299.7 149.5,-287.79 149.5,-277.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"153,-277.84 149.5,-267.84 146,-277.84 153,-277.84\"/>\n</g>\n<!-- 131328391322288 -->\n<g id=\"node9\" class=\"node\">\n<title>131328391322288</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"313,-267.5 218,-267.5 218,-248.5 313,-248.5 313,-267.5\"/>\n<text text-anchor=\"middle\" x=\"265.5\" y=\"-255.5\" font-family=\"monospace\" font-size=\"10.00\">ReluBackward0</text>\n</g>\n<!-- 131328391322288&#45;&gt;131328391322528 -->\n<g id=\"edge7\" class=\"edge\">\n<title>131328391322288&#45;&gt;131328391322528</title>\n<path fill=\"none\" stroke=\"black\" d=\"M268.74,-248.37C272.26,-238.97 278,-223.67 282.55,-211.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"285.93,-212.5 286.16,-201.91 279.37,-210.04 285.93,-212.5\"/>\n</g>\n<!-- 131328391322000 -->\n<g id=\"node10\" class=\"node\">\n<title>131328391322000</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"316,-333.5 215,-333.5 215,-314.5 316,-314.5 316,-333.5\"/>\n<text text-anchor=\"middle\" x=\"265.5\" y=\"-321.5\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n</g>\n<!-- 131328391322000&#45;&gt;131328391322288 -->\n<g id=\"edge8\" class=\"edge\">\n<title>131328391322000&#45;&gt;131328391322288</title>\n<path fill=\"none\" stroke=\"black\" d=\"M265.5,-314.37C265.5,-305.16 265.5,-290.29 265.5,-278.27\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"269,-277.91 265.5,-267.91 262,-277.91 269,-277.91\"/>\n</g>\n<!-- 131328391321808 -->\n<g id=\"node11\" class=\"node\">\n<title>131328391321808</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"153,-399.5 52,-399.5 52,-380.5 153,-380.5 153,-399.5\"/>\n<text text-anchor=\"middle\" x=\"102.5\" y=\"-387.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 131328391321808&#45;&gt;131328391322000 -->\n<g id=\"edge9\" class=\"edge\">\n<title>131328391321808&#45;&gt;131328391322000</title>\n<path fill=\"none\" stroke=\"black\" d=\"M124.48,-380.37C152.75,-369.27 202.04,-349.92 234.21,-337.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"235.58,-340.51 243.61,-333.6 233.02,-333.99 235.58,-340.51\"/>\n</g>\n<!-- 131328391407248 -->\n<g id=\"node12\" class=\"node\">\n<title>131328391407248</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"150,-471 55,-471 55,-441 150,-441 150,-471\"/>\n<text text-anchor=\"middle\" x=\"102.5\" y=\"-459\" font-family=\"monospace\" font-size=\"10.00\">layers.2.bias</text>\n<text text-anchor=\"middle\" x=\"102.5\" y=\"-448\" font-family=\"monospace\" font-size=\"10.00\"> (16)</text>\n</g>\n<!-- 131328391407248&#45;&gt;131328391321808 -->\n<g id=\"edge10\" class=\"edge\">\n<title>131328391407248&#45;&gt;131328391321808</title>\n<path fill=\"none\" stroke=\"black\" d=\"M102.5,-440.8C102.5,-431.7 102.5,-419.79 102.5,-409.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"106,-409.84 102.5,-399.84 99,-409.84 106,-409.84\"/>\n</g>\n<!-- 131328391321856 -->\n<g id=\"node13\" class=\"node\">\n<title>131328391321856</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"266,-399.5 171,-399.5 171,-380.5 266,-380.5 266,-399.5\"/>\n<text text-anchor=\"middle\" x=\"218.5\" y=\"-387.5\" font-family=\"monospace\" font-size=\"10.00\">ReluBackward0</text>\n</g>\n<!-- 131328391321856&#45;&gt;131328391322000 -->\n<g id=\"edge11\" class=\"edge\">\n<title>131328391321856&#45;&gt;131328391322000</title>\n<path fill=\"none\" stroke=\"black\" d=\"M224.84,-380.37C232.02,-370.59 243.89,-354.42 252.96,-342.08\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"255.86,-344.04 258.96,-333.91 250.22,-339.89 255.86,-344.04\"/>\n</g>\n<!-- 131328391321712 -->\n<g id=\"node14\" class=\"node\">\n<title>131328391321712</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"269,-465.5 168,-465.5 168,-446.5 269,-446.5 269,-465.5\"/>\n<text text-anchor=\"middle\" x=\"218.5\" y=\"-453.5\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n</g>\n<!-- 131328391321712&#45;&gt;131328391321856 -->\n<g id=\"edge12\" class=\"edge\">\n<title>131328391321712&#45;&gt;131328391321856</title>\n<path fill=\"none\" stroke=\"black\" d=\"M218.5,-446.37C218.5,-437.16 218.5,-422.29 218.5,-410.27\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"222,-409.91 218.5,-399.91 215,-409.91 222,-409.91\"/>\n</g>\n<!-- 131328391321424 -->\n<g id=\"node15\" class=\"node\">\n<title>131328391321424</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-531.5 0,-531.5 0,-512.5 101,-512.5 101,-531.5\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-519.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 131328391321424&#45;&gt;131328391321712 -->\n<g id=\"edge13\" class=\"edge\">\n<title>131328391321424&#45;&gt;131328391321712</title>\n<path fill=\"none\" stroke=\"black\" d=\"M73.16,-512.37C102.3,-501.27 153.09,-481.92 186.25,-469.28\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"187.84,-472.43 195.93,-465.6 185.34,-465.89 187.84,-472.43\"/>\n</g>\n<!-- 131328391407056 -->\n<g id=\"node16\" class=\"node\">\n<title>131328391407056</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"98,-603.5 3,-603.5 3,-573.5 98,-573.5 98,-603.5\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-591.5\" font-family=\"monospace\" font-size=\"10.00\">layers.0.bias</text>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-580.5\" font-family=\"monospace\" font-size=\"10.00\"> (32)</text>\n</g>\n<!-- 131328391407056&#45;&gt;131328391321424 -->\n<g id=\"edge14\" class=\"edge\">\n<title>131328391407056&#45;&gt;131328391321424</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-573.19C50.5,-563.91 50.5,-551.73 50.5,-541.69\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-541.54 50.5,-531.54 47,-541.54 54,-541.54\"/>\n</g>\n<!-- 131328391321472 -->\n<g id=\"node17\" class=\"node\">\n<title>131328391321472</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"220,-531.5 119,-531.5 119,-512.5 220,-512.5 220,-531.5\"/>\n<text text-anchor=\"middle\" x=\"169.5\" y=\"-519.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 131328391321472&#45;&gt;131328391321712 -->\n<g id=\"edge15\" class=\"edge\">\n<title>131328391321472&#45;&gt;131328391321712</title>\n<path fill=\"none\" stroke=\"black\" d=\"M176.11,-512.37C183.59,-502.59 195.97,-486.42 205.43,-474.08\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"208.38,-475.97 211.68,-465.91 202.82,-471.72 208.38,-475.97\"/>\n</g>\n<!-- 131328393321104 -->\n<g id=\"node18\" class=\"node\">\n<title>131328393321104</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"202,-604 137,-604 137,-573 202,-573 202,-604\"/>\n<text text-anchor=\"middle\" x=\"169.5\" y=\"-580\" font-family=\"monospace\" font-size=\"10.00\"> (1, 25)</text>\n</g>\n<!-- 131328393321104&#45;&gt;131328391321472 -->\n<g id=\"edge16\" class=\"edge\">\n<title>131328393321104&#45;&gt;131328391321472</title>\n<path fill=\"none\" stroke=\"black\" d=\"M169.5,-572.86C169.5,-563.68 169.5,-551.75 169.5,-541.86\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"173,-541.82 169.5,-531.82 166,-541.82 173,-541.82\"/>\n</g>\n<!-- 131328391321520 -->\n<g id=\"node19\" class=\"node\">\n<title>131328391321520</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"315,-531.5 238,-531.5 238,-512.5 315,-512.5 315,-531.5\"/>\n<text text-anchor=\"middle\" x=\"276.5\" y=\"-519.5\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n</g>\n<!-- 131328391321520&#45;&gt;131328391321712 -->\n<g id=\"edge17\" class=\"edge\">\n<title>131328391321520&#45;&gt;131328391321712</title>\n<path fill=\"none\" stroke=\"black\" d=\"M268.68,-512.37C259.65,-502.4 244.59,-485.79 233.33,-473.36\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"235.88,-470.96 226.57,-465.91 230.69,-475.67 235.88,-470.96\"/>\n</g>\n<!-- 131328391321136 -->\n<g id=\"node20\" class=\"node\">\n<title>131328391321136</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"327,-598 226,-598 226,-579 327,-579 327,-598\"/>\n<text text-anchor=\"middle\" x=\"276.5\" y=\"-586\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 131328391321136&#45;&gt;131328391321520 -->\n<g id=\"edge18\" class=\"edge\">\n<title>131328391321136&#45;&gt;131328391321520</title>\n<path fill=\"none\" stroke=\"black\" d=\"M276.5,-578.8C276.5,-569.32 276.5,-553.88 276.5,-541.64\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"280,-541.56 276.5,-531.56 273,-541.56 280,-541.56\"/>\n</g>\n<!-- 131328391406960 -->\n<g id=\"node21\" class=\"node\">\n<title>131328391406960</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"330,-670 223,-670 223,-640 330,-640 330,-670\"/>\n<text text-anchor=\"middle\" x=\"276.5\" y=\"-658\" font-family=\"monospace\" font-size=\"10.00\">layers.0.weight</text>\n<text text-anchor=\"middle\" x=\"276.5\" y=\"-647\" font-family=\"monospace\" font-size=\"10.00\"> (32, 25)</text>\n</g>\n<!-- 131328391406960&#45;&gt;131328391321136 -->\n<g id=\"edge19\" class=\"edge\">\n<title>131328391406960&#45;&gt;131328391321136</title>\n<path fill=\"none\" stroke=\"black\" d=\"M276.5,-639.69C276.5,-630.41 276.5,-618.23 276.5,-608.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"280,-608.04 276.5,-598.04 273,-608.04 280,-608.04\"/>\n</g>\n<!-- 131328391321904 -->\n<g id=\"node22\" class=\"node\">\n<title>131328391321904</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"361,-399.5 284,-399.5 284,-380.5 361,-380.5 361,-399.5\"/>\n<text text-anchor=\"middle\" x=\"322.5\" y=\"-387.5\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n</g>\n<!-- 131328391321904&#45;&gt;131328391322000 -->\n<g id=\"edge20\" class=\"edge\">\n<title>131328391321904&#45;&gt;131328391322000</title>\n<path fill=\"none\" stroke=\"black\" d=\"M314.81,-380.37C306.02,-370.5 291.43,-354.11 280.39,-341.72\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"282.7,-339.05 273.43,-333.91 277.47,-343.7 282.7,-339.05\"/>\n</g>\n<!-- 131328391321184 -->\n<g id=\"node23\" class=\"node\">\n<title>131328391321184</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"412,-465.5 311,-465.5 311,-446.5 412,-446.5 412,-465.5\"/>\n<text text-anchor=\"middle\" x=\"361.5\" y=\"-453.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 131328391321184&#45;&gt;131328391321904 -->\n<g id=\"edge21\" class=\"edge\">\n<title>131328391321184&#45;&gt;131328391321904</title>\n<path fill=\"none\" stroke=\"black\" d=\"M356.24,-446.37C350.4,-436.78 340.81,-421.05 333.35,-408.8\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"336.12,-406.62 327.93,-399.91 330.14,-410.27 336.12,-406.62\"/>\n</g>\n<!-- 131328391407152 -->\n<g id=\"node24\" class=\"node\">\n<title>131328391407152</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"440,-537 333,-537 333,-507 440,-507 440,-537\"/>\n<text text-anchor=\"middle\" x=\"386.5\" y=\"-525\" font-family=\"monospace\" font-size=\"10.00\">layers.2.weight</text>\n<text text-anchor=\"middle\" x=\"386.5\" y=\"-514\" font-family=\"monospace\" font-size=\"10.00\"> (16, 32)</text>\n</g>\n<!-- 131328391407152&#45;&gt;131328391321184 -->\n<g id=\"edge22\" class=\"edge\">\n<title>131328391407152&#45;&gt;131328391321184</title>\n<path fill=\"none\" stroke=\"black\" d=\"M380.95,-506.8C377.32,-497.5 372.54,-485.27 368.63,-475.26\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"371.85,-473.89 364.95,-465.84 365.33,-476.43 371.85,-473.89\"/>\n</g>\n<!-- 131328391322576 -->\n<g id=\"node25\" class=\"node\">\n<title>131328391322576</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"408,-267.5 331,-267.5 331,-248.5 408,-248.5 408,-267.5\"/>\n<text text-anchor=\"middle\" x=\"369.5\" y=\"-255.5\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n</g>\n<!-- 131328391322576&#45;&gt;131328391322528 -->\n<g id=\"edge23\" class=\"edge\">\n<title>131328391322576&#45;&gt;131328391322528</title>\n<path fill=\"none\" stroke=\"black\" d=\"M358.71,-248.37C345.83,-238.06 324.06,-220.65 308.37,-208.09\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"310.37,-205.21 300.37,-201.7 306,-210.68 310.37,-205.21\"/>\n</g>\n<!-- 131328391321328 -->\n<g id=\"node26\" class=\"node\">\n<title>131328391321328</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"459,-333.5 358,-333.5 358,-314.5 459,-314.5 459,-333.5\"/>\n<text text-anchor=\"middle\" x=\"408.5\" y=\"-321.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 131328391321328&#45;&gt;131328391322576 -->\n<g id=\"edge24\" class=\"edge\">\n<title>131328391321328&#45;&gt;131328391322576</title>\n<path fill=\"none\" stroke=\"black\" d=\"M403.24,-314.37C397.4,-304.78 387.81,-289.05 380.35,-276.8\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"383.12,-274.62 374.93,-267.91 377.14,-278.27 383.12,-274.62\"/>\n</g>\n<!-- 131328391407344 -->\n<g id=\"node27\" class=\"node\">\n<title>131328391407344</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"486,-405 379,-405 379,-375 486,-375 486,-405\"/>\n<text text-anchor=\"middle\" x=\"432.5\" y=\"-393\" font-family=\"monospace\" font-size=\"10.00\">layers.4.weight</text>\n<text text-anchor=\"middle\" x=\"432.5\" y=\"-382\" font-family=\"monospace\" font-size=\"10.00\"> (10, 16)</text>\n</g>\n<!-- 131328391407344&#45;&gt;131328391321328 -->\n<g id=\"edge25\" class=\"edge\">\n<title>131328391407344&#45;&gt;131328391321328</title>\n<path fill=\"none\" stroke=\"black\" d=\"M427.17,-374.8C423.69,-365.5 419.1,-353.27 415.35,-343.26\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"418.61,-341.98 411.82,-333.84 412.05,-344.44 418.61,-341.98\"/>\n</g>\n<!-- 131328391322480 -->\n<g id=\"node28\" class=\"node\">\n<title>131328391322480</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"463,-141 386,-141 386,-122 463,-122 463,-141\"/>\n<text text-anchor=\"middle\" x=\"424.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n</g>\n<!-- 131328391322480&#45;&gt;131328391322816 -->\n<g id=\"edge26\" class=\"edge\">\n<title>131328391322480&#45;&gt;131328391322816</title>\n<path fill=\"none\" stroke=\"black\" d=\"M402.81,-121.98C380.7,-113.3 346.18,-99.75 321.05,-89.88\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"322.17,-86.57 311.58,-86.17 319.61,-93.08 322.17,-86.57\"/>\n</g>\n<!-- 131328391321760 -->\n<g id=\"node29\" class=\"node\">\n<title>131328391321760</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"506,-201.5 405,-201.5 405,-182.5 506,-182.5 506,-201.5\"/>\n<text text-anchor=\"middle\" x=\"455.5\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 131328391321760&#45;&gt;131328391322480 -->\n<g id=\"edge27\" class=\"edge\">\n<title>131328391321760&#45;&gt;131328391322480</title>\n<path fill=\"none\" stroke=\"black\" d=\"M450.93,-182.37C446.44,-173.9 439.47,-160.74 433.81,-150.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"436.87,-148.36 429.09,-141.17 430.68,-151.64 436.87,-148.36\"/>\n</g>\n<!-- 131328391407536 -->\n<g id=\"node30\" class=\"node\">\n<title>131328391407536</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"533,-273 426,-273 426,-243 533,-243 533,-273\"/>\n<text text-anchor=\"middle\" x=\"479.5\" y=\"-261\" font-family=\"monospace\" font-size=\"10.00\">layers.6.weight</text>\n<text text-anchor=\"middle\" x=\"479.5\" y=\"-250\" font-family=\"monospace\" font-size=\"10.00\"> (2, 10)</text>\n</g>\n<!-- 131328391407536&#45;&gt;131328391321760 -->\n<g id=\"edge28\" class=\"edge\">\n<title>131328391407536&#45;&gt;131328391321760</title>\n<path fill=\"none\" stroke=\"black\" d=\"M474.17,-242.8C470.69,-233.5 466.1,-221.27 462.35,-211.26\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"465.61,-209.98 458.82,-201.84 459.05,-212.44 465.61,-209.98\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7771462f7f10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-19T10:57:36.706231Z",
     "start_time": "2025-04-19T10:57:36.526634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# If not installed, uncomment the next line:\n",
    "# !pip install torchsummary\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "def visualize_model_summary(model, input_size):\n",
    "    # input_size should be a tuple without batch size, e.g. (number_of_features,)\n",
    "    summary(model, input_size)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "input_size = X_train.shape[1]\n",
    "output_size = y_train.shape[1]\n",
    "model = MultiTargetRegressor(input_size, output_size)\n",
    "\n",
    "visualize_model_summary(model, input_size=(X_train.shape[1],))\n"
   ],
   "id": "b3cde278ae0feeb0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                   [-1, 32]             832\n",
      "              ReLU-2                   [-1, 32]               0\n",
      "            Linear-3                   [-1, 16]             528\n",
      "              ReLU-4                   [-1, 16]               0\n",
      "            Linear-5                    [-1, 2]              34\n",
      "================================================================\n",
      "Total params: 1,394\n",
      "Trainable params: 1,394\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.01\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Model Training Function:",
   "id": "a786d8c007b1e06"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T08:09:38.152829Z",
     "start_time": "2025-05-08T08:09:38.108436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(model, train_loader, test_loader, num_epochs=100):\n",
    "    \"\"\"Training loop with validation monitoring\"\"\"\n",
    "    # Loss function and optimizer\n",
    "    learning_rate = 0.01\n",
    "    loss_function = nn.MSELoss()  # Mean Squared Error for regression\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5, verbose=True)\n",
    "\n",
    "    # Track losses for visualization\n",
    "    train_losses, val_losses = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        epoch_train_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()  # Reset gradients\n",
    "            outputs = model(X_batch)  # Forward pass\n",
    "            loss = loss_function(outputs, y_batch)  # Compute loss\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Update weights\n",
    "            epoch_train_loss += loss.item()\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        epoch_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in test_loader:\n",
    "                outputs = model(X_batch)\n",
    "                loss = loss_function(outputs, y_batch)\n",
    "                epoch_val_loss += loss.item()\n",
    "\n",
    "        # Calculate average losses\n",
    "        train_loss = epoch_train_loss / len(train_loader)\n",
    "        val_loss = epoch_val_loss / len(test_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # Update learning rate\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}')\n",
    "\n",
    "    return train_losses, val_losses\n"
   ],
   "id": "1e9fb176a0a77840",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T07:54:19.946449Z",
     "start_time": "2025-05-08T07:50:06.901238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Model Training\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "output_size = y_train.shape[1]\n",
    "model = MultiTargetRegressor(input_size, output_size)\n",
    "\n",
    "# Train model\n",
    "train_losses, val_losses = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    num_epochs=30\n",
    ")\n",
    "\n",
    "#"
   ],
   "id": "f7ddddfc66b070aa",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sparashar/Installed/miniconda3/envs/calisma/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 | Train Loss: 0.6234 | Val Loss: 0.5815\n",
      "Epoch 2/30 | Train Loss: 0.5919 | Val Loss: 0.5786\n",
      "Epoch 3/30 | Train Loss: 0.5866 | Val Loss: 0.5748\n",
      "Epoch 4/30 | Train Loss: 0.5803 | Val Loss: 0.5766\n",
      "Epoch 5/30 | Train Loss: 0.5775 | Val Loss: 0.5800\n",
      "Epoch 6/30 | Train Loss: 0.5748 | Val Loss: 0.5697\n",
      "Epoch 7/30 | Train Loss: 0.5747 | Val Loss: 0.5673\n",
      "Epoch 8/30 | Train Loss: 0.5722 | Val Loss: 0.5679\n",
      "Epoch 9/30 | Train Loss: 0.5704 | Val Loss: 0.5731\n",
      "Epoch 10/30 | Train Loss: 0.5698 | Val Loss: 0.5738\n",
      "Epoch 11/30 | Train Loss: 0.5696 | Val Loss: 0.5602\n",
      "Epoch 12/30 | Train Loss: 0.5695 | Val Loss: 0.5611\n",
      "Epoch 13/30 | Train Loss: 0.5691 | Val Loss: 0.5695\n",
      "Epoch 14/30 | Train Loss: 0.5682 | Val Loss: 0.5718\n",
      "Epoch 15/30 | Train Loss: 0.5683 | Val Loss: 0.5754\n",
      "Epoch 16/30 | Train Loss: 0.5675 | Val Loss: 0.5797\n",
      "Epoch 17/30 | Train Loss: 0.5668 | Val Loss: 0.5721\n",
      "Epoch 18/30 | Train Loss: 0.5448 | Val Loss: 0.5514\n",
      "Epoch 19/30 | Train Loss: 0.5415 | Val Loss: 0.5520\n",
      "Epoch 20/30 | Train Loss: 0.5408 | Val Loss: 0.5532\n",
      "Epoch 21/30 | Train Loss: 0.5403 | Val Loss: 0.5523\n",
      "Epoch 22/30 | Train Loss: 0.5400 | Val Loss: 0.5535\n",
      "Epoch 23/30 | Train Loss: 0.5398 | Val Loss: 0.5490\n",
      "Epoch 24/30 | Train Loss: 0.5395 | Val Loss: 0.5507\n",
      "Epoch 25/30 | Train Loss: 0.5395 | Val Loss: 0.5524\n",
      "Epoch 26/30 | Train Loss: 0.5391 | Val Loss: 0.5507\n",
      "Epoch 27/30 | Train Loss: 0.5392 | Val Loss: 0.5497\n",
      "Epoch 28/30 | Train Loss: 0.5389 | Val Loss: 0.5518\n",
      "Epoch 29/30 | Train Loss: 0.5388 | Val Loss: 0.5524\n",
      "Epoch 30/30 | Train Loss: 0.5361 | Val Loss: 0.5511\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T08:11:34.318125Z",
     "start_time": "2025-05-08T08:10:04.480030Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define your hyperparameter grid\n",
    "param_grid = {\n",
    "    'lr': [0.01, 0.001],\n",
    "    'batch_size': [32, 64],\n",
    "    'hidden1': [128, 256]\n",
    "}\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_params = None\n",
    "\n",
    "for lr, batch_size, hidden1 in product(param_grid['lr'], param_grid['batch_size'], param_grid['hidden1']):\n",
    "    # Prepare data loaders with batch_size\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    # Define model with current hidden layer size\n",
    "    model = MultiTargetRegressor(input_size, output_size)\n",
    "    # Optionally, modify your model to accept hidden1 as a parameter\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Train for a few epochs (e.g., 5 for speed)\n",
    "    for epoch in range(5):\n",
    "        model.train()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            val_loss += loss.item()\n",
    "    val_loss /= len(test_loader)\n",
    "\n",
    "    # Save best\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_params = {'lr': lr, 'batch_size': batch_size, 'hidden1': hidden1}\n",
    "\n",
    "print(\"Best params:\", best_params)\n",
    "print(\"Best validation loss:\", best_val_loss)\n"
   ],
   "id": "aab9916eaa3b2042",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 31\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m5\u001B[39m):\n\u001B[1;32m     30\u001B[0m     model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m---> 31\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m X_batch, y_batch \u001B[38;5;129;01min\u001B[39;00m train_loader:\n\u001B[1;32m     32\u001B[0m         optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m     33\u001B[0m         outputs \u001B[38;5;241m=\u001B[39m model(X_batch)\n",
      "File \u001B[0;32m~/Installed/miniconda3/envs/calisma/lib/python3.11/site-packages/torch/utils/data/dataloader.py:708\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    705\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    706\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    707\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 708\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_data()\n\u001B[1;32m    709\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    710\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    711\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[1;32m    712\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    713\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called\n\u001B[1;32m    714\u001B[0m ):\n",
      "File \u001B[0;32m~/Installed/miniconda3/envs/calisma/lib/python3.11/site-packages/torch/utils/data/dataloader.py:764\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    762\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    763\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 764\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_fetcher\u001B[38;5;241m.\u001B[39mfetch(index)  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    765\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    766\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m~/Installed/miniconda3/envs/calisma/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:55\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     54\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n\u001B[0;32m---> 55\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcollate_fn(data)\n",
      "File \u001B[0;32m~/Installed/miniconda3/envs/calisma/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:398\u001B[0m, in \u001B[0;36mdefault_collate\u001B[0;34m(batch)\u001B[0m\n\u001B[1;32m    337\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdefault_collate\u001B[39m(batch):\n\u001B[1;32m    338\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    339\u001B[0m \u001B[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001B[39;00m\n\u001B[1;32m    340\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    396\u001B[0m \u001B[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001B[39;00m\n\u001B[1;32m    397\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 398\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m collate(batch, collate_fn_map\u001B[38;5;241m=\u001B[39mdefault_collate_fn_map)\n",
      "File \u001B[0;32m~/Installed/miniconda3/envs/calisma/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:211\u001B[0m, in \u001B[0;36mcollate\u001B[0;34m(batch, collate_fn_map)\u001B[0m\n\u001B[1;32m    208\u001B[0m transposed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch))  \u001B[38;5;66;03m# It may be accessed twice, so we use a list.\u001B[39;00m\n\u001B[1;32m    210\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m--> 211\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\n\u001B[1;32m    212\u001B[0m         collate(samples, collate_fn_map\u001B[38;5;241m=\u001B[39mcollate_fn_map)\n\u001B[1;32m    213\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m transposed\n\u001B[1;32m    214\u001B[0m     ]  \u001B[38;5;66;03m# Backwards compatibility.\u001B[39;00m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/Installed/miniconda3/envs/calisma/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:212\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    208\u001B[0m transposed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch))  \u001B[38;5;66;03m# It may be accessed twice, so we use a list.\u001B[39;00m\n\u001B[1;32m    210\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m    211\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\n\u001B[0;32m--> 212\u001B[0m         collate(samples, collate_fn_map\u001B[38;5;241m=\u001B[39mcollate_fn_map)\n\u001B[1;32m    213\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m transposed\n\u001B[1;32m    214\u001B[0m     ]  \u001B[38;5;66;03m# Backwards compatibility.\u001B[39;00m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/Installed/miniconda3/envs/calisma/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:155\u001B[0m, in \u001B[0;36mcollate\u001B[0;34m(batch, collate_fn_map)\u001B[0m\n\u001B[1;32m    153\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m collate_fn_map \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    154\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m elem_type \u001B[38;5;129;01min\u001B[39;00m collate_fn_map:\n\u001B[0;32m--> 155\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m collate_fn_map[elem_type](batch, collate_fn_map\u001B[38;5;241m=\u001B[39mcollate_fn_map)\n\u001B[1;32m    157\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m collate_type \u001B[38;5;129;01min\u001B[39;00m collate_fn_map:\n\u001B[1;32m    158\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, collate_type):\n",
      "File \u001B[0;32m~/Installed/miniconda3/envs/calisma/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:272\u001B[0m, in \u001B[0;36mcollate_tensor_fn\u001B[0;34m(batch, collate_fn_map)\u001B[0m\n\u001B[1;32m    270\u001B[0m     storage \u001B[38;5;241m=\u001B[39m elem\u001B[38;5;241m.\u001B[39m_typed_storage()\u001B[38;5;241m.\u001B[39m_new_shared(numel, device\u001B[38;5;241m=\u001B[39melem\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m    271\u001B[0m     out \u001B[38;5;241m=\u001B[39m elem\u001B[38;5;241m.\u001B[39mnew(storage)\u001B[38;5;241m.\u001B[39mresize_(\u001B[38;5;28mlen\u001B[39m(batch), \u001B[38;5;241m*\u001B[39m\u001B[38;5;28mlist\u001B[39m(elem\u001B[38;5;241m.\u001B[39msize()))\n\u001B[0;32m--> 272\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mstack(batch, \u001B[38;5;241m0\u001B[39m, out\u001B[38;5;241m=\u001B[39mout)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T08:11:34.397065898Z",
     "start_time": "2025-04-18T10:32:07.105094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# Define the hyperparameter space\n",
    "param_space = {\n",
    "    'lr': [1e-3, 5e-4, 1e-4, 5e-5],\n",
    "    'batch_size': [16, 32, 64, 128],\n",
    "    'num_epochs': [10, 20, 30],\n",
    "    # Add more hyperparameters as needed\n",
    "}\n",
    "\n",
    "n_trials = 10  # Number of random samples\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_params = None\n",
    "\n",
    "for trial in range(n_trials):\n",
    "    # Randomly sample hyperparameters\n",
    "    lr = random.choice(param_space['lr'])\n",
    "    batch_size = random.choice(param_space['batch_size'])\n",
    "    num_epochs = random.choice(param_space['num_epochs'])\n",
    "\n",
    "    # Create new dataloaders for this batch size\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    # Initialize model\n",
    "    model = MultiTargetRegressor(input_size, output_size)\n",
    "\n",
    "    # Set optimizer with sampled learning rate\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Train model (use your train_model function)\n",
    "    train_losses, val_losses = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        test_loader=test_loader,\n",
    "        num_epochs=num_epochs\n",
    "    )\n",
    "\n",
    "    # Use the last validation loss as the metric\n",
    "    final_val_loss = val_losses[-1]\n",
    "\n",
    "    print(f\"Trial {trial+1}: lr={lr}, batch_size={batch_size}, num_epochs={num_epochs}, val_loss={final_val_loss:.4f}\")\n",
    "\n",
    "    # Track the best hyperparameters\n",
    "    if final_val_loss < best_val_loss:\n",
    "        best_val_loss = final_val_loss\n",
    "        best_params = {\n",
    "            'lr': lr,\n",
    "            'batch_size': batch_size,\n",
    "            'num_epochs': num_epochs\n",
    "        }\n",
    "\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "print(\"Best validation loss:\", best_val_loss)\n"
   ],
   "id": "4686c18c0136136a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sparashar/Installed/miniconda3/envs/calisma/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 | Train Loss: 0.3935 | Val Loss: 0.3502\n",
      "Epoch 2/30 | Train Loss: 0.3534 | Val Loss: 0.3271\n",
      "Epoch 3/30 | Train Loss: 0.3437 | Val Loss: 0.3257\n",
      "Epoch 4/30 | Train Loss: 0.3372 | Val Loss: 0.3281\n",
      "Epoch 5/30 | Train Loss: 0.3329 | Val Loss: 0.3223\n",
      "Epoch 6/30 | Train Loss: 0.3290 | Val Loss: 0.3257\n",
      "Epoch 7/30 | Train Loss: 0.3258 | Val Loss: 0.3290\n",
      "Epoch 8/30 | Train Loss: 0.3232 | Val Loss: 0.3324\n",
      "Epoch 9/30 | Train Loss: 0.3211 | Val Loss: 0.3279\n",
      "Epoch 10/30 | Train Loss: 0.3188 | Val Loss: 0.3263\n",
      "Epoch 11/30 | Train Loss: 0.3168 | Val Loss: 0.3356\n",
      "Epoch 12/30 | Train Loss: 0.3044 | Val Loss: 0.3258\n",
      "Epoch 13/30 | Train Loss: 0.3014 | Val Loss: 0.3263\n",
      "Epoch 14/30 | Train Loss: 0.3003 | Val Loss: 0.3260\n",
      "Epoch 15/30 | Train Loss: 0.2995 | Val Loss: 0.3262\n",
      "Epoch 16/30 | Train Loss: 0.2989 | Val Loss: 0.3284\n",
      "Epoch 17/30 | Train Loss: 0.2984 | Val Loss: 0.3280\n",
      "Epoch 18/30 | Train Loss: 0.2964 | Val Loss: 0.3278\n",
      "Epoch 19/30 | Train Loss: 0.2962 | Val Loss: 0.3276\n",
      "Epoch 20/30 | Train Loss: 0.2960 | Val Loss: 0.3278\n",
      "Epoch 21/30 | Train Loss: 0.2960 | Val Loss: 0.3284\n",
      "Epoch 22/30 | Train Loss: 0.2959 | Val Loss: 0.3282\n",
      "Epoch 23/30 | Train Loss: 0.2958 | Val Loss: 0.3282\n",
      "Epoch 24/30 | Train Loss: 0.2956 | Val Loss: 0.3282\n",
      "Epoch 25/30 | Train Loss: 0.2956 | Val Loss: 0.3283\n",
      "Epoch 26/30 | Train Loss: 0.2956 | Val Loss: 0.3282\n",
      "Epoch 27/30 | Train Loss: 0.2956 | Val Loss: 0.3283\n",
      "Epoch 28/30 | Train Loss: 0.2956 | Val Loss: 0.3282\n",
      "Epoch 29/30 | Train Loss: 0.2956 | Val Loss: 0.3282\n",
      "Epoch 30/30 | Train Loss: 0.2955 | Val Loss: 0.3282\n",
      "Trial 1: lr=0.0005, batch_size=32, num_epochs=30, val_loss=0.3282\n",
      "Epoch 1/20 | Train Loss: 0.3886 | Val Loss: 0.3365\n",
      "Epoch 2/20 | Train Loss: 0.3526 | Val Loss: 0.3320\n",
      "Epoch 3/20 | Train Loss: 0.3427 | Val Loss: 0.3275\n",
      "Epoch 4/20 | Train Loss: 0.3365 | Val Loss: 0.3229\n",
      "Epoch 5/20 | Train Loss: 0.3321 | Val Loss: 0.3251\n",
      "Epoch 6/20 | Train Loss: 0.3287 | Val Loss: 0.3216\n",
      "Epoch 7/20 | Train Loss: 0.3256 | Val Loss: 0.3240\n",
      "Epoch 8/20 | Train Loss: 0.3230 | Val Loss: 0.3235\n",
      "Epoch 9/20 | Train Loss: 0.3207 | Val Loss: 0.3322\n",
      "Epoch 10/20 | Train Loss: 0.3185 | Val Loss: 0.3260\n",
      "Epoch 11/20 | Train Loss: 0.3169 | Val Loss: 0.3293\n",
      "Epoch 12/20 | Train Loss: 0.3151 | Val Loss: 0.3308\n",
      "Epoch 13/20 | Train Loss: 0.3023 | Val Loss: 0.3239\n",
      "Epoch 14/20 | Train Loss: 0.2992 | Val Loss: 0.3247\n",
      "Epoch 15/20 | Train Loss: 0.2981 | Val Loss: 0.3275\n",
      "Epoch 16/20 | Train Loss: 0.2973 | Val Loss: 0.3269\n",
      "Epoch 17/20 | Train Loss: 0.2967 | Val Loss: 0.3272\n",
      "Epoch 18/20 | Train Loss: 0.2961 | Val Loss: 0.3272\n",
      "Epoch 19/20 | Train Loss: 0.2940 | Val Loss: 0.3280\n",
      "Epoch 20/20 | Train Loss: 0.2938 | Val Loss: 0.3278\n",
      "Trial 2: lr=0.0005, batch_size=32, num_epochs=20, val_loss=0.3278\n",
      "Epoch 1/20 | Train Loss: 0.4073 | Val Loss: 0.3395\n",
      "Epoch 2/20 | Train Loss: 0.3589 | Val Loss: 0.3312\n",
      "Epoch 3/20 | Train Loss: 0.3480 | Val Loss: 0.3332\n",
      "Epoch 4/20 | Train Loss: 0.3417 | Val Loss: 0.3281\n",
      "Epoch 5/20 | Train Loss: 0.3363 | Val Loss: 0.3305\n",
      "Epoch 6/20 | Train Loss: 0.3324 | Val Loss: 0.3256\n",
      "Epoch 7/20 | Train Loss: 0.3290 | Val Loss: 0.3317\n",
      "Epoch 8/20 | Train Loss: 0.3261 | Val Loss: 0.3273\n",
      "Epoch 9/20 | Train Loss: 0.3239 | Val Loss: 0.3296\n",
      "Epoch 10/20 | Train Loss: 0.3213 | Val Loss: 0.3262\n",
      "Epoch 11/20 | Train Loss: 0.3194 | Val Loss: 0.3285\n",
      "Epoch 12/20 | Train Loss: 0.3175 | Val Loss: 0.3271\n",
      "Epoch 13/20 | Train Loss: 0.3061 | Val Loss: 0.3235\n",
      "Epoch 14/20 | Train Loss: 0.3038 | Val Loss: 0.3253\n",
      "Epoch 15/20 | Train Loss: 0.3029 | Val Loss: 0.3259\n",
      "Epoch 16/20 | Train Loss: 0.3023 | Val Loss: 0.3274\n",
      "Epoch 17/20 | Train Loss: 0.3018 | Val Loss: 0.3270\n",
      "Epoch 18/20 | Train Loss: 0.3013 | Val Loss: 0.3284\n",
      "Epoch 19/20 | Train Loss: 0.3008 | Val Loss: 0.3276\n",
      "Epoch 20/20 | Train Loss: 0.2992 | Val Loss: 0.3277\n",
      "Trial 3: lr=0.0005, batch_size=64, num_epochs=20, val_loss=0.3277\n",
      "Epoch 1/30 | Train Loss: 0.3820 | Val Loss: 0.3366\n",
      "Epoch 2/30 | Train Loss: 0.3506 | Val Loss: 0.3307\n",
      "Epoch 3/30 | Train Loss: 0.3415 | Val Loss: 0.3247\n",
      "Epoch 4/30 | Train Loss: 0.3354 | Val Loss: 0.3290\n",
      "Epoch 5/30 | Train Loss: 0.3308 | Val Loss: 0.3240\n",
      "Epoch 6/30 | Train Loss: 0.3276 | Val Loss: 0.3271\n",
      "Epoch 7/30 | Train Loss: 0.3246 | Val Loss: 0.3261\n",
      "Epoch 8/30 | Train Loss: 0.3219 | Val Loss: 0.3302\n",
      "Epoch 9/30 | Train Loss: 0.3200 | Val Loss: 0.3245\n",
      "Epoch 10/30 | Train Loss: 0.3179 | Val Loss: 0.3261\n",
      "Epoch 11/30 | Train Loss: 0.3157 | Val Loss: 0.3292\n",
      "Epoch 12/30 | Train Loss: 0.3010 | Val Loss: 0.3249\n",
      "Epoch 13/30 | Train Loss: 0.2974 | Val Loss: 0.3262\n",
      "Epoch 14/30 | Train Loss: 0.2960 | Val Loss: 0.3264\n",
      "Epoch 15/30 | Train Loss: 0.2951 | Val Loss: 0.3269\n",
      "Epoch 16/30 | Train Loss: 0.2944 | Val Loss: 0.3272\n",
      "Epoch 17/30 | Train Loss: 0.2938 | Val Loss: 0.3291\n",
      "Epoch 18/30 | Train Loss: 0.2913 | Val Loss: 0.3286\n",
      "Epoch 19/30 | Train Loss: 0.2911 | Val Loss: 0.3288\n",
      "Epoch 20/30 | Train Loss: 0.2909 | Val Loss: 0.3287\n",
      "Epoch 21/30 | Train Loss: 0.2908 | Val Loss: 0.3292\n",
      "Epoch 22/30 | Train Loss: 0.2908 | Val Loss: 0.3290\n",
      "Epoch 23/30 | Train Loss: 0.2907 | Val Loss: 0.3297\n",
      "Epoch 24/30 | Train Loss: 0.2904 | Val Loss: 0.3294\n",
      "Epoch 25/30 | Train Loss: 0.2904 | Val Loss: 0.3293\n",
      "Epoch 26/30 | Train Loss: 0.2904 | Val Loss: 0.3293\n",
      "Epoch 27/30 | Train Loss: 0.2903 | Val Loss: 0.3293\n",
      "Epoch 28/30 | Train Loss: 0.2903 | Val Loss: 0.3293\n",
      "Epoch 29/30 | Train Loss: 0.2903 | Val Loss: 0.3293\n",
      "Epoch 30/30 | Train Loss: 0.2903 | Val Loss: 0.3293\n",
      "Trial 4: lr=5e-05, batch_size=16, num_epochs=30, val_loss=0.3293\n",
      "Epoch 1/30 | Train Loss: 0.3825 | Val Loss: 0.3311\n",
      "Epoch 2/30 | Train Loss: 0.3505 | Val Loss: 0.3321\n",
      "Epoch 3/30 | Train Loss: 0.3419 | Val Loss: 0.3259\n",
      "Epoch 4/30 | Train Loss: 0.3360 | Val Loss: 0.3237\n",
      "Epoch 5/30 | Train Loss: 0.3318 | Val Loss: 0.3215\n",
      "Epoch 6/30 | Train Loss: 0.3286 | Val Loss: 0.3317\n",
      "Epoch 7/30 | Train Loss: 0.3259 | Val Loss: 0.3234\n",
      "Epoch 8/30 | Train Loss: 0.3235 | Val Loss: 0.3274\n",
      "Epoch 9/30 | Train Loss: 0.3209 | Val Loss: 0.3262\n",
      "Epoch 10/30 | Train Loss: 0.3191 | Val Loss: 0.3279\n",
      "Epoch 11/30 | Train Loss: 0.3171 | Val Loss: 0.3296\n",
      "Epoch 12/30 | Train Loss: 0.3027 | Val Loss: 0.3239\n",
      "Epoch 13/30 | Train Loss: 0.2992 | Val Loss: 0.3262\n",
      "Epoch 14/30 | Train Loss: 0.2980 | Val Loss: 0.3258\n",
      "Epoch 15/30 | Train Loss: 0.2971 | Val Loss: 0.3256\n",
      "Epoch 16/30 | Train Loss: 0.2965 | Val Loss: 0.3268\n",
      "Epoch 17/30 | Train Loss: 0.2959 | Val Loss: 0.3284\n",
      "Epoch 18/30 | Train Loss: 0.2935 | Val Loss: 0.3280\n",
      "Epoch 19/30 | Train Loss: 0.2932 | Val Loss: 0.3274\n",
      "Epoch 20/30 | Train Loss: 0.2931 | Val Loss: 0.3280\n",
      "Epoch 21/30 | Train Loss: 0.2930 | Val Loss: 0.3280\n",
      "Epoch 22/30 | Train Loss: 0.2929 | Val Loss: 0.3281\n",
      "Epoch 23/30 | Train Loss: 0.2929 | Val Loss: 0.3280\n",
      "Epoch 24/30 | Train Loss: 0.2926 | Val Loss: 0.3282\n",
      "Epoch 25/30 | Train Loss: 0.2925 | Val Loss: 0.3283\n",
      "Epoch 26/30 | Train Loss: 0.2925 | Val Loss: 0.3283\n",
      "Epoch 27/30 | Train Loss: 0.2925 | Val Loss: 0.3283\n",
      "Epoch 28/30 | Train Loss: 0.2925 | Val Loss: 0.3283\n",
      "Epoch 29/30 | Train Loss: 0.2925 | Val Loss: 0.3283\n",
      "Epoch 30/30 | Train Loss: 0.2925 | Val Loss: 0.3283\n",
      "Trial 5: lr=0.0005, batch_size=16, num_epochs=30, val_loss=0.3283\n",
      "Epoch 1/10 | Train Loss: 0.3947 | Val Loss: 0.3391\n",
      "Epoch 2/10 | Train Loss: 0.3568 | Val Loss: 0.3295\n",
      "Epoch 3/10 | Train Loss: 0.3464 | Val Loss: 0.3268\n",
      "Epoch 4/10 | Train Loss: 0.3398 | Val Loss: 0.3279\n",
      "Epoch 5/10 | Train Loss: 0.3351 | Val Loss: 0.3230\n",
      "Epoch 6/10 | Train Loss: 0.3308 | Val Loss: 0.3283\n",
      "Epoch 7/10 | Train Loss: 0.3277 | Val Loss: 0.3223\n",
      "Epoch 8/10 | Train Loss: 0.3245 | Val Loss: 0.3238\n",
      "Epoch 9/10 | Train Loss: 0.3224 | Val Loss: 0.3273\n",
      "Epoch 10/10 | Train Loss: 0.3198 | Val Loss: 0.3261\n",
      "Trial 6: lr=0.0005, batch_size=64, num_epochs=10, val_loss=0.3261\n",
      "Epoch 1/20 | Train Loss: 0.3869 | Val Loss: 0.3354\n",
      "Epoch 2/20 | Train Loss: 0.3521 | Val Loss: 0.3299\n",
      "Epoch 3/20 | Train Loss: 0.3420 | Val Loss: 0.3241\n",
      "Epoch 4/20 | Train Loss: 0.3361 | Val Loss: 0.3237\n",
      "Epoch 5/20 | Train Loss: 0.3320 | Val Loss: 0.3236\n",
      "Epoch 6/20 | Train Loss: 0.3282 | Val Loss: 0.3259\n",
      "Epoch 7/20 | Train Loss: 0.3254 | Val Loss: 0.3252\n",
      "Epoch 8/20 | Train Loss: 0.3229 | Val Loss: 0.3274\n",
      "Epoch 9/20 | Train Loss: 0.3203 | Val Loss: 0.3264\n",
      "Epoch 10/20 | Train Loss: 0.3186 | Val Loss: 0.3275\n",
      "Epoch 11/20 | Train Loss: 0.3167 | Val Loss: 0.3250\n",
      "Epoch 12/20 | Train Loss: 0.3043 | Val Loss: 0.3240\n",
      "Epoch 13/20 | Train Loss: 0.3012 | Val Loss: 0.3252\n",
      "Epoch 14/20 | Train Loss: 0.3001 | Val Loss: 0.3246\n",
      "Epoch 15/20 | Train Loss: 0.2993 | Val Loss: 0.3260\n",
      "Epoch 16/20 | Train Loss: 0.2987 | Val Loss: 0.3268\n",
      "Epoch 17/20 | Train Loss: 0.2981 | Val Loss: 0.3296\n",
      "Epoch 18/20 | Train Loss: 0.2962 | Val Loss: 0.3274\n",
      "Epoch 19/20 | Train Loss: 0.2959 | Val Loss: 0.3275\n",
      "Epoch 20/20 | Train Loss: 0.2958 | Val Loss: 0.3278\n",
      "Trial 7: lr=5e-05, batch_size=32, num_epochs=20, val_loss=0.3278\n",
      "Epoch 1/20 | Train Loss: 0.4020 | Val Loss: 0.3442\n",
      "Epoch 2/20 | Train Loss: 0.3579 | Val Loss: 0.3340\n",
      "Epoch 3/20 | Train Loss: 0.3476 | Val Loss: 0.3310\n",
      "Epoch 4/20 | Train Loss: 0.3405 | Val Loss: 0.3258\n",
      "Epoch 5/20 | Train Loss: 0.3356 | Val Loss: 0.3243\n",
      "Epoch 6/20 | Train Loss: 0.3314 | Val Loss: 0.3260\n",
      "Epoch 7/20 | Train Loss: 0.3282 | Val Loss: 0.3291\n",
      "Epoch 8/20 | Train Loss: 0.3255 | Val Loss: 0.3235\n",
      "Epoch 9/20 | Train Loss: 0.3232 | Val Loss: 0.3214\n",
      "Epoch 10/20 | Train Loss: 0.3207 | Val Loss: 0.3265\n",
      "Epoch 11/20 | Train Loss: 0.3186 | Val Loss: 0.3281\n",
      "Epoch 12/20 | Train Loss: 0.3171 | Val Loss: 0.3261\n",
      "Epoch 13/20 | Train Loss: 0.3152 | Val Loss: 0.3300\n",
      "Epoch 14/20 | Train Loss: 0.3136 | Val Loss: 0.3248\n",
      "Epoch 15/20 | Train Loss: 0.3124 | Val Loss: 0.3300\n",
      "Epoch 16/20 | Train Loss: 0.3010 | Val Loss: 0.3248\n",
      "Epoch 17/20 | Train Loss: 0.2988 | Val Loss: 0.3253\n",
      "Epoch 18/20 | Train Loss: 0.2979 | Val Loss: 0.3269\n",
      "Epoch 19/20 | Train Loss: 0.2972 | Val Loss: 0.3279\n",
      "Epoch 20/20 | Train Loss: 0.2967 | Val Loss: 0.3265\n",
      "Trial 8: lr=0.0001, batch_size=64, num_epochs=20, val_loss=0.3265\n",
      "Epoch 1/30 | Train Loss: 0.3985 | Val Loss: 0.3363\n",
      "Epoch 2/30 | Train Loss: 0.3561 | Val Loss: 0.3311\n",
      "Epoch 3/30 | Train Loss: 0.3451 | Val Loss: 0.3258\n",
      "Epoch 4/30 | Train Loss: 0.3390 | Val Loss: 0.3272\n",
      "Epoch 5/30 | Train Loss: 0.3346 | Val Loss: 0.3265\n",
      "Epoch 6/30 | Train Loss: 0.3308 | Val Loss: 0.3223\n",
      "Epoch 7/30 | Train Loss: 0.3277 | Val Loss: 0.3256\n",
      "Epoch 8/30 | Train Loss: 0.3249 | Val Loss: 0.3272\n",
      "Epoch 9/30 | Train Loss: 0.3222 | Val Loss: 0.3234\n",
      "Epoch 10/30 | Train Loss: 0.3200 | Val Loss: 0.3292\n",
      "Epoch 11/30 | Train Loss: 0.3180 | Val Loss: 0.3278\n",
      "Epoch 12/30 | Train Loss: 0.3162 | Val Loss: 0.3293\n",
      "Epoch 13/30 | Train Loss: 0.3056 | Val Loss: 0.3234\n",
      "Epoch 14/30 | Train Loss: 0.3029 | Val Loss: 0.3239\n",
      "Epoch 15/30 | Train Loss: 0.3020 | Val Loss: 0.3255\n",
      "Epoch 16/30 | Train Loss: 0.3013 | Val Loss: 0.3247\n",
      "Epoch 17/30 | Train Loss: 0.3007 | Val Loss: 0.3258\n",
      "Epoch 18/30 | Train Loss: 0.3005 | Val Loss: 0.3266\n",
      "Epoch 19/30 | Train Loss: 0.2986 | Val Loss: 0.3260\n",
      "Epoch 20/30 | Train Loss: 0.2984 | Val Loss: 0.3260\n",
      "Epoch 21/30 | Train Loss: 0.2984 | Val Loss: 0.3261\n",
      "Epoch 22/30 | Train Loss: 0.2983 | Val Loss: 0.3261\n",
      "Epoch 23/30 | Train Loss: 0.2983 | Val Loss: 0.3266\n",
      "Epoch 24/30 | Train Loss: 0.2982 | Val Loss: 0.3263\n",
      "Epoch 25/30 | Train Loss: 0.2980 | Val Loss: 0.3263\n",
      "Epoch 26/30 | Train Loss: 0.2980 | Val Loss: 0.3263\n",
      "Epoch 27/30 | Train Loss: 0.2980 | Val Loss: 0.3263\n",
      "Epoch 28/30 | Train Loss: 0.2980 | Val Loss: 0.3263\n",
      "Epoch 29/30 | Train Loss: 0.2979 | Val Loss: 0.3263\n",
      "Epoch 30/30 | Train Loss: 0.2980 | Val Loss: 0.3263\n",
      "Trial 9: lr=5e-05, batch_size=64, num_epochs=30, val_loss=0.3263\n",
      "Epoch 1/10 | Train Loss: 0.4002 | Val Loss: 0.3419\n",
      "Epoch 2/10 | Train Loss: 0.3583 | Val Loss: 0.3316\n",
      "Epoch 3/10 | Train Loss: 0.3470 | Val Loss: 0.3273\n",
      "Epoch 4/10 | Train Loss: 0.3408 | Val Loss: 0.3249\n",
      "Epoch 5/10 | Train Loss: 0.3359 | Val Loss: 0.3342\n",
      "Epoch 6/10 | Train Loss: 0.3322 | Val Loss: 0.3269\n",
      "Epoch 7/10 | Train Loss: 0.3290 | Val Loss: 0.3242\n",
      "Epoch 8/10 | Train Loss: 0.3262 | Val Loss: 0.3260\n",
      "Epoch 9/10 | Train Loss: 0.3234 | Val Loss: 0.3331\n",
      "Epoch 10/10 | Train Loss: 0.3215 | Val Loss: 0.3248\n",
      "Trial 10: lr=5e-05, batch_size=64, num_epochs=10, val_loss=0.3248\n",
      "Best hyperparameters: {'lr': 5e-05, 'batch_size': 64, 'num_epochs': 10}\n",
      "Best validation loss: 0.3247509590034411\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Best Hyperparameters when predictand = both:\n",
    "Best hyperparameters: {'lr': 5e-05, 'batch_size': 64, 'num_epochs': 10}\n",
    "Best validation loss: 0.3247509590034411\n",
    "\n"
   ],
   "id": "786ecf52debf133d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Model Evaluation:",
   "id": "2de8f68ac000e0a5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T08:11:56.219114Z",
     "start_time": "2025-05-08T08:11:56.163234Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(model, X_test_tensor, y_test):\n",
    "    \"\"\"Generate predictions and calculate metrics\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_tensor = model(X_test_tensor)\n",
    "\n",
    "    # Convert to numpy for sklearn metrics\n",
    "    y_pred = y_pred_tensor.numpy()\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)  # Method #2 from search results\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Display metrics\n",
    "    print(\"\\nFinal Model Evaluation:\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")  # Added from search result [1][2]\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"R: {r2:.4f}\")\n",
    "\n",
    "    return y_pred"
   ],
   "id": "8fb2ae85b752b57c",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Visualisation",
   "id": "d434549c427ddb89"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T08:11:59.621144Z",
     "start_time": "2025-05-08T08:11:59.563452Z"
    }
   },
   "cell_type": "code",
   "source": [
    " def plot_loss_curves(train_losses, val_losses):\n",
    "    \"\"\"Plot training and validation loss curves\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.title(f'Loss Curves when predictands = {predictands}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MSE Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ],
   "id": "80aff5cd849a7ca8",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Execution",
   "id": "1f6a550e4a0d52bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T08:12:04.160753Z",
     "start_time": "2025-05-08T08:12:03.845241Z"
    }
   },
   "cell_type": "code",
   "source": [
    " #Visualize training progress\n",
    "plot_loss_curves(train_losses=train_losses, val_losses=val_losses)\n",
    "\n",
    "# Final evaluation\n",
    "evaluate_model(model=model, X_test_tensor=X_test_tensor, y_test=y_test)\n",
    "#y_pred = evaluate_model(model, X_test_tensor, y_test)"
   ],
   "id": "6211a66b46e6c7b3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1cAAAIhCAYAAACizkCYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACo4UlEQVR4nOzdd3hT9d/G8fdJundLS5kte8qSvUGGDHEgoqIgiANx4QZxz5+bx4EbUFBABXGAyt577z3KKhtaWjpznj8ODRQKtNA2bXq/ritXkpOTk096Usjd7zJM0zQRERERERGRa2JzdQEiIiIiIiLuQOFKREREREQkFyhciYiIiIiI5AKFKxERERERkVygcCUiIiIiIpILFK5ERERERERygcKViIiIiIhILlC4EhERERERyQUKVyIiIiIiIrlA4UpErtmoUaMwDIPly5e7upRsmTdvHj179qR06dJ4eXkRHBxMs2bN+PLLL0lISHB1eQVKuXLluOmmm1xdRoFjGAavvfaa837G78Du3btzdJwpU6ZkOo4rzJ49G8MwmD17tkvruFCbNm0wDAPDMC76DBqGwahRo3J0vEu9z88++4xKlSrh5eWFYRicPHmSvn370qZNm6uqO+OzcL42bdpc9fGuVps2bejbt6/z/smTJ50/T8Mw+PDDD/O1HpGiQuFKRIqUV199lVatWrF//37efPNNpk2bxrhx42jXrh2vvfYaL730kqtLlEKoa9euLFq0iJIlS+boeVOmTOH111/Po6oKv3r16rFo0SI++uijPDn+6tWreeKJJ2jbti0zZ85k0aJFBAYG5slruVpgYCCLFi1i4sSJri5FxK15uLoAEZH88uuvv/LGG2/Qv39/vv3220x/Xe7cuTPPP/88ixYtypXXSkxMxM/PL1eOJbknr85LREQEERERuX7coi4oKIgmTZrk2fE3bNgAwIMPPkijRo3y7HUKArvdTpMmTXLcuioiOaOWKxHJN/Pnz6ddu3YEBgbi5+dHs2bNmDx5cqZ9EhMTefbZZylfvjw+Pj6EhYXRoEEDxo4d69xn586d3HXXXZQqVQpvb28iIyNp164dq1evvuzrv/HGG4SGhvLpp59e1G0HrL/sduzYEYDdu3dfsuvRhV3CXnvtNQzDYOXKlfTo0YPQ0FAqVqzIsGHDMAyD7du3X3SMF154AS8vL44ePercNn36dNq1a0dQUBB+fn40b96cGTNmZHrekSNHeOihhyhbtize3t5ERETQvHlzpk+ffsn3vWHDBgzD4Ndff3VuW7FiBYZhULNmzUz73nzzzdSvX/+iY/z7779cf/31+Pr6Uq1aNUaMGHHRPrGxsTz88MOUKVMGLy8vypcvz+uvv05aWppzn4yf64cffsjHH39M+fLlCQgIoGnTpixevPiS7yFDRperadOm0a9fP8LCwvD396dbt27s3Lkz075t2rThuuuuY+7cuTRr1gw/Pz/uv/9+AOLi4pyfMy8vL0qXLs2gQYMu6hYaFxfHgw8+SLFixQgICKBTp05s3br1knVd+MX133//pV27dgQHB+Pn50f16tV59913Aejbty9ffPEFQKbuWhnH+OKLL2jVqhXFixfH39+fWrVq8f7775Oamprl+1y2bBktW7bEz8+PChUq8L///Q+Hw5Fp382bN9OpUyf8/PwIDw9nwIABxMfHX/R+Vq1axU033UTx4sXx9vamVKlSdO3alX379l3hDLnO5s2bufvuu4mMjMTb25uoqCj69OlDcnJylvu3adOGe++9F4DGjRtjGEambnR5qWHDhnTt2jXTtlq1amEYBsuWLXNumzhxIoZhsG7dOuDcvzWrVq2ie/fuBAUFERwczL333suRI0fypXYRuTy1XIlIvpgzZw4dOnSgdu3afP/993h7ezN8+HC6devG2LFjufPOOwF4+umnGT16NG+99Rb16tUjISGB9evXc+zYMeexunTpQnp6Ou+//z5RUVEcPXqUhQsXcvLkyUu+/sGDB1m/fj133nlnnrUode/enbvuuosBAwaQkJBA8+bNeeGFFxg1ahRvvfWWc7/09HTGjBlDt27dCA8PB2DMmDH06dOHW265hR9++AFPT0++/vprbrzxRv777z/atWsHQO/evVm5ciVvv/02VapU4eTJk6xcuTLTz+dCNWvWpGTJkkyfPp077rgDsIKcr68vGzdu5MCBA5QqVYq0tDTmzJnDgAEDMj1/zZo1PPPMMwwePJjIyEi+++47+vfvT6VKlWjVqhVgBatGjRphs9l45ZVXqFixIosWLeKtt95i9+7djBw5MtMxv/jiC6pVq8awYcMAePnll+nSpQu7du0iODj4ij/r/v3706FDB37++Wf27t3LSy+9RJs2bVi7di0hISHO/Q4ePMi9997L888/zzvvvIPNZiMxMZHWrVuzb98+XnzxRWrXrs2GDRt45ZVXWLduHdOnT8cwDEzT5NZbb2XhwoW88sorNGzYkAULFtC5c+cr1gfw/fff8+CDD9K6dWu++uorihcvztatW1m/fr3zPSckJPDbb79lajHN6Fq4Y8cOevXq5QyAa9as4e2332bz5s0XhdvY2FjuuecennnmGV599VV+//13hgwZQqlSpejTpw8Ahw4donXr1nh6ejJ8+HAiIyP56aefeOyxxzIdKyEhgQ4dOlC+fHm++OILIiMjiY2NZdasWVkGsfM5HI6LAl1WDMPAbrdf+Yd4CaZpZrq/Zs0aWrRoQXh4OG+88QaVK1fm4MGD/Pnnn6SkpODt7X3RMYYPH87YsWN56623GDlyJNWqVXO2PuZ0PNf5+vbte8WQ1r59ez7//HNSU1Px9PTk0KFDrF+/Hl9fX6ZNm0bDhg0B6/c0MjKSWrVqZXr+bbfdRs+ePRkwYAAbNmzg5ZdfZuPGjSxZsgRPT0+AAjeGTqTIMEVErtHIkSNNwFy2bNkl92nSpIlZvHhxMz4+3rktLS3NvO6668wyZcqYDofDNE3TvO6668xbb731ksc5evSoCZjDhg3LUY2LFy82AXPw4MHZ2n/Xrl0mYI4cOfKixwDz1Vdfdd5/9dVXTcB85ZVXLtq3e/fuZpkyZcz09HTntilTppiA+ddff5mmaZoJCQlmWFiY2a1bt0zPTU9PN+vUqWM2atTIuS0gIMAcNGhQtt7D+e69916zQoUKzvvt27c3H3zwQTM0NNT84YcfTNM0zQULFpiAOXXqVOd+0dHRpo+Pj7lnzx7ntjNnzphhYWHmww8/7Nz28MMPmwEBAZn2M03T/PDDD03A3LBhg2ma536utWrVMtPS0pz7LV261ATMsWPHXvZ9ZHzWbrvttkzbM2p/6623nNtat25tAuaMGTMy7fvuu++aNpvtos/rb7/9ZgLmlClTTNM0zX/++ccEzP/7v//LtN/bb7990Wcgo65du3aZpmma8fHxZlBQkNmiRQvnZzsrjz76qJmd/4rT09PN1NRU88cffzTtdrt5/Pjxi97nkiVLMj2nRo0a5o033ui8/8ILL5iGYZirV6/OtF+HDh1MwJw1a5Zpmqa5fPlyEzAnTZp0xboulPG7cKVLdHT0FY/VunVrs3Xr1tl63RtuuMEMCQkxDx8+fMl9Zs2alel9mmb2/u3KDRe+l+nTp5uAOXfuXNM0TXPMmDFmYGCgOXDgQLNt27bO/SpXrmz26tXLeT/j5/vUU09lOv5PP/1kAuaYMWOuWEvG7+AHH3xwje9KRLKiboEikucSEhJYsmQJPXr0ICAgwLndbrfTu3dv9u3bx5YtWwBo1KgR//zzD4MHD2b27NmcOXMm07HCwsKoWLEiH3zwAR9//DGrVq3K1l/K88Ptt99+0bZ+/fqxb9++TN32Ro4cSYkSJZwtIAsXLuT48ePcd999pKWlOS8Oh4NOnTqxbNkyZ3e1Ro0aOVvCFi9efFEXsUtp164dO3fuZNeuXSQlJTF//nw6depE27ZtmTZtGmD9ldzb25sWLVpkem7dunWJiopy3vfx8aFKlSrs2bPHue3vv/+mbdu2zhawjEvGe5wzZ06mY3bt2jVTy0Xt2rUBMh3zcu65555M95s1a0Z0dDSzZs3KtD00NJQbbrgh07a///6b6667jrp162aq9cYbb8w0m1zGsS58rV69el2xvoULFxIXF8fAgQOz7IKaHatWreLmm2+mWLFi2O12PD096dOnD+np6Rd1TSxRosRFY4Zq166d6ec5a9YsatasSZ06dS77fipVqkRoaCgvvPACX331FRs3bsx2zQ899BDLli274uWvv/7K9jGvJDExkTlz5tCzZ89CM+6tefPm+Pj4OP9dmDZtGm3atKFTp04sXLiQxMRE9u7dy7Zt22jfvv1Fz7/wM9mzZ088PDwu+vyLSP5TuBKRPHfixAlM08xyJrVSpUoBOLu1ffrpp7zwwgtMmjSJtm3bEhYWxq233sq2bdsAqzvRjBkzuPHGG3n//fe5/vrriYiI4Iknnrhsl6WMcLBr167cfntOWb2/zp07U7JkSWe3uBMnTvDnn3/Sp08fZ7g4dOgQAD169MDT0zPT5b333sM0TY4fPw7A+PHjue+++/juu+9o2rQpYWFh9OnTh9jY2MvWlvEFbfr06cyfP5/U1FRuuOEG2rdv7xzXNX36dJo3b46vr2+m5xYrVuyi43l7e2cKvocOHeKvv/66qP6MMV3njy3L6pgZ3bYuDNOXUqJEiSy3Xdg9MqtzcujQIdauXXtRrYGBgZim6az12LFjeHh4XFRrVq99oYzxL2XKlMnW+7lQTEwMLVu2ZP/+/fzf//0f8+bNY9myZc4xWhf+nLJzjo4dO3bJn9v5goODmTNnDnXr1uXFF1+kZs2alCpVildfffWKYb5EiRLUrVv3ipcaNWpk+2dxJSdOnCA9Pf2qf9au4OPjk2ms5IwZM+jQoQNt2rQhPT2defPmOf/okVW4uvCcZXxOL9c9WETyh8ZciUieCw0NxWazcfDgwYseO3DgAIBz7JG/vz+vv/46r7/+OocOHXK2YnXr1o3NmzcDEB0dzffffw/A1q1b+eWXX3jttddISUnhq6++yrKGkiVLUqtWLaZOnZqtGeN8fHwALhoMf7kvL1m1UGS0zn366aecPHmSn3/+meTkZPr16+fcJ+O9f/bZZ5ecGS0yMtK577Bhwxg2bBgxMTH8+eefDB48mMOHD/Pvv/9esrYyZcpQpUoVpk+fTrly5WjQoAEhISG0a9eOgQMHsmTJEhYvXnzV04KHh4dTu3Zt3n777SwfzwjRuSWrMBkbG0ulSpUybcvqnISHh+Pr65vlpBwZj4MVWNLS0jh27Fim8HKlIAs4W1CudgKISZMmkZCQwMSJE4mOjnZuv9KkLZdTrFixS/7cLlSrVi3GjRuHaZqsXbuWUaNG8cYbb+Dr68vgwYMv+RpvvPFGtj5D0dHRuTZrXVhYGHa7vUBPtpGVdu3a8corr7B06VL27dtHhw4dCAwMpGHDhkybNo0DBw5QpUoVypYte9FzY2NjKV26tPN+Vp9TEXENtVyJSJ7z9/encePGTJw4MdNf0h0OB2PGjHF+8b9QZGQkffv25e6772bLli0kJiZetE+VKlV46aWXqFWrFitXrrxsHS+//DInTpzgiSeeuGhAPMDp06eZOnWq87V9fHxYu3Ztpn3++OOPbL3n8/Xr14+kpCTGjh3LqFGjaNq0KdWqVXM+3rx5c0JCQti4cSMNGjTI8uLl5XXRcaOionjsscfo0KHDFd87WH8BnzlzJtOmTaNDhw6A9fOLiorilVdeITU1Ncu/kmfHTTfdxPr166lYsWKW9ed2uPrpp58y3V+4cCF79uzJ1kKtN910Ezt27KBYsWJZ1lquXDkA2rZtm+Vr/fzzz1d8jWbNmhEcHMxXX32V5Wctw6Va7DJC4fkTMZimybfffnvF176Utm3bsmHDBtasWZNp++Xej2EY1KlTh08++YSQkJArfs5c0S3Q19eX1q1b8+uvv17UQlqQtW/fnrS0NF5++WXKlCnj/Dehffv2TJ8+nZkzZ17y9/HCz+Qvv/xCWlpavi9ULCIXU8uViOSamTNnZvnX6C5duvDuu+/SoUMH2rZty7PPPouXlxfDhw9n/fr1jB071vllsnHjxtx0003Url2b0NBQNm3axOjRo2natCl+fn6sXbuWxx57jDvuuIPKlSvj5eXFzJkzWbt27WX/og5wxx138PLLL/Pmm2+yefNm+vfvT8WKFUlMTGTJkiV8/fXX3HnnnXTs2BHDMLj33nsZMWIEFStWpE6dOixdujRbX6wvVK1aNZo2bcq7777L3r17+eabbzI9HhAQwGeffcZ9993H8ePH6dGjB8WLF+fIkSOsWbOGI0eO8OWXX3Lq1Cnatm1Lr169qFatGoGBgSxbtox///2X7t27X7GOdu3aMXz4cI4ePeqcpS9j+8iRIwkNDc1yGvbseOONN5g2bRrNmjXjiSeeoGrVqiQlJbF7926mTJnCV199lavdtpYvX84DDzzAHXfcwd69exk6dCilS5dm4MCBV3zuoEGDmDBhAq1ateKpp56idu3aOBwOYmJimDp1Ks888wyNGzemY8eOtGrViueff56EhAQaNGjAggULGD169BVfIyAggI8++ogHHniA9u3b8+CDDxIZGcn27dtZs2YNn3/+OYBzFrj33nuPzp07Y7fbqV27Nh06dMDLy4u7776b559/nqSkJL788ktOnDhx1T+zQYMGMWLECLp27cpbb73lnC0wo0U4w99//83w4cO59dZbqVChAqZpMnHiRE6ePOkM5ZdSqlSpXA/S2fHxxx/TokULGjduzODBg6lUqRKHDh3izz//5Ouvv86VhYH79u3LDz/8wK5du5wB/FrUr1+f0NBQpk6dmqklu3379rz55pvO21mZOHEiHh4edOjQwTlbYJ06dejZs+c11yUi18h1c2mIiLvImHHrUpeMGdTmzZtn3nDDDaa/v7/p6+trNmnSxDljXobBgwebDRo0MENDQ01vb2+zQoUK5lNPPWUePXrUNE3TPHTokNm3b1+zWrVqpr+/vxkQEGDWrl3b/OSTTzLNPnc5c+bMMXv06GGWLFnS9PT0NIOCgsymTZuaH3zwgRkXF+fc79SpU+YDDzxgRkZGmv7+/ma3bt3M3bt3X3K2wCNHjlzyNb/55hsTMH19fc1Tp05dsq6uXbuaYWFhpqenp1m6dGmza9eu5q+//mqapmkmJSWZAwYMMGvXrm0GBQWZvr6+ZtWqVc1XX33VTEhIuOL7PnHihGmz2Ux/f38zJSXFuT1jprHu3btf9Jzo6Giza9euF23Paia3I0eOmE888YRZvnx509PT0wwLCzPr169vDh061Dx9+rRpmpefqezCn2tWMj5rU6dONXv37m2GhISYvr6+ZpcuXcxt27ZdVGPNmjWzPM7p06fNl156yaxatarp5eVlBgcHm7Vq1TKfeuopMzY21rnfyZMnzfvvv98MCQkx/fz8zA4dOpibN2++4myBGaZMmWK2bt3a9Pf3N/38/MwaNWqY7733nvPx5ORk84EHHjAjIiJMwzAyHeOvv/4y69SpY/r4+JilS5c2n3vuOecMhufPeHep93nfffddNCvfxo0bzQ4dOpg+Pj5mWFiY2b9/f/OPP/7IdMzNmzebd999t1mxYkXT19fXDA4ONhs1amSOGjXqEmclb+RktkDTtN7bHXfcYRYrVsz08vIyo6KizL59+5pJSUmmaV77bIG333676evra544cSKH7+TS7+W2224zAfOnn35ybktJSTH9/f1Nm8120Wtl/FuzYsUKs1u3bmZAQIAZGBho3n333eahQ4eyVYtmCxTJW4ZpXqa/goiISAEyatQo+vXrx7Jly2jQoIGry5E81KZNG0zTZMaMGdhsNmw2145kKFGiBL179+aDDz5wWQ2vvfYar7/+OkeOHHGODcyJtLQ09uzZQ6VKlfjggw949tln86BKkaJNY65ERESkQJo7dy6enp7cfPPNLq1jw4YNJCYm8sILL7i0jmtx8uRJPD09L5r0RURyl8ZciYiISIHz9ddfO5dXCAkJcWktNWvWJC4uzqU1XKuMMZoZspqFUESunboFioiIiIiI5AJ1CxQREREREckFClciIiIiIiK5QOFKREREREQkF2hCiyw4HA4OHDhAYGCgc2FTEREREREpekzTJD4+nlKlSl1xWQiFqywcOHBAs+iIiIiIiIjT3r17KVOmzGX3UbjKQmBgIGD9AIOCglxcDaSmpjJ16lQ6duyIp6enq8uRPKBz7P50josGnWf3p3NcNOg8u7+cnOO4uDjKli3rzAiXo3CVhYyugEFBQQUmXPn5+REUFKRfcDelc+z+dI6LBp1n96dzXDToPLu/qznH2RkupAktREREREREcoHClYiIiIiISC5QuBIREREREckFGnMlIiIiIoWCaZqkpaWRnp6ep6+TmpqKh4cHSUlJef5a4hoXnmNPT0/sdvs1H1fhSkREREQKvJSUFA4ePEhiYmKev5ZpmpQoUYK9e/dqzVM3deE5NgyDMmXKEBAQcE3HVbgSERERkQLN4XCwa9cu7HY7pUqVwsvLK09Dj8Ph4PTp0wQEBFxx0VgpnM4/x4ZhcOTIEfbt20flypWvqQVL4UpERERECrSUlBQcDgdly5bFz88vz1/P4XCQkpKCj4+PwpWbuvAcR0REsHv3blJTU68pXOnTIiIiIiKFgoKO5JXcagnVJ1RERERERCQXKFyJiIiIiIjkAoUrEREREZFCok2bNgwaNCjb++/evRvDMFi9enWe1STnKFyJiIiIiOSyjOm9L3Xp27fvVR134sSJvPnmm9nev2zZshw8eJDrrrvuql4vuxTiLJotUEREREQklx08eNB5e/z48bzyyits2bLFuc3X1zfT/qmpqXh6el7xuGFhYTmqw263U6JEiRw9R66eWq5EREREpFAxTZPElLQ8vZxJSc9yu2ma2aqxRIkSzktwcDCGYTjvJyUlERISwi+//EKbNm3w8fFhzJgxHDt2jLvvvpsyZcrg5+dHrVq1GDt2bKbjXtgtsFy5crzzzjvcf//9BAYGEhUVxTfffON8/MIWpdmzZ2MYBjNmzKBBgwb4+fnRrFmzTMEP4K233qJ48eIEBgbywAMPMHjwYOrWrXtV5wsgOTmZJ554guLFi+Pj40OLFi1YtmyZ8/ETJ05wzz33EBERga+vL5UrV2bkyJGANRX/Y489RsmSJfHx8aFcuXK8++67V11LXlLLlYiIiIgUKmdS06nxyn8uee2Nb9yIn1fufIV+4YUX+Oijjxg5ciTe3t4kJSVRv359XnjhBYKCgpg8eTK9e/emQoUKNG7c+JLH+eijj3jzzTd58cUX+e2333jkkUdo1aoV1apVu+Rzhg4dykcffURERAQDBgzg/vvvZ8GCBQD89NNPvP322wwfPpzmzZszbtw4PvroI8qXL3/V7/X5559nwoQJ/PDDD0RHR/P+++9z4403sn37dsLCwnj55ZfZuHEj//zzD+Hh4Wzfvp0zZ84A8Omnn/Lnn3/yyy+/EBUVxd69e9m7d+9V15KXFK5ERERERFxg0KBBdO/ePdO2Z5991nn78ccf599//+XXX3+9bLjq0qULAwcOBKzA9sknnzB79uzLhqu3336b1q1bAzB48GC6du1KUlISPj4+fPbZZ/Tv359+/foB8MorrzB16lROnz59Ve8zISGBL7/8klGjRtG5c2cAvv32W6ZNm8b333/Pc889R0xMDPXq1aNBgwaA1SKXISYmhsqVK9OiRQsMwyA6Ovqq6sgPClcF3J5jCazec5z9Ca6uRERERKRg8PW0s/GNG/Ps+A6Hg/i4eAKDAi9auNjX055rr5MRJDKkp6fzv//9j/Hjx7N//36Sk5NJTk7G39//ssepXbu283ZG98PDhw9n+zklS5YE4PDhw0RFRbFlyxZnWMvQqFEjZs6cma33daEdO3aQmppK8+bNnds8PT1p1KgRmzZtAuCRRx7h9ttvZ+XKlXTs2JFbb72VZs2aAdC3b186dOhA1apV6dSpEzfddBMdO3a8qlrymsJVAffN3J38tCSG9qU1PE5EREQErACRW13zsuJwOEjzsuPn5XFRuMpNF4amjz76iE8++YRhw4ZRq1Yt/P39GTRoECkpKZc9zoUTYRiGgcPhyPZzDMMAyPScjG0ZsjvWLCsZz83qmBnbOnfuzJ49e5g8eTLTp0+nXbt2PProo3z44Ydcf/317Nq1i3/++Yfp06fTs2dP2rdvz2+//XbVNeUVfWMv4CoVDwDgUKKLCxERERGRPDVv3jxuueUW7r33XurUqUOFChXYtm1bvtdRtWpVli5dmmnb8uXLr/p4lSpVwsvLi/nz5zu3paamsnz5cqpXr+7cFhERQd++fRkzZgzDhg3LNDFHUFAQd955J99++y3jx49nwoQJHD9+/KpryitquSrgnOHqjHGFPUVERESkMKtUqRITJkxg4cKFhIaG8vHHHxMbG5spgOSHxx9/nAcffJAGDRrQrFkzxo8fz9q1a6lQocIVn3vhrIMANWrU4JFHHuG5554jLCyMqKgo3n//fRITE+nfvz9gjeuqX78+NWvWJDk5mb///tv5vj/55BNKlixJ3bp1sdls/Prrr5QoUYKQkJBcfd+5QeGqgMsIV0eTICXNQTaWPxARERGRQujll19m165d3Hjjjfj5+fHQQw9x6623curUqXyt45577mHnzp08++yzJCUl0bNnT/r27XtRa1ZW7rrrrou27dq1i//97384HA569+5NfHw8DRo04L///iM0NBQALy8vhgwZwu7du/H19aVly5aMGzcOgICAAN577z22bduG3W6nYcOGTJkyJU+7bF4tw7yWDpRuKi4ujuDgYE6dOkVQUJBLazFNk+te+4+E5HSmPN6MGqVDXVqP5I3U1FSmTJlCly5dsrWAoBQ+OsdFg86z+9M5do2kpCR27dpF+fLl8fHxyfPXczgcxMXFERQUVCC/wLtChw4dKFGiBKNHj3Z1KbniwnN8uc9YTrKBWq4KOMMwqBjuz9r9cew4kqBwJSIiIiJ5KjExka+++oobb7wRu93O2LFjmT59OtOmTXN1aQWeonghUDHCmklmxxHNxy4iIiIiecswDKZMmULLli2pX78+f/31FxMmTKB9+/auLq3AU8tVIVAxwhp3tePI1S3cJiIiIiKSXb6+vkyfPt3VZRRKarkqBNRyJSIiIiJS8ClcFQIZ4Wrn0QQcDs0/IiIiIiJSEClcFQJlQ32xGyZJqQ72nzzj6nJERERERCQLCleFgIfdRsTZGSG3a9yViIiIiEiBpHBVSJTwtboD7jiscCUiIiIiUhC5PFwNHz7cuVhX/fr1mTdv3mX3T05OZujQoURHR+Pt7U3FihUZMWKE8/Fvv/2Wli1bEhoaSmhoKO3bt8/WatIFXaSvdb1d4UpEREREpEByabgaP348gwYNYujQoaxatYqWLVvSuXNnYmJiLvmcnj17MmPGDL7//nu2bNnC2LFjqVatmvPx2bNnc/fddzNr1iwWLVpEVFQUHTt2ZP/+/fnxlvJMpJ/VcqVwJSIiIlJ0tGnThkGDBjnvlytXjmHDhl32OYZhMGnSpGt+7dw6TlHi0nD18ccf079/fx544AGqV6/OsGHDKFu2LF9++WWW+//777/MmTOHKVOm0L59e8qVK0ejRo1o1qyZc5+ffvqJgQMHUrduXapVq8a3336Lw+FgxowZ+fW28kTk2W6B24+cxjQ1Y6CIiIhIQdatW7dLLrq7aNEiDMNg5cqVOT7usmXLeOihh661vExee+016tate9H2gwcP0rlz51x9rQuNGjWKkJCQPH2N/OSyRYRTUlJYsWIFgwcPzrS9Y8eOLFy4MMvn/PnnnzRo0ID333+f0aNH4+/vz80338ybb76Jr69vls9JTEwkNTWVsLCwS9aSnJxMcnKy835cXBwAqamppKam5vSt5brU1FSK+4ABnExM5dDJBIoFeLu6LMlFGZ+zgvB5k7yhc1w06Dy7P51j10hNTcU0TRwOBw6HI89fL+MP2RmveTX69etHjx492LVrF9HR0Zke+/7776lbty5169bN1vHPr6NYsWIAV3xeTn5WGe/3wv2LFy+erde6FhnHzo/zer4Lz7HD4cA0TVJTU7Hb7Zn2zcnvu8vC1dGjR0lPTycyMjLT9sjISGJjY7N8zs6dO5k/fz4+Pj78/vvvHD16lIEDB3L8+PFM467ON3jwYEqXLn3JvxwAvPvuu7z++usXbZ86dSp+fn45eFd5x8sOYd4mx5INfvprBpWCXV2R5IVp06a5ugTJYzrHRYPOs/vTOc5fHh4elChRgtOnT5OSkgKmCWl5vzxN/PHELIrxBcO44nNbtWpFREQE33zzDS+88IJze2JiIr/88gsvvfQSu3fv5rnnnmPx4sWcOHGCcuXK8fTTT9OjRw/n/mlpaaSkpDj/+F+7dm0eeeQRHnnkEQB27NjB448/zsqVKylXrhzvvvsuAGfOnHE+59VXX2Xy5MkcOHCA4sWLc8cdd/D888/j6enJzz//zBtvvAHgDBVffPEFvXr1IjQ0lDFjxtC1a1cANmzYwJAhQ1i2bBm+vr7cfPPNvPXWWwQEBAAwcOBATp06RZMmTfjiiy9ISUmhe/fuvPvuu3h6emb5c0pKSsI0TWetF9q7dy8vvPACc+fOxWaz0a5dO9577z1n8Fu3bh0vvvgiq1evxjAMKlSowCeffEK9evWIiYnh+eefZ/HixaSmphIVFcXrr79Ox44dncePj48HrIafM2fOMHfuXNLS0jLVkJiYxefgElwWrjIYF3w4TdO8aFsGh8OBYRj89NNPBAdb6eLjjz+mR48efPHFFxe1Xr3//vuMHTuW2bNn4+Pjc8kahgwZwtNPP+28HxcXR9myZenYsSNBQUFX+9ZyTWpqKtOmTaNm2WLM3X6c8Iq16NKorKvLklyUcY47dOhwyX98pHDTOS4adJ7dn86xayQlJbF3714CAgKs73QpCdj+V90ltTgG7wMv/2zt26dPH8aNG8dbb73l/H77+++/k5KSQv/+/UlMTKRJkyYMHTqUoKAgpkyZwoABA6hZsyaNGzcGrGDp5eXl/E5qs9nw8fEhKCgIh8NB3759CQ8PZ+HChcTFxTm/0/r6+jqfEx4ezqhRoyhVqhTr1q3j4YcfJjw8nOeee4777ruPHTt28N9//zF16lQAgoODnd+rM46TmJhIz549ady4MUuWLOHw4cM89NBDDB06lJEjRwLg6enJ/PnzKVu2LDNnzmT79u3cfffdNGzYkAcffDDLn5GPjw+GYWT5nds0Te677z78/f2ZNWsWaWlpPPbYYzz00EPMnDkTgEceeYS6devy9ddfY7fbWb16NSEhIQQFBTFkyBDS09OZM2cO/v7+bNy4kaCgIIKCgjBNk/j4eAIDAzEMg6SkJHx9fWnVqtVFueFSwS8rLgtX4eHh2O32i1qpDh8+fFFrVoaSJUtSunRpZ7ACqF69OqZpsm/fPipXruzc/uGHH/LOO+8wffp0ateufdlavL298fa+uJudp6dngfqHs3JkIHO3H2fXsTMFqi7JPQXtMye5T+e4aNB5dn86x/krPT0dwzCw2WzYbDawuW7agJy8fv/+/fnwww+ZO3cubdu2BawxRt27d6dYsWIUK1aM5557zrn/E088wX///ceECRNo2rSpc3vGe7/w/vTp09m0aRO7d++mTJkyALzzzjt07tz53M8KePnll53PrVChAlu3bmX8+PG88MIL+Pv7ExgYiIeHB6VKlcry/dpsNsaOHcuZM2ecQ3MAPv/8c7p168b7779PZGQkhmEQGhrKF198gd1up0aNGnTt2pVZs2bx8MMPX/rned71+aZNm8batWvZtWsXZctaDQujR4+mZs2arFixgoYNGxITE8Nzzz1HjRo1AKhatarz+Xv37uX222+nTp06AFSqVMn5WEY3xPM/V4ZhZPm7nZPfdZeFKy8vL+rXr8+0adO47bbbnNunTZvGLbfckuVzmjdvzq+//srp06edzY9bt27FZrM5P1AAH3zwAW+99Rb//fcfDRo0yNs3ko8qRlgf5B1aSFhERESKMk8/ePFAnh3e4XAQFx9PUGDgxV/6PbM/ZKRatWo0a9aMESNG0LZtW3bs2MG8efOcLUTp6en873//Y/z48ezfv985D0BGeLmSTZs2ERUVlel78PmhLMNvv/3GsGHD2L59O6dPnyYtLS3HvbM2bdpEnTp1MtXWvHlzHA4HW7ZscTaO1KxZM9OYpZIlS7Ju3bocvdb5r1m2bFlnsAKoUaMGISEhbNq0iYYNG/L000/zwAMPMHr0aNq3b88dd9xBxYoVASusPvLII0ydOpX27dtz++23X7HR5Vq5dLbAp59+mu+++44RI0awadMmnnrqKWJiYhgwYABgddfr06ePc/9evXpRrFgx+vXrx8aNG5k7dy7PPfcc999/v7Pp8v333+ell15ixIgRlCtXjtjYWGJjYzl9uvAHkooRVqDUdOwiIiJSpBmG1TUvLy+efllvz8Z4q/P179+fCRMmEBcXx8iRI4mOjqZdu3YAfPTRR3zyySc8//zzzJw5k9WrV3PjjTda48qyIasZpC8cXrN48WLuuusuOnfuzN9//82qVasYOnRotl/j/Ne61NCd87df2MpjGMZVT1Zxqdc8f/trr73Ghg0b6Nq1KzNnzqRGjRr8/vvvADzwwAPs3LmT3r17s27dOho0aMBnn312VbVkl0vD1Z133smwYcN44403qFu3LnPnzmXKlCnOGVUOHjyYac2rgIAApk2bxsmTJ2nQoAH33HMP3bp149NPP3XuM3z4cFJSUujRowclS5Z0Xj788MN8f3+5LaPl6uCpJE4np11hbxERERFxtZ49e2K32/n555/54Ycf6NevnzMYzJs3j1tuuYV7772XOnXqUKFCBbZt25btY9eoUYOYmBgOHDjXirdo0aJM+yxYsIDo6GiGDh1KgwYNqFy5Mnv27Mm0j5eXF+np6Vd8rdWrV5OQkJDp2DabjSpVqmS75pzIeH979+51btu4cSOnTp2ievVzY+6qVKnCU089xdSpU+nevbtzDBhA2bJlGTBgABMnTuSZZ57h22+/zZNaM7h8QouBAwcycODALB8bNWrURduqVat22Rl6du/enUuVFTzBvp6EB3hz9HQyOw6fpk7ZEFeXJCIiIiKXERAQwJ133smLL77IqVOn6Nu3r/OxSpUqMWHCBBYuXEhoaCgff/wxsbGxmYLD5bRv356qVavSp08fPvroI+Li4hg6dGimfSpVqkRMTAzjxo2jYcOGTJ482dmyk6FcuXLs2rWL1atXU6ZMGQIDAy+aj+Cee+7h1Vdf5b777uO1117jyJEjPP744/Tu3fuS8yVkV3p6OqtXr860zcvLi/bt21O7dm3uuecehg0bRlpaGgMHDqR169Y0aNCAM2fO8Nxzz9GjRw/Kly/Pvn37WLZsGbfffjsAgwYNonPnzlSpUoUTJ04wc+bMbP9sr5ZLW64k5yoVt1qv1DVQREREpHDo378/J06coH379kRFRTm3v/zyy1x//fXceOONtGnThhIlSnDrrbdm+7g2m43ff/+d5ORkGjVqxAMPPMDbb7+daZ9bbrmFp556iscee4y6deuycOHCTBNcANx+++106tSJtm3bEhERwdixYy96LT8/P/777z+OHz9Ow4YN6dGjB+3atePzzz/P2Q8jC6dPn6ZevXqZLl26dMEwDCZNmkRoaCitWrWiffv2VKhQgfHjxwPW1PHHjh2jT58+VKlShZ49e9K5c2fnEkvp6ek8+uijVK9enU6dOlG1alWGDx9+zfVejmFm1VmziIuLiyM4OJhTp04VmKnYp0yZQpcuXXh98mbGLI7hkTYVeaFTNVeXJrnk/HOs2afck85x0aDz7P50jl0jKSmJXbt2Ub58+csur5NbHA4HcXFxBAUFZTmLnRR+F57jy33GcpIN9GkpZCppUgsRERERkQJJ4aqQqVQ8EIAdClciIiIiIgWKwlUhU6m41XK153giKWlXN62liIiIiIjkPoWrQiYyyJsAbw/SHSa7jyVc+QkiIiIiIpIvFK4KGcMwqFhc465ERESk6NE8bJJXcuuzpXBVCGlSCxERESlKMmZmTExMdHEl4q5SUlIAa3r3a+HyRYQl5yqp5UpERESKELvdTkhICIcPHwasNZcMw8iz13M4HKSkpJCUlKSp2N3U+ecY4MiRI/j5+eHhcW3xSOGqEFK4EhERkaKmRIkSAM6AlZdM0+TMmTP4+vrmaYgT17nwHNtsNqKioq75fCtcFUIZ4Wrn0dM4HCY2m37pRURExL0ZhkHJkiUpXrw4qampefpaqampzJ07l1atWmmxaDd14Tn28vLKlVZKhatCqGyoL152G0mpDvafPEPZMD9XlyQiIiKSL+x2+zWPi8nOa6SlpeHj46Nw5aby6hyrE2kh5GG3UT7cH1DXQBERERGRgkLhqpDSuCsRERERkYJF4aqQ0lpXIiIiIiIFi8JVIeVsuTqicCUiIiIiUhAoXBVS5y8krNXKRURERERcT+GqkKoQ4Y9hwKkzqRw9neLqckREREREijyFq0LKx9NO2VBrCnaNuxIRERERcT2Fq0KsssZdiYiIiIgUGApXhVjGpBY71HIlIiIiIuJyCleFmKZjFxEREREpOBSuCjEtJCwiIiIiUnAoXBViGeEqNi6J+KRUF1cjIiIiIlK0KVwVYkE+nhQP9AZgx5EEF1cjIiIiIlK0KVwVcuoaKCIiIiJSMChcFXIKVyIiIiIiBYPCVSGncCUiIiIiUjAoXBVylSLOrnWlhYRFRERERFxK4aqQy2i52nMsgaTUdBdXIyIiIiJSdClcFXIRgd4E+njgMGH3Mc0YKCIiIiLiKgpXhZxhGBp3JSIiIiJSAChcuYGMcVcKVyIiIiIirqNw5QbUciUiIiIi4noKV25A4UpERERExPUUrtxARrjaeTSBdIfp4mpERERERIomhSs3UCbUDy8PGylpDvadSHR1OSIiIiIiRZLClRuw2wwqhPsD6hooIiIiIuIqClduQuOuRERERERcS+HKTShciYiIiIi4lsKVm3CGqyMKVyIiIiIirqBw5SbOb7kyTc0YKCIiIiKS3xSu3ET5cH9sBsQnpXEkPtnV5YiIiIiIFDkKV27C28NOVJgfoHFXIiIiIiKuoHDlRjTuSkRERETEdRSu3EhFzRgoIiIiIuIyCldupFKEwpWIiIiIiKsoXLkRrXUlIiIiIuI6ClduJKNb4OH4ZOKSUl1cjYiIiIhI0aJw5UaCfDyJDPIG1HolIiIiIpLfFK7cjLoGioiIiIi4hsKVm8mY1GKHwpWIiIiISL5SuHIzarkSEREREXENhSs3U1ELCYuIiIiIuITClZvJaLnaezyRpNR0F1cjIiIiIlJ0KFy5mYgAb4J8PHCYsOtogqvLEREREREpMhSu3IxhGBp3JSIiIiLiAgpXbkjhSkREREQk/ylcuaFKmtRCRERERCTfKVy5oYxwpbWuRERERETyj8KVG6oUEQjAzqMJpDtMF1cjIiIiIlI0KFy5odKhvnh72EhJc7D3eKKryxERERERKRIUrtyQ3WZQIUKTWoiIiIiI5CeFKzelSS1ERERERPKXwpWbqqSWKxERERGRfKVw5aa01pWIiIiISP5SuHJT50/HbpqaMVBEREREJK8pXLmpcuF+2AyIT07jcHyyq8sREREREXF7ClduytvDTnQxf0BdA0VERERE8oPClRurqEktRERERETyjcKVG9OkFiIiIiIi+Ufhyo0pXImIiIiI5B+FKzemhYRFRERERPKPwpUbqxhhTWhxJD6ZU2dSXVyNiIiIiIh7U7hyY4E+npQI8gHUNVBEREREJK8pXLm58xcTFhERERGRvKNw5eY07kpEREREJH8oXLm5ipoxUEREREQkXyhcublKWkhYRERERCRfKFy5uYxugXtPJJKUmu7iakRERERE3JfClZsLD/Ai2NcT04SdRxJcXY6IiIiIiNtSuHJzhmFoUgsRERERkXygcFUEaNyViIiIiEjeU7gqArTWlYiIiIhI3lO4KgIqaTp2EREREZE85/JwNXz4cMqXL4+Pjw/169dn3rx5l90/OTmZoUOHEh0djbe3NxUrVmTEiBGZ9pkwYQI1atTA29ubGjVq8Pvvv+flWyjwMsLVrqMJpKU7XFyNiIiIiIh7cmm4Gj9+PIMGDWLo0KGsWrWKli1b0rlzZ2JiYi75nJ49ezJjxgy+//57tmzZwtixY6lWrZrz8UWLFnHnnXfSu3dv1qxZQ+/evenZsydLlizJj7dUIJUO8cXH00ZKuoO9J864uhwREREREbfk0nD18ccf079/fx544AGqV6/OsGHDKFu2LF9++WWW+//777/MmTOHKVOm0L59e8qVK0ejRo1o1qyZc59hw4bRoUMHhgwZQrVq1RgyZAjt2rVj2LBh+fSuCh6bzaBCuLoGioiIiIjkJQ9XvXBKSgorVqxg8ODBmbZ37NiRhQsXZvmcP//8kwYNGvD+++8zevRo/P39ufnmm3nzzTfx9fUFrJarp556KtPzbrzxxsuGq+TkZJKTk5334+LiAEhNTSU1NfVq3l6uyqjhWmqpEO7HxoNxbDl4ijaVw3KrNMkluXGOpWDTOS4adJ7dn85x0aDz7P5yco5z8jlwWbg6evQo6enpREZGZtoeGRlJbGxsls/ZuXMn8+fPx8fHh99//52jR48ycOBAjh8/7hx3FRsbm6NjArz77ru8/vrrF22fOnUqfn5+OX1reWbatGlX/VzHSQOwM3f1Fsqe3pR7RUmuupZzLIWDznHRoPPs/nSOiwadZ/eXnXOcmJiY7eO5LFxlMAwj033TNC/alsHhcGAYBj/99BPBwcGA1bWwR48efPHFF87Wq5wcE2DIkCE8/fTTzvtxcXGULVuWjh07EhQUdFXvKzelpqYybdo0OnTogKen51Udw1gfy5Txa0nyDqFLlya5XKFcq9w4x1Kw6RwXDTrP7k/nuGjQeXZ/OTnHGb3assNl4So8PBy73X5Ri9Lhw4cvannKULJkSUqXLu0MVgDVq1fHNE327dtH5cqVKVGiRI6OCeDt7Y23t/dF2z09PQvUL9S11FOtVAgAO48k4uHhcdmwKa5T0D5zkvt0josGnWf3p3NcNOg8u7/snOOcfAZcNqGFl5cX9evXv6gpbtq0aZkmqDhf8+bNOXDgAKdPn5uUYevWrdhsNsqUKQNA06ZNLzrm1KlTL3nMoqJcMX/sNoPTyWkciku+8hNERERERCRHXDpb4NNPP813333HiBEj2LRpE0899RQxMTEMGDAAsLrr9enTx7l/r169KFasGP369WPjxo3MnTuX5557jvvvv9/ZJfDJJ59k6tSpvPfee2zevJn33nuP6dOnM2jQIFe8xQLDy8NGdJg1fkwzBoqIiIiI5D6Xhqs777yTYcOG8cYbb1C3bl3mzp3LlClTiI6OBuDgwYOZ1rwKCAhg2rRpnDx5kgYNGnDPPffQrVs3Pv30U+c+zZo1Y9y4cYwcOZLatWszatQoxo8fT+PGjfP9/RU0FYtnTMce7+JKRERERETcj8sntBg4cCADBw7M8rFRo0ZdtK1atWpXnNWjR48e9OjRIzfKcyuVigcwbeMhth9Ry5WIiIiISG5zacuV5K9KEVpIWEREREQkryhcFSGVnN0CE1xciYiIiIiI+1G4KkIyxlwdPZ3MqUStOC4iIiIikpsUroqQAG8PSgb7ALD9iCa1EBERERHJTQpXRcy5roEadyUiIiIikpsUroqYiprUQkREREQkTyhcFTFquRIRERERyRsKV0WMM1xprSsRERERkVylcFXEZISrfSfOkJSa7uJqRERERETch8JVEVPM34sQP09ME3ao9UpEREREJNcoXBUxhmFQSZNaiIiIiIjkOoWrIiija+AOhSsRERERkVyjcFUEaVILEREREZHcp3BVBFXUdOwiIiIiIrlO4aoIyhhztetoAmnpDhdXIyIiIiLiHhSuiqDSIb74etpJTTeJOZ7o6nJERERERNyCwlURZLMZVIjwB9Q1UEREREQktyhcFVGa1EJEREREJHcpXBVRzrWuDilciYiIiIjkBoWrIkotVyIiIiIiuUvhqog6fyFh0zRdXI2IiIiISOGncFVERRfzx24zSEhJ5+CpJFeXIyIiIiJS6ClcFVFeHjaii/kBmjFQRERERCQ3KFwVYc5JLRSuRERERESumcJVEaZJLUREREREco/CVRHmDFdquRIRERERuWYKV0XY+TMGioiIiIjItVG4KsIqnh1zdSwhhRMJKS6uRkRERESkcFO4KsL8vT0oFewDaNyViIiIiMi1Urgq4ipq3JWIiIiISK5QuCriNKmFiIiIiEjuULgq4jLC1TaFKxERERGRa6JwVcRdVyoYgHnbjvD7qn0urkZEREREpPBSuCriapcJ5r6m0ZgmPPPLGv5Zd9DVJYmIiIiIFEoKV0WcYRi82q0md9Qvg8OEJ8atYtaWw64uS0RERESk0FG4Emw2g//dXpubapckNd1kwOgVLNpxzNVliYiIiIgUKgpXAoDdZvDJnXVpX704yWkO+v+wjJUxJ1xdloiIiIhIoaFwJU6edhuf97qeFpXCSUxJp++IpWw4cMrVZYmIiIiIFAoKV5KJj6edb/rUp0F0KHFJafT+finbD8e7uiwRERERkQJP4Uou4uflwYh+DalVOpjjCSn0+nYJe44luLosEREREZECTeFKshTk48mP9zeiamQgh+OT6fXtEg6cPOPqskRERERECiyFK7mkUH8vRj/QiHLF/Nh/8gz3freEI/HJri5LRERERKRAUriSyyoe6MNPDzahdIgvO48m0Pv7JZxISHF1WSIiIiIiBY7ClVxR6RBffnqgMcUDvdkcG899I5cSn5Tq6rJERERERAoUhSvJlnLh/vz0QGNC/TxZu+8U949aRmJKmqvLEhEREREpMBSuJNsqRwYyun9jAn08WLb7BA+PXkFyWrqryxIRERERKRAUriRHrisdzKh+DfHzsjNv21Ee+3kVqekOV5clIiIiIuJyCleSY/Wjw/iuTwO8PGxM23iIp39ZQ7rDdHVZIiIiIiIupXAlV6VZpXC+uvd6PGwGf605wJCJa3EoYImIiIhIEaZwJVfthmqR/N9d9bAZ8Mvyfbzx90ZMUwFLRERERIomhSu5Jl1rl+SDHnUAGLVwNx9O3eLiikREREREXEPhSq7Z7fXL8Oat1wHwxawdfDFru4srEhERERHJfwpXkit6N4nmxS7VAPjgvy2MmL/LxRWJiIiIiOQvhSvJNQ+1qsiT7SoD8MbfGxm3NMbFFYmIiIiI5B+FK8lVg9pX5sGW5QEY8vs6/li938UViYiIiIjkD4UryVWGYfBil+rc0zgK04Snf1nD1A2xri5LRERERCTPKVxJrjMMgzdvuY7u9UqT7jB57OdVzN16xNVliYiIiIjkKYUryRM2m8H7PWrT+boSpKQ7eGj0ctbvP+XqskRERERE8ozCleQZD7uN/7urHi0rh5OU6uDh0Ss4djrZ1WWJiIiIiOQJhSvJU14eNj6/+3qii/mx/+QZHvt5FanpDleXJSIiIiKS63Icrs6cOUNiYqLz/p49exg2bBhTp07N1cLEfQT7efJtnwb4edlZtPMY70zZ5OqSRERERERyXY7D1S233MKPP/4IwMmTJ2ncuDEfffQRt9xyC19++WWuFyjuoUpkIB/3rAPAyAW7+W3FPhdXJCIiIiKSu3IcrlauXEnLli0B+O2334iMjGTPnj38+OOPfPrpp7leoLiPTteV5IkbKgHw4u/rWLP3pGsLEhERERHJRTkOV4mJiQQGBgIwdepUunfvjs1mo0mTJuzZsyfXCxT3Mqh9FdpVK05KmjXBxZF4TXAhIiIiIu4hx+GqUqVKTJo0ib179/Lff//RsWNHAA4fPkxQUFCuFyjuxWYz+OSuulSI8Cc2LomBP60gJU0TXIiIiIhI4ZfjcPXKK6/w7LPPUq5cORo3bkzTpk0BqxWrXr16uV6guJ8gH2uCi0BvD5btPsEbf29wdUkiIiIiItcsx+GqR48exMTEsHz5cv7991/n9nbt2vHJJ5/kanHivipGBDDsrroYBoxZHMPYpTGuLklERERE5Jpc1TpXJUqUoF69ethsNuLi4pg0aRKBgYFUq1Ytt+sTN9aueiRPt68CwCt/rGfFnuMurkhERERE5OrlOFz17NmTzz//HLDWvGrQoAE9e/akdu3aTJgwIdcLFPf2aNtKdKpZgtR0kwFjVnIoLsnVJYmIiIiIXJUch6u5c+c6p2L//fffMU2TkydP8umnn/LWW2/leoHi3mw2gw971qFKZABH4pMZMGYFyWnpri5LRERERCTHchyuTp06RVhYGAD//vsvt99+O35+fnTt2pVt27bleoHi/gK8PfimdwOCfDxYFXOSVyZtwDRNV5clIiIiIpIjOQ5XZcuWZdGiRSQkJPDvv/86p2I/ceIEPj4+uV6gFA3lwv35rNf12AwYv3wvY5ZoggsRERERKVxyHK4GDRrEPffcQ5kyZShVqhRt2rQBrO6CtWrVyu36pAhpXSWC5ztZk6K8/ucGlu7SBBciIiIiUnjkOFwNHDiQRYsWMWLECObPn4/NZh2iQoUKGnMl1+zhVhW4qXZJ0hwmA39awYGTZ1xdkoiIiIhItnhczZMaNGhAgwYNME0T0zQxDIOuXbvmdm1SBBmGwfs9arPjSAKbDsbx8OgV/DqgKT6edleXJiIiIiJyWVe1ztWPP/5IrVq18PX1xdfXl9q1azN69Ojcrk2KKD8vD77pXZ9QP0/W7T/Fi7+v0wQXIiIiIlLg5ThcffzxxzzyyCN06dKFX375hfHjx9OpUycGDBjAJ598khc1ShFUNsyPz3tdj91mMHHlfkYu2O3qkkRERERELivH3QI/++wzvvzyS/r06ePcdsstt1CzZk1ee+01nnrqqVwtUIqu5pXCebFLdd78eyNvT9lEtRKBNKsU7uqyRERERESylOOWq4MHD9KsWbOLtjdr1oyDBw/mSlEiGe5vXo7u9UqT7jB59OeV7D2e6OqSRERERESylONwValSJX755ZeLto8fP57KlSvnSlEiGQzD4J3utahVOpgTiak8NHoFZ1LSXV2WiIiIiMhFctwt8PXXX+fOO+9k7ty5NG/eHMMwmD9/PjNmzMgydMk1Mk04c8LVVbiUj6edr3vXp9tn89l0MI7nJ6zl07vqYhiGq0sTEREREXHKccvV7bffzpIlSwgPD2fSpElMnDiR8PBwli5dym233ZYXNRZtW6bg8cX1VDw0BdJTXF2Ny5QK8WX4PdfjYTP4a80Bvpm709UliYiIiIhkclVTsdevX58xY8awYsUKVq5cyZgxYyhVqhRvvPFGbtcna3/BSI7nugPj8Pi6OWyebLVmFUGNKxTj1W41AHjv383M2XrExRWJiIiIiJxzVeEqK7Gxsbz++uu5dTjJ0GMkaTd9RpJHMMaJXTCuF/x4Cxza4OrKXOLeJtHc2aAsDhMe/3klu48muLokEREREREgF8OV5BGbDbPO3cyo8T7pzQaB3Rt2zYGvWsDfT0PCUVdXmK8Mw+CNW2tSLyqEuKQ0Hhq9nITkNFeXJSIiIiKicFVYpNl9cbR9CR5bCjVuAdMBy7+HT6+HRV9AWtEZj+XtYeere+sTEejN1kOneeaXNZhFtKukiIiIiBQcLg9Xw4cPp3z58vj4+FC/fn3mzZt3yX1nz56NYRgXXTZv3pxpv2HDhlG1alV8fX0pW7YsTz31FElJSXn9VvJHaDno+SP0nQwlakHyKfjvRfiyKWz9r8iMx4oM8uGre+vjaTf4d0MsX8za7uqSRERERKSIy/ZU7E8//fRlHz9yJOeTC4wfP55BgwYxfPhwmjdvztdff03nzp3ZuHEjUVFRl3zeli1bCAoKct6PiIhw3v7pp58YPHgwI0aMoFmzZmzdupW+ffsC8Mknn+S4xgKrXAt4aA6s/glmvAHHtsPPPaHiDXDju1C8mqsrzHP1o0N585brGDxxHR9N20p8chqPtq1EkI+nq0sTERERkSIo2+Fq1apVV9ynVatWOXrxjz/+mP79+/PAAw8AVovTf//9x5dffsm77757yecVL16ckJCQLB9btGgRzZs3p1evXgCUK1eOu+++m6VLl+aotkLBZofr+0CNW2Heh7D4S9gxE75sBg37Q5sh4Bfm6irz1F2NotgcG8+ohbv5es5Ofl2+jyduqMQ9TaLxtOdSw2xKAmz6C8q3hqCSuXNMEREREXE72Q5Xs2bNytUXTklJYcWKFQwePDjT9o4dO7Jw4cLLPrdevXokJSVRo0YNXnrpJdq2bet8rEWLFowZM4alS5fSqFEjdu7cyZQpU7jvvvsuebzk5GSSk5Od9+Pi4gBITU0lNTX1at5ersqo4ZK12H2hzctQ517sM17DtmUyLP0Gc+0vOFq9gOP6vmB339acFztVpkn5EN7/bxs7jybw2l8bGbVwN891rEyH6sWvabFhI2Yh9r+fxDixCzOyFmn9Z0IeLF58xXMshZ7OcdGQemI/nmkJOs9uTL/LRYPOs/vLyTnOyefAMF00E8CBAwcoXbo0CxYsoFmzZs7t77zzDj/88ANbtmy56Dlbtmxh7ty51K9fn+TkZEaPHs1XX33F7NmzM7WaffbZZzzzzDOYpklaWhqPPPIIw4cPv2Qtr732WpbTyP/888/4+fld4zvNf+HxG7lu308EJ+0FIN6nFOtL9+JwUG0XV5a30k1YdMjgn302TqdaAahCoMkt0emUC8zZsezpSdQ48AsVjk7PtH1xhac4FFwvt0oWETdS9tg86saMINkziNnV3iLFI4f/8IiISIGUmJhIr169OHXqVKahSVlxebhauHAhTZs2dW5/++23GT169EWTVFxKt27dMAyDP//8E7Amvbjrrrt46623aNy4Mdu3b+fJJ5/kwQcf5OWXX87yGFm1XJUtW5ajR49e8QeYH1JTU5k2bRodOnTA0zObLVCOdGyrR2Ob8y5G4jFrU8X2pHd4E4pVzsNqXe90chrfztvNiIW7SUp1ANC1Vgme6VCJsqFXDsvGnvlWa9XJPQA46vbGtHtiXzECR8l6pPebmuutV1d1jqVQ0Tl2Y6aJbe572Od/6NyUVqM75m3fuLAoySv6XS4adJ7dX07OcVxcHOHh4dkKV9nuFpjbwsPDsdvtxMbGZtp++PBhIiMjs32cJk2aMGbMGOf9l19+md69ezvHcdWqVYuEhAQeeughhg4dis128Tgcb29vvL29L9ru6elZoH6hclaPJzR+EGrfAXM/gCVfY9sxHduu2dDoIWj9PPiG5mW5LhPq6cnznavTu1k5Ppq6lQkr9zF5XSzTNh7mvmbRPNa2MsF+Wfwck0/D9Ndg2bfW/aAycPOn2Cq1g9NHYM1YbAdXYYuZC5Xa50ntBe0zJ7lP59jNpCXDX4/D2vEAOGrdibHuFzw2ToQ6PaFqZxcXKHlFv8tFg86z+8vOOc7JZ8BlU7F7eXlRv359pk2blmn7tGnTMnUTvJJVq1ZRsuS5SQYSExMvClB2ux3TNIvmWki+IXDj2/DoEqjSGRxpsHi4tT7W0m8h3X0X4C0Z7MuHd9Th78db0LxSMVLSHXw7bxetPpjF9/N3kZLmOLfzrrnWdPYZwap+Xxi4CCq1s+4HRECDftbtOR8UmSnvReQyEo/D6NusYGXYodunpN/8BduLd7Ee/2sQnDnh0hJFRCR/uXSdq6effprvvvuOESNGsGnTJp566iliYmIYMGAAAEOGDKFPnz7O/YcNG8akSZPYtm0bGzZsYMiQIUyYMIHHHnvMuU+3bt348ssvGTduHLt27WLatGm8/PLL3Hzzzdjt9nx/jwVGsYrQaxz0/h0iqsOZ4zDlWfi6JezI3clKCpqapYIZ078xI/s1pEpkAKfOpPLm3xtp//Ec/l25HfPvp+GHbnAyBoLLQu9J0O3/wOeCZt9mT4DdG/Yuht2XXo9NRIqA4zvh+46wZwF4B8G9v0F9a+KkzSVvwwyrCKdj4b+XXFyoiIjkp2yHq/fff58zZ84478+dOzfTOKX4+HgGDhyYoxe/8847GTZsGG+88QZ169Zl7ty5TJkyhejoaAAOHjxITEyMc/+UlBSeffZZateuTcuWLZk/fz6TJ0+me/fuzn1eeuklnnnmGV566SVq1KhB//79ufHGG/n6669zVJvbqngDDJgPXT4E3zA4vBFG3wq/9oWkU66uLs8YhkHbqsWZ8kRL/te9FhGB3pQ+uYyakzphLP/e2qnB/VZrVcW2WR8kqCRc39u6Pef9/ClcRAqevUvhu/ZwbJvVffj+f61/W89y2LxI7/YZYMDqMbBt+qWPJSIibiXbE1rY7XYOHjxI8eLFAQgKCmL16tVUqFABgEOHDlGqVCnS09Pzrtp8EhcXR3BwcLYGreWH1NRUpkyZQpcuXXK33++ZE1ZIWPqN1V0wtBzcMQpKuflseMnxpP77Ep6rRgGwzwzn+dSHCKnZnudvrEa5cP9LP/fkXvi0HjhSod+/EN300vvmQJ6dYykwdI7dxIZJ8PvDkJYEJevA3eMzrX+X6TzPeMXqhh1UGgYuvrg1XAol/S4XDTrP7i8n5zgn2SDbLVcXZrAiOX7J3fiGQqd34f6pEBIFJ3Zb3VyWfuu+Y4p2zobhzZzBKrFOP76p+ROLzeuYsi6WDp/M4fW/NnAiISXr54eUhbrWAtXMVeuVSJFhmrDg/+DX+6xgVaUz9J1y+YXFb3jJ+qNV3H6YlvVstSIi4l5cOuZKCogy9eHhuVDtJkhPscZi/Xqfe3UTTIqzBpf/eAucirHC5H1/4XfbMN7o2YQpT7akdZUIUtNNRi7YTasPZvHN3B0kpWbREtviKWvw+o6ZsG9Fvr8VEcln6Wnw91Mw7RXrfqOH4a6fwDvg8s/z8oebP7durxhl/XFHRETcmsKVWHxD4c4x0Ol/YPOEjX/A163gwGpXV3btdsyEL5vBipHW/YYPwiOLoPy5haerlQjih/sbMbp/I6qVCCQ+KY13pmym/cdz+GP1fhyO81rywspD7Tut22q9EnFvSXEw9s6z/34Y1r+RXd4HWzYnSCrfEhpaS4Pw5+PWkg8iIuK2crTO1XfffUdAgPWXurS0NEaNGkV4eDhgTWghhZxhQJNHoEwja4KLE7vh+w5w4zvWl4NcXjg3zyXFwdSXYOUP1v2QaLjlC+vLziW0rBzB5CfCmbhyHx9O3cK+E2d4ctxqRszfxZAu1WlSodjZHZ+BteNg679wcI019kJE3Mup/fBzTzi0Hjx8ocf3UK1rzo/T/jXYOtWakXTG69Dlg1wvVURECoZsh6uoqCi+/fZb5/0SJUowevToi/YRN1CmPgyYC5MehS2TrW6Cu+fDzZ+CT7Crq8ue7dPhzychbp91v9HD0O6VK3fjAew2gzsalOWm2qX4bt5OvpqzgzX7TnHXN4tpXSWC526synWlK0HN7rD+N2uR5jvHXPG4IlKIHFxrBav4g+Bf3FrKonT9qzuWdyDc/H/WmlhLv4Gat0F09tdzFBGRwiPb4Wr37t15WIYUOL6h1piCxV9aA7E3TrJaaO4YBaXquri4y0g6Bf8NhVVng39oOau1qlyLHB/K18vO4+0qc1ejKP5vxlbGLd3LnK1HmLP1CN3qlGLw9Y9Sev1vsOkvOLQRImvk7nsREdfYOtVqvU9NgIhq0OsXCI2+tmNWvAGu7wMrf4Q/HoUBC8DLL1fKFRGRgkNjruTSDAOaDoT7/4PgKDixy+omWFBnE9w2HYY3PResGg+ARxZeVbA6X0SgN2/dWosZz7TmlrqlAPhrzQFa/xDL+uA21k7zPrym1xCRAmLpt9YYq9QEKN/a+vfvWoNVho5vQWApawHiWW/nzjFFRKRAyXa4WrJkCf/880+mbT/++CPly5enePHiPPTQQ5kWFRY3UqYBPDwHqnY5N5vgb/2sMU0FQfwh6y/BP91uTXkcWt6aIrnze9ZsXbkkupg//3dXPSY/0YK2VSNIc5g8f7gjAOb6icTv3ZhrryUi+czhsFq9pzwLpgPq3gv3/Aa+Ibn3Gj7B0O3/rNuLvrAWIxYREbeS7XD12muvsXbtWuf9devW0b9/f9q3b8/gwYP566+/ePfdd/OkSCkA/MLgrp+tyS1sHrDhd2s2wYNrXFNPcjysHmuNYfi4GqwaAxjQZODZ1qrmefbSNUsFM7JfI8Y/1ATfqHpMS6+Pgcns71/gy9k7OJNS+BfSFilSUhLh1z6w6Oy06Te8BLd8Dh5euf9aVTpCnbsB0/qjUGpS7r+GiIi4TLbD1erVq2nXrp3z/rhx42jcuDHffvstTz/9NJ9++im//PJLnhQpBYRhQNNHz3YTLGt1E/yuPSz7Ln+6CaalwJZ/4Nd+8EFlmDTAmmbddECZhtBvirUocj6NY2hcoRi/DWhK0I0vAtDZnM/Y/+bQ+oNZ/LRkD6npjnypQ0SuwenD8MNN1thJuxfc/j20ei5vZ0e98R0IiISjW2HO//LudUREJN9lO1ydOHGCyMhI5/05c+bQqVMn5/2GDRuyd+/e3K1OCqYyDaxFhzO6CU5+Ju+6CTocsGeRtYDnR1Vg7F2wYSKknYFilaHtUHhiFTww3SWzbxmGQeMW7TErtsfDcPCc32QOxycz9Pf1dPh4Dn+tOZB5jSwRKTiObIHv2sH+FdYkPn3+gFo98v51/cKg68fW7QWfwv6Vef+aIiKSL7IdriIjI9m1axcAKSkprFy5kqZNmzofj4+Px9PTM/crlIIpo5tgx7fPdRP8prU1fXFuOLwJpr8O/1cHRnaC5SPgzAnrr71NHoWHZsNjy6D18xBWIXde8xoYrZ8H4CZzNh+0D6GYvxe7jyXy+NhVdPt8PnO2HsEsiJOAiBRVu+ZaE/ScjLHGafbP5z/QVL8JrrsdzHSre2BaSv69toiI5Jlsh6tOnToxePBg5s2bx5AhQ/Dz86Nly3OLsa5du5aKFSvmSZFSQBkGNHsM+v1rdRM8vtPqJrh8xNV1Ezy1Dxb8H3zZAoY3gfkfw6kY8AqEuvdA70nw9Cbo9A6UqlewFjWOagzlW2E40rgjaQJznm/L0x2qEODtwYYDcdw3Yil3f7uYlTEnXF2piKweC6O7W0s3lG1stXyHV8r/Ojp/AH7hcHijZhwVEXET2Q5Xb731Fna7ndatW/Ptt9/y7bff4uV1brDviBEj6NixY54UKQVc2YZWN8EqnSE92erCN6F/9roJnjkBK0bByK7wyXUw7RU4tA5snlC1q7Wu1nPb4NbhULEt2Ox5/W6uXiur9YpVowlIPswT7Soz9/m2PNCiPF4eNhbvPE734Qt58MflbD0U79paRYoi04RZ71rjNR2p1mK+ff4E/3DX1ONfDLp8YN2e91HutfyLiIjLZHsR4YiICObNm8epU6cICAjAbs/8JffXX38lICAg1wuUQsIvDO4ea822Nf01WD8BDqy2wlHJ2pn3TU2Crf/Cul9h21Rr3FaG6OZQ6w6ocYt1zMKkXAuIagYxC61xFJ3/R5i/Fy/dVIN+Lcrzf9O38tuKfUzbeIjpmw7RvV4ZnupQmTKhWkhUJM+dPmx1v9s21brf4im44RWwuXi5x5q3WeNIN/0FfwyEB2eBXV3sRUQKqxz/rxIcHHxRsAIICwvL1JIlRZBhQLPHod8/EFQGju84103QkQ47Z8OkR+HDyvDrfbD5bytYFa8J7V+DQeutGf8a9Ct8wQqs99/6Oev2ipHW+ltnlQ7x5f0edZj6VCs61SyBacKElfu44cM5vP7XBo6d1hpxInlm63/WAuPbpoLdG27+zPo3x9XBCqx/N7p+bE2oEbsOFgxzdUUiInINst1ydf/992drvxEjRlx1MeImyjaCAfPg9wGw7T+rm+D016zxDRmCylizctXuCZE1XVZqrqvQFko3gP3LYdFn0PGtTA9XKh7IV73rs3rvSd77ZzOLdh5j5ILd/LJsL9WCbCz+cyN+3p74eNrw8bDj7WnDx9Oe6ba3x9ltnvbM+3nYnY/bbAVoPJqIq6Segakvw7JvrfuR18Ht30Hx6q6t60IBxaHz+zDxQZjzPlS7qeDVKCIi2ZLtcDVq1Ciio6OpV6+eZj2TK/MLg7vHnesmmHQKfEKg5q1QqydENS0YfzXObYZhzWD4c09YNgKaP2WNq7hA3bIh/PxgY+ZvP8r7/25h3f5TrDhqY8XRfblShpeHDR8PG97nBbCIQG/ubRJNp5olFL7E/R1cCxMegKNbrPtNHoV2r4Cnj2vrupRad1jdqbf+C5MGQv9pYM/2f9EiIlJAZPtf7gEDBjBu3Dh27tzJ/fffz7333ktYWCHsuiX5x2aD5k9ApXYQdxDKtwKPItB1tHJHKFkHDq6BxV9YX+iyYBgGLStH0KJSOFM3HOTvucspV7EyqQ6DpNR0ktPSSUp1nL1tXVsXB0lp6SSnOjLtk3beelopaQ5S0hyQlObctu3waRbuOEaVyAAebVuJm2qXwq6QJe7G4bB+76a/bk1aEVACbvsSKt7g6souzzDgpk/gi0VwYKX1Hpo/6eqqREQkh7IdroYPH84nn3zCxIkTGTFiBEOGDKFr167079+fjh07YhSkabGlYIms6V5d/67EMKDVczD+XljyjTUOzTf0Mrsb3FA1gqQdJl1uqHTV68WlpTtISnOQnJpO0gVhLDktnUU7jjFqwW62HjrNk+NWM2z6Nga2qcit9UrjaXfDVkQpeuIOWN2Rd82x7lftao2vyqL1uEAKKmUtNfHHozDzbWuh9vDKrq5KRERyIEffqLy9vbn77ruZNm0aGzdupGbNmgwcOJDo6GhOnz6dVzWKFD5Vu0LxGpASD0u+zpeX9LDbCPD2oFiAN6VDfKkYEUDNUsHUjw6lWcVwnulYlfmDb+DpDlUI8fNk19EEnvttLTd8NJufl8RYLV0ihdXGP+HLZlaw8vSDbv8Hd/1UeIJVhrr3QMV21rIWfzxqTQYkIiKFxlX/udowDAzDwDRNHA59KRPJxGaDVs9atxcPz96aX/kg2NeTJ9pVZv4LN/BCp2oU8/di7/EzvPj7Olp/MIsfF+0mKbWIfJlLPA57l1kLys54E365z5p8JS3lys+VgiP5NPzxGPzS21o3r2Rda929+n0L1kLj2WUYVjD0CoS9S/LtjzMiIpI7cjRaNjk52dktcP78+dx00018/vnndOrUCZs7Tk4gci1q3Arh/4OjW63Zylo+4+qKnAK8PXikTUXuaxbNz0ti+GbuTg6eSuKVPzbw+cztPNSqAvc0jsbXqwAv2pwdKQlwfCcc2372suPc9ZnjWT8nurk1k6UUfPtXwIQHrWUfMKDFIGjzYuEf2xlSFjq+YYX9GW9A1U4QVsHVVYmISDZkO1wNHDiQcePGERUVRb9+/Rg3bhzFihWy7hYi+clmh5bPwu8PwaIvoPEA8PJ3dVWZ+Hl58EDLCtzbJJpfl+/ly9k7OHAqibcmb+LL2Tt4oGUFejeNJsC7AM9alp4KJ/acF6DOC1LxBy7/3KDSUKwiFKsEp/ZbSwesGadwVdA50mH+JzD7XXCkWUs73PYVlG/p6spyz/V9Yf1E2D0P/ngc7vvLPWdYFRFxM9n+xvTVV18RFRVF+fLlmTNnDnPmzMlyv4kTJ+ZacSKF3nW3W18AT+yyFlNu9rirK8qSj6ed3k3LcWfDKCau3Mfw2TuIOZ7Ie/9u5qs5O7i/eXn6Ni9HsO/VTbaRKxKPQ+zaC1qgtlvByrxMV0bfMCs8Fat0LkgVq2i1BJwfdo/tsMLVjhkQHwuBJfL+PUnOnYyBiQ9DzELrfs3brFn2LjNpTKFks1mTcXzZDPbMh+XfQ6MHXV2ViIhcQbbDVZ8+fTQjoEhO2T2s7oB/PgYLPoWGD4Cnr6uruiQvDxt3NYqiR/0y/LH6AF/M2s7Oowl8Mn0r383bSd/m5bi/eXlC/fO529XOOTD2bkhNyPpxT38oVuG8EHX2ElbBWnMtO4pVhLKNrXEua3+xlhGQgmXdb/D305B8CrwCoMuHUOeuwjm2KjvCykP71+Cf52Haq9YyD6HRrq5KREQuI0eLCIvIVahzF8x5H07FwIofoMkAV1d0RR52G7fXL8Ot9Uozed1BPp+5ja2HTvPZzO2MmL+Le5tG82DLCoQHeOd9MXsWwti7IDURgqOsaf2dLVBnL4ElcucLdp27rHC1ZqzVyuiuX9oLm6Q4mPIcrB1n3S/TELp/UzTGITV8EDb8DjGL4K8noffv+lyKiBRg6sAtktfsntZAe4AF/wdpyS4tJyfsNoOb65Ti3ydb8dW911OjZBAJKel8PWcnLd6byRt/beRQXFLeFbB3Kfx0hxWsKrWHx5dDr3Fw49vQoJ81xiaoZO592azZHezecHijtQi0uF7MYviquRWsDBu0Hgz9/i0awQqs7oG3fAEePrBzFqz80dUViYjIZShcieSHevdCYClrgoVVY1xdTY7ZbAadrivJ5Cda8P19DahTNoSkVAcjFuyi5XuzeHnSevafPJO7L7p/JYy5HVJOQ/nWcOcY8MjjljLfEKjWxbq9ZmzevpZcXnoazHoHRna2xlmFRFmhqu0Qq7ttUVKsItzwknV76kvW5CsiIlIgKVyJ5AcP73OtV/OHWTPcFUKGYdCueiSTBjbjx/sb0bBcKCnpDkYv3kObD2bxyJgVTNt46NoXJD64FkbfCslx1tTod4/Lv7FqdXpZ1+t+1ZpXrnJ8J4zsBHPeA9MBde6GAQsgqrGrK3OdJgOhdAPrd+LvQWCarq5IRESyoHAlkl+u7wP+xa2xV2vGubqaa2IYBq2qRPDLw00Z+2ATmlUsRmq6yT/rY3nwx+U0eXcGr/6xnjV7T2Lm9EvgoY3w4y2QdMqaYKLXePDyy5s3kpWKN0BAJCQeg+3T8+91xQoMq3+Gr1rCvmXgHQy3f29Ns+4T5OrqXMtmt7oH2r1g21RrDJaIiBQ4Clci+cXT99wMdPM+sro9FXKGYdC0YjF+frAJU55oyYMtyxMR6M3xhBR+WLSHW75YQPuP5/DFrO3Z6zZ4ZAv8eLO1wG+p6+GeX8E7MO/fyPnsHlDrDuv2mp/z97WLKtOE7TPgh24w6RGrK2h0c3hkgdYcO1/xalC9m3V711zX1iIiIllSuBLJTw3uB79i1rpX6ye4uppcVaNUEEO71mDR4BsY1a8hN9cphY+njR1HEvjgvy00/99M7v5mMb8s30t8UhbdIo/tgB9uhoQjUKI29J4IPsH5/0YA6p7tGrjlX2t9Lckb6WnW9Opft4Qx3a0Fc20e0O4Va9HckLKurrDgiW5uXe+e79o6REQkS0VsVLCIi3n5Q9NHYcYbMO9D66/yNrurq8pVHnYbbaoWp03V4sQnpfLP+lgmrtzH4p3HWbTzGIt2HuOVP9bTsUYJul9fmhaVwvE4tcdqtTgdC8VrQp8/XLsobGRNKFELYtdZIViLt+aulERrYpdFn1mTVQB4+sH191m/HwpVl1auhXW9b5k1JtAjn9ecExGRy1K4EslvDR+0FhQ+uhU2ToLrbnd1RXkm0MeTng3K0rNBWfadSOSP1QeYsHIfO48k8OeaA/y55gC1Ak4x2vY6ISmxEFHNClbZXfg3L9XpBbFDrDFACle5I/E4LP0Wln5tjWkDqyW38QBrge2CcN4LuvAq4BcOiUfhwEqIauLqikRE5DzqFiiS33yCoMkj1u25H4LjGmfWKyTKhPrxaNtKzHi6NX882pz7mkZTxTeOz1NeJSQllh2OkvRKHsI3K+Pydu2s7Kp1h9VF7cBKayyYXL2TMfDPC/BJTZj9jhWsQqKhy4cwaD20fl7BKrsMA6KbWbfVNVBEpMBRy5WIKzR+GBZ+bi1Wu2UyVOrk6oryjWEY1CkbQp2QJMw9H2IcP8wRj5L0PfMyew97snDKZv73z2ZaVI6ge73SdKwZiZ+XC/6pCoiASh1g6z/WmlftX8v/Ggq7QxushbPX/QZmurWtRC1oPghq3Fr01qvKLeVawKY/Yc9CV1ciIiIX0P9sIq7gG2oFrHkfwpz3oeKNrq4of50+Aj/cjHF8OwRHEdFvMn97leTvdQeYuHI/K/acYO7WI8zdegR/LzudrivJ7deXpnGFYthtRv7VWffus+FqPNzwstuNj8sTpgl7FljruW2fdm57+VZWqKp4g9X6Ilcvo+Vq7xJrUhCFVBGRAkP/Iou4SpOBsPhLiF2Lcf6XUHeXeNxax+roFggqDff9CSFRBAP3NI7mnsbR7D6awO+r9jNx1T72Hj/DhJX7mLByH3abQUSAN5HBPpQI8qZksC+RQT6UCPa2roN8KBHsk3stXVU6gU8IxB+AXXOsYCBZczhg899WS9X+5dY2wwbVb4bmT0Lp611bnzspXtOaSTPpFMSugdL1XV2RiIicpXAl4ir+xaBhf1j4Kbb5H0HxJ1xdUd47c8IKVoc3QEAJa7rtsPIX7VYu3J+nOlRhUPvKrNhzggkr9zN57QHiktKIjUsiNi6JNZd5mUAfD2fQyrg+P3xFBvlQzN8L25VawTy8rRkdl30Hq8cqXGUlLdlaFHvhp3Bsu7XN7m1NZ9/scShW0bX1uSObDaKaWa2quxcoXImIFCAKVyKu1OxxWPottgMriPDdAHR1dUV5J+kUjO4OsWvBP8JqsbrCF2/DMGhQLowG5cJ469brOHo6mdhTVrjKuD6Ucf/s7YSUdOKT0ohPOs22w6cveWxPu0HxwHMBLDLIh/BALwK9PQjw8cDfy7qOKHkTlfkOc9NfnIk/jm9AKIa6tVnnc/kIq/X19CFrm0+wNetf4wEQUNy19bm7cs2tcLVn4bnFyUVExOUUrkRcKaA41O8LS76kxoFxcKgrlKnr6qpyX3I8/HSHNfOeb5g13XpE1Rwdwm4ziDwbgupcZr/4pNRMAexQXMbtZA7FJXHwVBLHEpJJTTfZf/IM+0+eucIrm8zwKknFtIO8+r93meBog7+3B4HeHvifDWIB3tbF3/vc7QAfj0z7+XpAzGnYeDAOby9P7IaBzWZgNwzstnO3bTYu2ma3Gdic17g23MUdhCVfwvKRkBxnbQssZa1PVf8+8A50XW1FSca4q5iF4EjXeEARkQJC4UrE1Zo/ibnyR0LOxMB3raFSe2uMSrmW7jHwPyUBfr7TGnzvE2IFq8iaefZygT6eBPp4Ujny0l/yU9MdHI5PPhe+zl4fPZ1CQnIap8+7JCSn8VdSGwYxltvt8/g1vc3ZlrG0q6jOg4/WLb76N3eWzSBT4MoIah42A39vD0L8PAn29STEz4tQP09CfD0J9vMixNeTED/Ps497OffztGdjVQ7TtBa/XvQ5pKdY28KrWp/VWndoMdv8VqIOeAVYLYiHN1qzMIqIiMspXIm4WlBJ0vr+w6Ffn6P0qWUY26fD9ulQqp71xbX6zYX3r9KpZ2Ds3dbscd5B0Pt3KFnb1VXhabdROsSX0iG+2XvCqWqYn4yjiW0Tyx+txCmf0lYIS8ocwuLPXlvb0zmdnEpCcjrxyWmcTkrl2KnTeHn74DBN0h3WxWFi3TZNHGevTfPy5ThMcKSbwMU7HktIIeZ4zn4eAd4eZ8PY2YuvF8FnQ1nG/Uon53L9go8BMMs2wWgxCCrfaI3/kfxn94CyjWHHDGvclcKViEiBoHAlUhAUr8GK8o8S2bQGnsu+hlVj4MAq+LUvhJaDpo9B3XvAy8/VlWZfWjKMv9eaZc8rAO6dUHhnjAsujVGhNeycTfiOSYS3eSHHh0hNTWXKlCl06dIaT0/Py+5rZoQv08ThgPSz9x0XhDBr27nH0x0mp5NTOZl49nImlVOJKZw8k/X9uKRUTBNnQLxUF0kfkpnu/QoY8FXaTXwR04fqs4KosWUTNUoGUaNUEJWKB+DjWUj/CFBYlWtuhas9C6DJAFdXIyIiKFyJFCyh5aDrh9BmMCz9FpZ+Ayd2w5RnYfa70OhhaPQg+IW5utLLS0uBX+6zWuA8/eCeX6FsI1dXdW3q9IKds60FhVs/n6ddNg3DwMNu5Pk/0OkOk7gzqWfDVsrZ8HXu9snEVE6dSaXtgW8oc+ooh4xwvjR7EJ+cxtLdx1m6+1wTmd1mUCkigBqlgpyBq3rJIML81V0wz0Q3t673LLS6bbpDN2IRkUJO4UqkIPIPh7ZDrFnAVv0Eiz6DkzEw+x1YMAzq9bYmEAiNdnWlF0tPhd/6WTOZefjA3ePODb4vzKrfBJMD4MQuiFkM0U1dXdE1s9sMQv29CPX3Avyz3unYDhj+KwCRd3zM8qrd2HHkNBsPxLHxQBybYuPYcCCOk4mpbDkUz5ZD8fy+ar/z6SWDfahe8lzgqlEyiKgwvytPgy9XVup68PCFxKNwZAsUr+bqikREijyFK5GCzMsfGj8EDe6HjZOsBVpj18LSr621l2reZgWwkpebPy8fpafBxIesxWTtXnDXT1Chtauryh1e/lDjFlj9E6z52S3C1RWZptVqmp4CFdtB9ZvxNAyqlQiiWokgul+fsZtJbFySM3BtPGhd9hxL5OApa4bGmZsPOw/r72W3AtfZsFW9ZBBVSwTmebdCh8PEYZp4ZGcCj8LAwwvKNoRdc62ugQpXIiIup3AlUhjYPazFbK+73eqatuD/YOcsWP+bdanQ1pr8okIb13UNcqTDH4/Cholg84Seo62ZD91JnbutcLVhEnR+HzyzOSFGYbXpT9gx0wrKXT645GfLMAxKBvtSMtiXdtUjndvjk1LZEhtvha2zoWtzbDwJKeks33OC5XtOOPe1GVAxIoAKEf4YGKSdDUJpDpN0h4O0dGtMmXO7877DuT39vEuaI/PjGZOHAIQHeFE+3J9yxfwpF+5PhXDrulwxf3y9Ctm4sejm58JVw/6urkZEpMhTuBIpTAwDKra1LgfXwMLPYP1EK2jtnAUlalshq8atViDLD2kpEH8Q5r4Pa8eBYYc7RkLVTvnz+vkpujkER8GpGNg82Qq87ir5NPw7xLrd/MkrLviclUAfT+ci0BnS0h3sPJrApvMC14YDcRxPSGHb4csv/Jxbjp5O4ejpFJbtPnHRYyWDfazgFe5P+WL+zttRYX54eRTAFi+NuxIRKVAUrkQKq5J14Pbv4IaXYfFwWPmj1WVwQn+Y8To0fRzq3WN1Z7taKYlWcIrbD3EHLric3ZZwrrsXhs2qqXq3a39/BZHNBnXusoLkmrHuHa7mvm+d45AoaPF0rh3Ww26jSmQgVSIDuaVuacDqVng4PpmNB+LYeyIRm2Gt2WU/7+Jhs529NrDbrbW9MvbxsBvYbTY8zq79Zd0/73GbDZsNPGw2TNPkwMkkdh1LYNeRBHYfS2Dn0QR2H03g1JlUZzfGhTuOZarbZkCZUL9zLV3F/CgfEUD5Yv6UDvXF7qoxZGUaWC2L8Qfh+M6rCsEiIpJ7FK5ECrvQaOj8HrR+wRqHteQra/KLf547O8Pgg9DoIWuSjPMlx2cOSVndPnPxX/azZPe2voTfMNQaB+bOMsLVjpkQdxCCSrq6otx3ZAss+sK63fn9PF8CwDAMIoN8iAzyydPXyVAswJtaZYIv2n4iIcUZtHYdTcgUwBJT0ok5nkjM8UTmbj2S6Xledhtlw3wpH+5PdJgv8YcMQnYco2JkECWD8zh4efpC6foQs8hqvVK4EhFxKYUrEXfhF2ZNEd7scWtc0MLPrZnt5rxnjdGq3BFSTp8LT8lx2Tuupx8ElYagUuddl8q8zS+s6HRHKlYRyjaBvYth3S9Wlzl3Ypow+RlwpEGVTlC1s6sryjeh/l7U9/eifnRopu2maXIkPjlz8Dpqha7dxxJJSXOw40gCO44knH2GnV92rgDAy8NGVJgf5Yr5EV3M/7xrf0qF+OTO5BrRzc6GqwVwfe9rP56IiFw1hSsRd+PpCw0fgPr9YNNf1tTtB1ZZkxNcyDv4vLBUKusQ5RNcdIJTdtW5ywpXq8dCsyfc6+ezfgLsnmdNo9/5PVdXUyAYhkHxIB+KB/nQpEKxTI+lO0wOnjpjha2jCWw/HM+yTbtJ8ghg74kzpKQ52H74NNuzGEvmaTcoG+pH9HnBK2NijdKhvnhmN3hFN4d5H1nhSkREXErhSsRd2exQ81Zr+vDd82H/cgiIPBeeAkuCd4Crqyycat4G/7wARzbBwdVQqp6rK8odSXHw31DrdstnrEWt5bLsNoMyoX6UCfWjZeUIUlNTmcJOunRpgc3uwYGTZ5wtXHuOnr0+lsCe41aL186j1pgvOJLFcX2JLuZP+YzwFW5dlw29YHKNso2siWROxsDJvRBSNn9/CCIi4qRwJeLuDAPKt7Qukjt8Q6BaV2va+TXj3Cdczf4fnI6F0PJWi5xcE7vNoGyYH2XD/GhZOfNj6Q5rbbDzA9euownsOZbI7mMJJKc52HMskT3HEpl7wXHD/L2Y/EQLSgafXQrAOxBK1YX9K6xxVyF35sfbExGRLChciYhcjbq9rHC17lfo8Ka1oGthdmiDNRkKQJcPwTN/Jpcoquw2g9IhvpQO8aVZpcyPORzW7IlW2DoXvnYfS2THkdMcT0hh1uYj9Gocde5J0c3Ohqv5UEfhSkTEVRSuRESuRoW2VjfL04dg+zSrJauwMk2Y/CyY6dY0+pXdbPHnQsZmMygR7EOJYB+aVsw8xuujqVv4bOZ2lu85fkG4amGte7dnYT5XKyIi5yuAKyKKiBQCdg+o3dO6vfpn19ZyrdaOh5iF1syQN77r6mrkMjJmMlyx54JlEqKaAAYc2w7xsflfmIiIAApXIiJXr04v63rrf5B43LW1XK0zJ2HqS9btVs9pMoQCrl5UKIYBe44lciQ++dwDviFQ4jrrtmYNFBFxGYUrEZGrFVkDStQGRyqs+83V1VydWW9DwhEoVhmaPubqauQKgn09qVI8EMii9Sq6hXWtroEiIi6jcCUici3qnm29WjPWtXVcjYNrYNl31u2uHxb+STmKiOvPdg1cGXNhuGpmXe9Wy5WIiKsoXImIXItad4DNAw6shCNbXF1N9jkcMPkZMB1QsztUaOPqiiSbGpwNV8t3X9AVNSNcHdkECcfyuSoREQGFKxGRa+MfDpU7WrcL08QWq8fAvmXgFQA3vu3qaiQHGpSzwtX6/XEkpaafe8A/HCKqWbdj1DVQRMQVFK5ERK5Vnbut67XjwZF++X0LgsTjMO1V63abwRBUyrX1SI5EhfkRHuBFSrqD9ftPZX4wurl1rXFXIiIuoXAlInKtqtwIvqEQfxB2znZ1NVc24w04cxwiqkPjAa6uRnLIMAznlOzLL5rUImPc1fx8rkpEREDhSkTk2nl4w3U9rNsFfWKL/StgxSjrdtcPwe7p0nLk6lxyvauMlqvYdZB0QauWiIjkOYUrEZHckNE1cNPfkBTn2louxZFuTWKBCbXvhHItXF2RXKX60WEArNxzAtM0zz0QVBLCKgAmxCx2TXEiIkWYwpWISG4ofT2EV4G0M7DxD1dXk7UVo+DAKvAOgg5vuroauQbXlQ7Cy8PGsYQUdh9LzPygc9yVpmQXEclvClciIrnBMM61XhXEroEJR62xVgBth0JgpGvrkWvi7WGndulgIKsp2c+GK613JSKS7xSuRERyS+07AcNqMTix29XVZDb9VUg6CSVqQcMHXF2N5IL65S6xmHC5s+Hq4GpIPp2/RYmIFHEKVyIiuSW49LnFeNeMc2kpmcQsgVVjrNtdPgK7h2vrkVxRPypjMeELwlVIFARHgSMN9i11QWUiIkWXwpWISG6q28u6XjMWzp9owFXS02DKM9btuvdCVGPX1iO5JmPGwG2HT3MyMSXzg84p2dU1UEQkPylciYjkpmpdwSvA6hZYEGZrW/69NS23Twh0eN3V1UguKhbgTYVwfwBWxZzM/GA5LSYsIuIKClciIrnJyx9q3GrdXvOzS0vh9GGY+ZZ1u90r4B/u2nok113vXEz4EpNa7F8OqWfyuSoRkaJL4UpEJLfVPTtr4IZJrv1iO/VlSI6DUvWgfl/X1SF5psGlFhMOqwABJSA9xVo4WkRE8oXClYhIbotqZk0qkBwHmye7pobdC2DtOMCArh+Bze6aOiRPZYy7Wr33JKnpjnMPGIbGXYmIuIDClYhIbrPZzq15tdoFXQPTU2HKs9bt+n2hdP38r0HyRcWIAIJ9PUlKdbDpYFzmB8tpMWERkfymcCUikhfq3GVd75wFcQfz97WXfA2HN4JvmDXWStyWzWZwfVQIkMWU7BnjrvYuhbQLZhMUEZE8oXAlIpIXwipAVFMwHbB2fP69btxBmP2udbvD6+AXln+vLS7RoJx1ji8adxVRDfyKQdoZa0FhERHJcwpXIiJ5JaP1Kj/XvJo6FFJOQ5mG1rpW4vbqnzdjoHn+58wwrIAPsHu+CyoTESl6FK5ERPJKzdvAwweObIbYNXn/ejtnw/oJYNjOTmKhf+KLgjplQvCwGRyKS2b/yQtmpyzXwrrWelciIvlC//OKiOQVn2BrUWHAllddAx0OOLYDNv4Jk5+xtjV8AErWyZvXkwLH18tOzVJBQBZdAzNmDIxZDOlp+VyZiEjR4+HqAkRE3FqdXrB+ArYNEzCqNL22YyUetyaqOLTh3OXwRkhNPLePfwS0HXptryOFzvXRoazZd4oVe05wS93S5x6IvA68gyH5FBxaZ615JiIieUbhSkQkL1VsCwElME7HEhm3Brj5ys9JT4Vj288GqPXnglTc/qz39/CxJi+IrAlNHwXfkNx8B1IINIgOY+SC3RfPGGizQ3RT2Pqvtd6VwpWISJ5yebgaPnw4H3zwAQcPHqRmzZoMGzaMli1bZrnv7Nmzadu27UXbN23aRLVq1Zz3T548ydChQ5k4cSInTpygfPnyfPTRR3Tp0iXP3oeISJZsdqjdExZ+StTxLCYVOH04c4A6tB6ObIH0S0ydHRIFxWtaQSqyptUyEVYB7C7/51xcqEE5a1KLzbFxnE5OI8D7vM9DdDMrXO1ZAM0ec1GFIiJFg0v/Nx4/fjyDBg1i+PDhNG/enK+//prOnTuzceNGoqKiLvm8LVu2EBQU5LwfERHhvJ2SkkKHDh0oXrw4v/32G2XKlGHv3r0EBgbm6XsREbmkOnfDwk+JjFuNY+UPcGLnuUCVeDTr53gFnBegzoao4tWtcVwiF4gM8qF0iC/7T55hdcxJWlQOP/dg9HmTWjgcmuhERCQPuTRcffzxx/Tv358HHngAgGHDhvHff//x5Zdf8u67717yecWLFyckJCTLx0aMGMHx48dZuHAhnp6eAERHR+d67SIi2RZZA7NEbWyxa7H980zmxwwbhFW8IEjVhOAofQmWHGlQLpT9q8+wYs+JzOGqZG3w9Iekk9YYvRLXuaxGERF357JwlZKSwooVKxg8eHCm7R07dmThwstPGVuvXj2SkpKoUaMGL730Uqaugn/++SdNmzbl0Ucf5Y8//iAiIoJevXrxwgsvYLfbszxecnIyycnJzvtxcXEApKamkpqaerVvMddk1FAQapG8oXPs/tKbPUva5OfwjawEkddhFq8BxWtgRlQFT78snpBuXaRQceXvct0yQfyx+gDLdh8jNbVcpsfsZRth2zmL9J3zcBSrmu+1uRP9e1006Dy7v5yc45x8DlwWro4ePUp6ejqRkZGZtkdGRhIbG5vlc0qWLMk333xD/fr1SU5OZvTo0bRr147Zs2fTqlUrAHbu3MnMmTO55557mDJlCtu2bePRRx8lLS2NV155Jcvjvvvuu7z++usXbZ86dSp+fll86XGRadOmuboEyWM6x26uxgfWdRpwADhwEDjowoIkr7jidzkxAcCD5buO8vfkKdiMc49VOVOM6kDs0gksP1Iq32tzR/r3umjQeXZ/2TnHiYmJV9wng2FmWs49/xw4cIDSpUuzcOFCmjY9Nz3x22+/zejRo9m8eXO2jtOtWzcMw+DPP/8EoEqVKiQlJbFr1y5nS9XHH3/snDQjK1m1XJUtW5ajR49mGtvlKqmpqUybNo0OHTo4uzqKe9E5dn86x0WDK89zWrqDBu/MIiElnb8ebUq1EufGGht7F+Px402Y/hGkPbkRDOMyR5LL0e9y0aDz7P5yco7j4uIIDw/n1KlTV8wGLmu5Cg8Px263X9RKdfjw4Ytasy6nSZMmjBkzxnm/ZMmSeHp6ZuoCWL16dWJjY0lJScHLy+uiY3h7e+Pt7X3Rdk9PzwL1C1XQ6pHcp3Ps/nSOiwZXnGdPT6gXFcr87UdZvT+eWmXDzj0Y1Qg8fDASjuB5ajdEVMnX2tyRfpeLBp1n95edc5yTz4DLRkt7eXlRv379i5ripk2bRrNmzbJ9nFWrVlGyZEnn/ebNm7N9+3YcDodz29atWylZsmSWwUpERMRd1I+2pmRfueeC9a48vKFMQ+v2ngX5XJWISNHh0qmonn76ab777jtGjBjBpk2beOqpp4iJiWHAgAEADBkyhD59+jj3HzZsGJMmTWLbtm1s2LCBIUOGMGHCBB577Ny6HY888gjHjh3jySefZOvWrUyePJl33nmHRx99NN/fn4iISH7KCFfL9xy/+MHos3+4VLgSEckzLp2K/c477+TYsWO88cYbHDx4kOuuu44pU6Y4p04/ePAgMTExzv1TUlJ49tln2b9/P76+vtSsWZPJkydnWhy4bNmyTJ06laeeeoratWtTunRpnnzySV544YV8f38iIiL5qV5UCIYBe4+f4XBcEsWDfM49GN3cut69AExT465ERPKAS8MVwMCBAxk4cGCWj40aNSrT/eeff57nn3/+isds2rQpixcvzo3yRERECo1AH0+qRgayOTaeFXtO0LnWuW7zlGkINk+IPwAndkNYeZfVKSLirrRCpYiIiBtpUM7qGrjiwnFXXn5Q+nrr9p7LrycpIiJXR+FKRETEjTSItmYJXH5huIJzXQM17kpEJE8oXImIiLiRjEktNhw4RVJqeuYHneOu5udzVSIiRYPClYiIiBspE+pL8UBvUtNN1u47lfnBqMZg2ODkHji1zzUFioi4MYUrERERN2IYxqWnZPcOhJJ1rNsadyUikusUrkRERNzMJRcTBo27EhHJQwpXIiIibiYjXK3YcwLTNDM/eP56VyIikqsUrkRERNxMzVLBeHvYOJGYys6jCZkfjG4KGHBsG5w+7JL6RETclcKViIiIm/HysFGnbAgAK3Zf0DXQNxQia1q31TVQRCRXKVyJiIi4oUtOagHnjbvSpBYiIrlJ4UpERMQNNThv3NVFymnclYhIXlC4EhERcUPXR1nhaseRBE4kpGR+MKqZdX14AyRm0bIlIiJXReFKRETEDYX6e1Exwh+AlTEXtF4FREB4Vet2zKJ8rkxExH0pXImIiLipBtFhACzPcr2rs61XGnclIpJrFK5ERETclHO9qwtnDAQo18K63j0/HysSEXFvClciIiJuqn45K1yt2XeSlDRH5gczWq5i10LSqXyuTETEPSlciYiIuKkK4f6E+nmSnOZgw4ELAlRQKQgtD6YD9i51TYEiIm5G4UpERMRNGYZxrmtgluOuMqZkV9dAEZHcoHAlIiLixq7PznpXmtRCRCRXKFyJiIi4sfNnDDRNM/ODGeOuDqyElIR8rkxExP0oXImIiLix2mWC8bQbHIlPZt+JM5kfDImGoDLgSIN9y1xToIiIG1G4EhERcWM+nnZqlgoGYPme45kfNIxzrVe7F+RzZSIi7kfhSkRExM010LgrEZF8oXAlIiLi5jJmDFye1WLC0WcXE963DFKT8rEqycSRDgfXwpJvYNKjsHWqqysSkavg4eoCREREJG9lLCa85VA88UmpBPp4nnuwWEXwLw4Jh62JLTK6CRZGyadh/3Lrunh1ax0vWwH9O3JKAuxbDnuXQMwi2LsMUuLPPb76J+j8HjR+2HU1ikiOKVyJiIi4ueKBPkSF+RFzPJFVMSdpVSXi3IOGYXUN3PC7Ne6qMIWr+EOwdzHsWWQFlNh1YKafe9zT3wpZkTUh8rqz1zXAN9QFtcZCzOJzYerg2sy1AngHQZmG4OkLm/+Gf56HkzHQ4c2CGxJFJBOFKxERkSKgfnQoMccTWbHnROZwBdZiwht+hz0LgOdcUt8VmSYc224Fk5jF1vXxnRfvFxwFfqFwZAukJlgtWfuXZ94nqMy5oJURuopVArvnxce7Gg4HHN1qBb+Ys5cTuy7eL6gMRDU5dyleA2x2673O/wRmvA6LPodT++C2r8HTJ3fqE5E8o3AlIiJSBNSPDuX3VfuzntQi+uykFnuXQnpq7oWMa5GWArFrM4epxGMX7GRYwSiqCUQ1ta6Dy1gPOdKt8HVoPRzacPay3moJittnXbb9d+5Qdi+IqHpeC9fZ1q6A4leuNTUJDq4+V+veJXDmwp+zYR0vI0iVbQwhZbM+nmFAy6et9zJpIGycBKcPwV0/g19Y9n5+IuISClciIiJFQMakFqtiTpCW7sDDfl43s4hqVle5MyfgwGoo2zD/C0yKg31Lz7X07FsOaResy+XhA6XrnwtTZRqCb0jWx7PZIbyydal523mvcwoOb7ogdG2AlNNWt8LYdZmP4x+RuVthWBW8U09ibP0XDiyDmCXWWLX0lAtq9YUyDc6FqTINwSc4Zz+T2j0hsASMu9cKbt93hHt/g9ByOTuOO0k9A9unW5+RErWhWhfwDnR1VUVDWrLVippxiTtg/YGgfCsIKuXq6goMhSsREZEioEpkIIHeHsQnp7HlULxz7SvAGs8T3dwa57NnQf6Eq7gDmVulDm0A05F5H9/Qcy1SUU2hZB3w8L621/UJPhd4MjgccComcwvXoQ1wbAckHIGds60L4Al0Alh/wXH9i0NUY6vOsk2gZO3caQEs3wru/xd+ugOObYPvOkCv8VD6+ms/dmGRkgjbpsLGP2Drf1Z3zwwePlDlRrjudqjc0RqvJjlnmpB4HE7tPS9A7c18//ShSz+/WGXrs1q+FZRrCf7F8q/2AkbhSkREpAiw2wzqRoUwb9tRVuw5kTlcgTWRRUa4ajHo2l/Q4YDEo2f/wr3fClMZX9j2r7C6510otFzmMFWscv5M5GCzWa8dWg6qdT23PSURjmzK1MJlHlqPceYEZrHKGNFng1RUEwirYHXnywuRNeCBafBTTzi0DkZ1hf9v787jo6rvf4+/z2Qmkz0kJCQBwqJsEhYlEYkLrnBBSxGwVYsW98t1ueVSf9rF/kTrFa9W1P4sWHGrSos/qyJWKkYFRKwKFAQBEWQ3wRiW7JkkM+f+8c3CEHYmnGTm9Xw8zoMz58xMPpMv38dj3vl+z/f85C9Sn5Gt8/PagtpKE6TWz5M2FUh1Vc3nkrtJp11oQvmezSZ0rX9bik407TdggnT6xW1jemtbUV9r+uGBI0+lO4IfH/g7PhxPnJmumtxVSsySitdLRV+a4L9nk7TiefO8zIFSzwtN2OqWL8Ukte7na0MIVwAARIi87qlN4ern+T2CTzZed7XjM3O9kivq8G9k22YKYWNwCgpQ3zVc01TYcqrcgSyX+QLWGKayh0lJWSf9GUMqOs5MQ+yS23SovrZW7737tkb96Ep5PKfwy3tSZ+nGBdJ//1zaskj62zXSFY9LeTeeuhpam69C+ua9hkD1QfC00A7dpf5jpZwrpc5DTJC1bTON86u/S1+9aYL7mrlmi02RzvixNPAq83/7SP+fw42/zvyhZMM/pP3bTf8s3y3JPvpr4zuZqX7JXaXk7IatIUx16GZ+rwf/EaF6n7kJ+daPzVa8vnmK7b+elqwoM9LaOLKVfU5YjzASrgAAiBB5PY5wM+HMgWYpcF+ZGRGITQ0OTgeGptLvWl4PdUiWlJAhJXeRkrqYL2hJXczy6NlD2+e1MpalgCvamZ8dkyRNfF165xfmPlj/mGICxSW/a71Rs9ZWU9Y8QrX5A6n+gBtZp/Q0Yar/WCnrzJaf0bLM9MusQdJlD5gbYa/9u1n5srJY+vdfzJaQYa67G3CVuQ6uvf6ujqZ8t7TyJbOVF7U8H+U9ICgdFJySs03fPJEVKWNTzIhh46hvRXFz0Nr6sVkpc9dysy193NSRPbR5ZKvLkLAaZSRcAQAQIQZnd5DLkr7bX63dpTXKTD7gi5QryowgbXrfTDs7FnFpDcGpa8sAldTZTBtyOxREwlWURxr7J/NleMkj5stq6S7px0+3n991Tam0sWGEavOHkt/XfC719OZAlTno2IOQZZkv7NlDpVHTpW2fmBGt9fPNtUKfP2O2Dt2knPFmRCtjQPsPWrZt/hjyxWxpw3wpUG+Ox6dLZ10ndT6rOTzFp5+az5vQyfx+B15lHu/fIW1d2hC2lpjgt22p2RbJ3I+u+7kmaJ12oZQxsF3f141wBQBAhEjwunVGVpLWFZZp5fZ9umLQQdPwcsabcCVJMR2ag1JQcOrcEJ5O8K/cOHmWJV38a9Me7/xCWvOaGbW4+pXjX5HwVKneL238pwlU334UPGW0Y+/mQBWKwOOKMl/ST7tQuvxx8/O+ekP6+l3zRX/Zk2ZL62NGswZMkNJ6ndzPPNVqK6U1/y0tf84swNIo+xzp7Ful/j8++cVfQqVDN+msiWZrvF/d1iUNYWupVL1X2lxgNsmMhPU4v3lkK61PuwrBhCsAACJIbvcUrSss04rte1uGqzOvlXpdZq41io53pkAcuyHXm+vU/nuS+bL6wigzbbDxXl9Oq94nfb2gIVAtkgJ1zefS+jYHqk79W+/Lszta6jvKbLVV5t5mX70hffO+udHz4ofNljnIjLTkjD/8/cfagpLNJlCt/qvkKzXH3LGm9qG3mhU12zLLar5Fwtm3mIVvitc1TyHctsz8v9nwjtkk6bbFZgSunSBcAQAQQXK7p+jlf23Xvw91M2FJSkg/tQXh5PS6zCx0MeenZiGB50aYgJU5wJl6qveZhRTWzzPL1zdOU5Ok9DMOCFRnnPraouPMtVc548y1Xl+/a4LWlkXmhtW710gF/yllnyPXGeMU53ObkRanBfzmurTls80oXKOUniagnDXRjPa0R66GhW0yB0r5d0j+eqlwVfPI1g8bTfBtRwhXAABEkLweqZKkdYVlqq71KzY6glZRC1dZg6VbPpDmXCX98LUZwbr6FbMc+alQU2am/K1701xDdeAIVaec5kCV3vfU1HMsYpLMSO2Z10qVe6QNb5sVB7d9Iu38XFE7P9cISfaW35vfb9Zgs6hG1plm2f1TcU1Q5R5p1cvS8hfMsumSJMvcz2vordLpl7bra5MOKcpt7rOXfbY0/O6jr1zaBhGuAACIIJ2TY5SZFKPdZTX6ctd+DTstcm/2GVY6ZJubDc+9Ttr+iQlaP/4v6cyftc7Pq600y6Z/9aa5D9WBi1J06m+m1+VcaaZ/tXXxHaW8m8xWViSte0uBr96UXbhKUTWlzVPWGkUnmNGUzmc2B6+OvU0wCIVdK80o1VdvNv9eY1Oks643Nab2DM3PaQ/aWbCSCFcAAEQUy7KU2yNF764p0srt+whX4SQ2Rbr+TWne7WalvHn/y6wkOPw/QnNNU121CVLr3jTT1A686WzH3tKA8SZUdep38j/LKUlZUv7t8ufdqn/+Y75G5/WQ54d15ka5RV+aezfVVkg7PjVbI3esmdrWNMo12Ex9PNYlxutqzO/1i9lS4b+bj2edaUapBkwI63tDhRPCFQAAESa3mwlXK7btdboUhJrbK42fbUayPnlCWvR/zb2wrphxYvcSqq811/mse9MsTlFb3nwupYcJUwPGh8ey5gexXW4zQpXdfBNp+evNQhhFX0pFqxv+XSPVVUq7vjBbo6hoKSMneFphp/7Bq2zu2y6teEH698tm1bzG1+WMN6GqS27Y/V7DHeEKAIAI03gz4X/v2K9AwJbLxZe3sOJySZdNM6sGLvgP88W9rFD6yUvHduNmf51ZUOCrt6Sv3zH3pWqUnG2m++WMNyu4RdoX/yi3lNHfbGdea44F/NLeLVLh6uDA5Ss1izMUrmp+vcttFvboPNhcU/XNe5IaFs1IzpbybpTO+jkLy7RjhCsAACLMGVlJivVEqbS6Tt/+UKHeGcfwhRvtz9m3mPuR/f0mafMH0ouXm5UEEzNbPjfgN4s5rHvT3Hi3+oBRzYRME6gGTJC65IXfIgonyxXVvLz4oJ+YY7Yt7dvaPJ2w6EsTvqr3St+vNVuj0y6Sht4m9f4fobtuC46hBQEAiDCeKJcGZyfrsy17tXL7PsJVOOs7WrrhH2ap9t1rzFLt1/3drNwXCEg7PzfLka9/W6osbn5dXJpZ4W/AeKlbfrtcWMBRlmVWFUw9zSz9LpnAVbqreUqhHZAGX9s+Fv3AMSNcAQAQgfK6p+qzLXu1Yvs+XTO0m9PloDV1yZVuKZBevUra+630/Ahp4E/MNVTlhc3Pi02Rzhhjpvz1uIBRlFCzLHMtXIds6YwfOV0NWgm9BgCACJTbveG6q8PdTBjhJfU06eYCae61ZrRq+XPmuDdJ6vcjM0J12kUntugFgCaEKwAAItCQbiZcbSmp1J4KnzomeB2uCK0uvqP087elgv80N/7t/2NzI9oDV68DcFIIVwAARKDkOI96d0rQpuIKrdy+TyNzDrHIAcKPJ1a6/DGnqwDCFsu9AAAQoRqXZF+5g6mBABAKhCsAACJUbvdUSdLKbYQrAAgFwhUAABGqcVGLNd+Vylfvd7gaAGj/CFcAAESoHh3j1DE+WrX1AX31XZnT5QBAu0e4AgAgQlmWpSEsyQ4AIUO4AgAgguU1hKsV2/c6XAkAtH+EKwAAIljjdVcrt++TbdsOVwMA7RvhCgCACDagS7Kio1wqqajVjr1VTpcDAO0a4QoAgAgW44nSwK7JkqQVLMkOACeFcAUAQIRrmhrIzYQB4KQQrgAAiHBN4YqRKwA4KYQrAAAi3JBuJlx9U1yu0uo6h6sBgPaLcAUAQIRLT/SqR8c42ba0iqmBAHDCCFcAAEC53VMlmSXZAQAnhnAFAACC7ncFADgxhCsAAKC8HiZcrd65X/X+gMPVAED7RLgCAADqlZ6gpBi3qmr9+np3udPlAEC7RLgCAAByuSwNaZga+PeVu+QP2A5XBADtD+EKAABIkkb2z5QkvfTpNl31zKf65ntGsADgeBCuAACAJOmas7P10JUDlOB1a9WO/brij0v1RME38tX7nS4NANoFwhUAAJBkpgZeN6y7Pph6oS47I0N1fltPfbhJV/zxE63cvtfp8gCgzSNcAQCAIJnJMZr981z96WdDlJYQrc3FFbrqmX/pP9/+ShW+eqfLA4A2i3AFAABasCxLVwzK0gdTL9RP87rKtqWX/7VdI2Ys0Udff+90eQDQJhGuAADAYXWIi9ajVw3WnFvOUbfUOBWV1uiml1borr+tUkmFz+nyAKBNIVwBAICjOq9XmhZOGa7/Ofw0uSzpnS8LddmMJXpj5S7ZNsu2A4BEuAIAAMcoNjpKv778DL19x/k6IytJ+6vq9MvXv9TPX/hCO/dWOV0eADiOcAUAAI7LwK7Jmn/nebpnVF9Fu11auqlEI5/4WM8t3cLNhwFENMIVAAA4bp4ol26/qJcWThmuc3qmqrrOr4fe3aDxM5dpQ1GZ0+UBgCMIVwAA4IT1TIvX324dpkfGD1RijFtf7irVmP/6RH9YuFE1ddx8GEBkIVwBAICT4nJZumZoN30w9UKNyslUfcDW04s26/KnlurzLXucLg8AThnCFQAACImMpBg9c32unrluiNITvdpSUqmrn/1Mv31rrcpq6pwuDwBaHeEKAACE1KgB5ubD1w7NliTN+XyHRsxYovfX7Xa4MgBoXYQrAAAQcsmxHk0fP0h/vfUc9egYp+/LfLrtlZW6fc5KffVdqapq650uEQBCzu10AQAAIHyde3qa3psyXE99uEnPfrxFC9bu1oK1ZgQrKzlGPdPi1SMtXqelxTftZ6fEKdrN338BtD+EKwAA0KpiPFG6d1Q//WhQlh7559das6tUpdV1KiqtUVFpjT79NnjRiyiXpeyU2IOCV4J6pMWpc3KsXC7LoU8CAEdGuAIAAKdETudkvXLzOZKkfZW12lJSqa0lldrW8G/jVl3n17Y9Vdq2p0ra+EPQe3jdLvXoGB8cvNLN447x0bIsghcA5xCuAADAKZcSH63c+Gjldk8JOm7btr4v8x0Qtiq0taRKW0sqtGNvlXz1AW38vlwbvy9v8Z6JXrd6pptphemJXqUlRCstwau0BK953HDM6446VR8TQIRxPFzNnDlTjz32mIqKipSTk6Mnn3xSF1xwwSGfu3jxYl188cUtjm/YsEH9+vVrcXzu3Lm69tprNXbsWM2bNy/UpQMAgBCzLEuZyTHKTI5R/ukdg87V+wMq3F+jLSUVTSNejaNf3+2vVrmvXmt2lWrNrtIj/ozEGLfSE0zYSk84IIQ1Pj4gmMV4CGIAjp2j4eq1117TlClTNHPmTJ133nn685//rNGjR2v9+vXq1q3bYV+3ceNGJSUlNT1OT09v8Zzt27fr7rvvPmxQAwAA7Ys7yqVuHePUrWOcLuobfK6mzq+de6u0paRShfurVVLhU0l5rX6o8DXs+/RDhU91flvlNfUqr6nXlpLKo/7MpiCW4FVaYrRS4zzaW2hpz2c71DExRkmxHiUftHmiWIwDiFSOhqsZM2bo5ptv1i233CJJevLJJ7Vw4ULNmjVL06dPP+zrOnXqpA4dOhz2vN/v18SJE/XAAw9o6dKl2r9/f4grBwAAbUmMJ0q9MxLVOyPxsM+xbVtl1fVNgeuH8obgdYggVlJRq1p/4DBBLEoLdn592J8TFx3VFLQOFb6atjiCGRBuHAtXtbW1WrlypX71q18FHR85cqQ+/fTTI772rLPOUk1Njfr376/77ruvxVTBBx98UOnp6br55pu1dOnSo9bi8/nk8/maHpeVlUmS6urqVFfn/B3lG2toC7WgddDG4Y82jgy0c9sX55G6p3jVPcV7xOfZtq2ymnqVVNSqpMKnPRUmfBWX1WjtN1uV2DFD5T6/SqvrVFZdp9KGECZJVbV+VdX6VVRac/z1RUcpKcatuOgoed1Rio2OUozbJa/HpVhPlLwe89jsuxTT8Byv26WYhscxDa+J8UQ1H/MEP2bFxSOjL4e/42nj4/l/4Fi4Kikpkd/vV0ZGRtDxjIwM7d596Du4Z2Vl6dlnn1Vubq58Pp9eeeUVXXrppVq8eLGGDx8uSVq2bJmef/55rV69+phrmT59uh544IEWx99//33FxcUd+4dqZQUFBU6XgFZGG4c/2jgy0M7hKb1hyzldkopanA/YUnW9VFUvVfml6nrL7NdL1X6pqt5qPl8vVfvN+eqGfak5mLU2j8tWbJQU07i5mx/HuqWYKPuAfZlz7uDXeFxSuC/OSF8Of8fSxlVVVcf8fo4vaHHwkqm2bR92GdW+ffuqb9/mSdb5+fnauXOn/vCHP2j48OEqLy/Xddddp9mzZystLe2Ya/j1r3+tqVOnNj0uKytTdna2Ro4cGXRtl1Pq6upUUFCgESNGyOPxOF0OWgFtHP5o48hAO4e/1mpjf8BcC1ZaXafS6jpV1/nlqw+ops6v6rqAfHV+1dQHVF3rl6/er5o6c66m4TkHPvbV+VXdcMxXH2jY96vObzd/joCluoBU1vQH+eNPSZ4oSwletxJjzJbgdSux4XFctFuWdcC7WlbT/oHHrYOO64DjjVU1HrdkNe27LEuJMW4lx3qU0jC9skNc8/7JTq+kL4e/42njxlltx8KxcJWWlqaoqKgWo1TFxcUtRrOOZNiwYXr11VclSd9++622bdumMWPGNJ0PBAKSJLfbrY0bN+r0009v8R5er1deb8vpAR6Pp011qLZWD0KPNg5/tHFkoJ3DX6jb2CMpxhut9OSQvWUL/oDdEMTM6FhZTV3TNWUVvub9oOMH7Jc37FfU1su2pTq/rX1VddpX1famziV43eoQ1xi4ohtCWLQJXw3/mvPRSomLVoeG6+OiDpouSV8Of8fSxsfzf8CxcBUdHa3c3FwVFBRo3LhxTccLCgo0duzYY36fVatWKSsrS5LUr18/rV27Nuj8fffdp/Lycj311FPKzs4OTfEAAADtTJTLUrzXrXivWx2P/vTDCgRsVdbWB4cuX3AAq6r1S7YZKbNldm01PLalxjG0A4/LbnzukZ9n21LAtlVWXaf91Sbc7a+q1f6qOpXV1Mm2pQpfvSp89dq1r/qYP5dlSUkxzaNfFaVReqXwC9myFLBtU4NtK9BQSyDQXG/j+abnyew3v05BzwnYkttlRt8SYtxKjPEoMcatpMZ9b/Bxc65x36MEr1vRbhY/aYscnRY4depUXX/99crLy1N+fr6effZZ7dixQ5MnT5Zkput99913evnllyWZ1QR79OihnJwc1dbW6tVXX9Ubb7yhN954Q5IUExOjAQMGBP2MxlUFDz4OAACA4+dyWQ1f+tveiI4/YELXvqpa7auqU2l1rfZVmhC2v6pW+xpC2P6qOu1vPFdVq8pav2xbTdMyDUsq39+q9e4+9tlmLXjdLiXGeBoCWXPoatqPccvrdsntsuSJcskTZf51H7BvHlvyuMwxd5RL0Y3Hgl5jNRxvOOZysSjKYTgarq6++mrt2bNHDz74oIqKijRgwAAtWLBA3bt3lyQVFRVpx44dTc+vra3V3Xffre+++06xsbHKycnRu+++q8svv9ypjwAAAIA2IsplKSU+Winx0cf1utr6gPZX16q0YZpjSVm1vli5UrlDhsjjdstlmevAXJa53ksN/7oscy1Y43nrwONNr2l+XuN5y5Lq/bbKfS2nXZbX1KnCV6+yQxxvGhWU5KsPyNdw+wAnuF2Wzu2Vpl+O6KPB2R0cqaEtcnxBi9tvv1233377Ic+99NJLQY/vuece3XPPPcf1/ge/BwAAAHCgaLdLnRJj1CkxRlLD7Xi22RqVk9Hmrrmq9wdU6TvwmrmGf4OCmrmOrq7eVl0goDq/rXp/QHV+s1/nD6jeb6vWH1B9IND0vPqGc83PMfu1/kDLOgK2Pv7mB338zQ8a2T9DvxzZV30zD3+fuUjheLgCAAAAcGzcUS4lx7mUHHfqQp9t2/IHbNUHGgKZ31ZJhU9/XrJFb63apffXf6+CDd9r7ODOmnJZH/VIiz9ltbU1XAkHAAAA4LAsy1yPFeOJUlKMR6nx0eqTkajHfzpY7/+f4bp8YKZsW5q3ulCXzliiX7+5VkWlx76YSDghXAEAAAA4Ib06JWrmxFz9467zdVHfdPkDtv72xQ5d+NhiPfjOeseuCXMK4QoAAADASRnQJVkv3ThUr0/O19CeqaqtD+iFZVs1/NFF+sPCjQeswhjeCFcAAAAAQuLsHql67bZhevmmoRrYJVlVtX49vWizLvh/H+lPizarqrbe6RJbFeEKAAAAQMhYlqXhfdI1/87z9Mx1uerdKUFlNfV6bOFGDX90kV5ctlW+er/TZbYKwhUAAACAkLMsS6MGZOq9KcP1xNWD1S01TiUVtXrgnfW6+LHFem35DtUfYpn39oxwBQAAAKDVRLksjTurqz785YV6eNxAZSbFqLC0Rve+sVYjnvhY878sVCBgO11mSBCuAAAAALQ6T5RLPzunmxb/x0W674ozlBofra0llfrff1uly/+4VAXrv5dtt++QRbgCAAAAcMrEeKJ0ywWn6eN7LtYvR/RRotetr3eX69aXV2jczE+1bHOJ0yWeMMIVAAAAgFMuwevWXZf21tJ7L9b/uuh0xXqitHrnfk187nNd++xnWrl9n9MlHjfCFQAAAADHdIiL1r2j+mnJPRfphnN7KDrKpX9t2aMJsz7Vv77d43R5x8XtdAEAAAAA0CkxRtN+nKNbLuipP364SRuKynVOz1SnyzouhCsAAAAAbUbXlDg9etVg1dYH5HJZTpdzXJgWCAAAAKDNiXa3v6jS/ioGAAAAgDaIcAUAAAAAIUC4AgAAAIAQIFwBAAAAQAgQrgAAAAAgBAhXAAAAABAChCsAAAAACAHCFQAAAACEAOEKAAAAAEKAcAUAAAAAIUC4AgAAAIAQIFwBAAAAQAgQrgAAAAAgBAhXAAAAABAChCsAAAAACAHCFQAAAACEAOEKAAAAAELA7XQBbZFt25KksrIyhysx6urqVFVVpbKyMnk8HqfLQSugjcMfbRwZaOfwRxtHBto5/B1PGzdmgsaMcCSEq0MoLy+XJGVnZztcCQAAAIC2oLy8XMnJyUd8jmUfSwSLMIFAQIWFhUpMTJRlWU6Xo7KyMmVnZ2vnzp1KSkpyuhy0Ato4/NHGkYF2Dn+0cWSgncPf8bSxbdsqLy9X586d5XId+aoqRq4OweVyqWvXrk6X0UJSUhIdPMzRxuGPNo4MtHP4o40jA+0c/o61jY82YtWIBS0AAAAAIAQIVwAAAAAQAoSrdsDr9er++++X1+t1uhS0Eto4/NHGkYF2Dn+0cWSgncNfa7UxC1oAAAAAQAgwcgUAAAAAIUC4AgAAAIAQIFwBAAAAQAgQrgAAAAAgBAhXbdzMmTPVs2dPxcTEKDc3V0uXLnW6JITQtGnTZFlW0JaZmel0WTgJH3/8scaMGaPOnTvLsizNmzcv6Lxt25o2bZo6d+6s2NhYXXTRRVq3bp0zxeKEHa2db7jhhhZ9e9iwYc4UixMyffp0nX322UpMTFSnTp105ZVXauPGjUHPoT+3b8fSxvTl9m/WrFkaNGhQ082C8/Pz9c9//rPpfKj7MeGqDXvttdc0ZcoU/fa3v9WqVat0wQUXaPTo0dqxY4fTpSGEcnJyVFRU1LStXbvW6ZJwEiorKzV48GA9/fTThzz/6KOPasaMGXr66ae1fPlyZWZmasSIESovLz/FleJkHK2dJWnUqFFBfXvBggWnsEKcrCVLluiOO+7QZ599poKCAtXX12vkyJGqrKxseg79uX07ljaW6MvtXdeuXfXII49oxYoVWrFihS655BKNHTu2KUCFvB/baLOGDh1qT548OehYv3797F/96lcOVYRQu//+++3Bgwc7XQZaiST7rbfeanocCATszMxM+5FHHmk6VlNTYycnJ9vPPPOMAxUiFA5uZ9u27UmTJtljx451pB60juLiYluSvWTJEtu26c/h6OA2tm36crhKSUmxn3vuuVbpx4xctVG1tbVauXKlRo4cGXR85MiR+vTTTx2qCq1h06ZN6ty5s3r27KlrrrlGW7ZscboktJKtW7dq9+7dQf3a6/XqwgsvpF+HocWLF6tTp07q06ePbr31VhUXFztdEk5CaWmpJCk1NVUS/TkcHdzGjejL4cPv92vu3LmqrKxUfn5+q/RjwlUbVVJSIr/fr4yMjKDjGRkZ2r17t0NVIdTOOeccvfzyy1q4cKFmz56t3bt369xzz9WePXucLg2toLHv0q/D3+jRozVnzhx99NFHevzxx7V8+XJdcskl8vl8TpeGE2DbtqZOnarzzz9fAwYMkER/DjeHamOJvhwu1q5dq4SEBHm9Xk2ePFlvvfWW+vfv3yr92H3S1aJVWZYV9Ni27RbH0H6NHj26aX/gwIHKz8/X6aefrr/85S+aOnWqg5WhNdGvw9/VV1/dtD9gwADl5eWpe/fuevfddzV+/HgHK8OJuPPOO7VmzRp98sknLc7Rn8PD4dqYvhwe+vbtq9WrV2v//v164403NGnSJC1ZsqTpfCj7MSNXbVRaWpqioqJapObi4uIW6RrhIz4+XgMHDtSmTZucLgWtoHElSPp15MnKylL37t3p2+3QXXfdpfnz52vRokXq2rVr03H6c/g4XBsfCn25fYqOjlavXr2Ul5en6dOna/DgwXrqqadapR8Trtqo6Oho5ebmqqCgIOh4QUGBzj33XIeqQmvz+XzasGGDsrKynC4FraBnz57KzMwM6te1tbVasmQJ/TrM7dmzRzt37qRvtyO2bevOO+/Um2++qY8++kg9e/YMOk9/bv+O1saHQl8OD7Zty+fztUo/ZlpgGzZ16lRdf/31ysvLU35+vp599lnt2LFDkydPdro0hMjdd9+tMWPGqFu3biouLtZDDz2ksrIyTZo0yenScIIqKiq0efPmpsdbt27V6tWrlZqaqm7dumnKlCl6+OGH1bt3b/Xu3VsPP/yw4uLi9LOf/czBqnG8jtTOqampmjZtmiZMmKCsrCxt27ZNv/nNb5SWlqZx48Y5WDWOxx133KG//vWvevvtt5WYmNj0l+3k5GTFxsbKsiz6czt3tDauqKigL4eB3/zmNxo9erSys7NVXl6uuXPnavHixXrvvfdapx+f5EqGaGV/+tOf7O7du9vR0dH2kCFDgpYHRft39dVX21lZWbbH47E7d+5sjx8/3l63bp3TZeEkLFq0yJbUYps0aZJt22b55vvvv9/OzMy0vV6vPXz4cHvt2rXOFo3jdqR2rqqqskeOHGmnp6fbHo/H7tatmz1p0iR7x44dTpeN43Co9pVkv/jii03PoT+3b0drY/pyeLjpppuavkunp6fbl156qf3+++83nQ91P7Zs27ZPNAkCAAAAAAyuuQIAAACAECBcAQAAAEAIEK4AAAAAIAQIVwAAAAAQAoQrAAAAAAgBwhUAAAAAhADhCgAAAABCgHAFAAAAACFAuAIAIMQsy9K8efOcLgMAcIoRrgAAYeWGG26QZVkttlGjRjldGgAgzLmdLgAAgFAbNWqUXnzxxaBjXq/XoWoAAJGCkSsAQNjxer3KzMwM2lJSUiSZKXuzZs3S6NGjFRsbq549e+r1118Pev3atWt1ySWXKDY2Vh07dtRtt92mioqKoOe88MILysnJkdfrVVZWlu68886g8yUlJRo3bpzi4uLUu3dvzZ8/v3U/NADAcYQrAEDE+d3vfqcJEyboyy+/1HXXXadrr71WGzZskCRVVVVp1KhRSklJ0fLly/X666/rgw8+CApPs2bN0h133KHbbrtNa9eu1fz589WrV6+gn/HAAw/opz/9qdasWaPLL79cEydO1N69e0/p5wQAnFqWbdu200UAABAqN9xwg1599VXFxMQEHb/33nv1u9/9TpZlafLkyZo1a1bTuWHDhmnIkCGaOXOmZs+erXvvvVc7d+5UfHy8JGnBggUaM2aMCgsLlZGRoS5duujGG2/UQw89dMgaLMvSfffdp9///veSpMrKSiUmJmrBggVc+wUAYYxrrgAAYefiiy8OCk+SlJqa2rSfn58fdC4/P1+rV6+WJG3YsEGDBw9uClaSdN555ykQCGjjxo2yLEuFhYW69NJLj1jDoEGDmvbj4+OVmJio4uLiE/1IAIB2gHAFAAg78fHxLabpHY1lWZIk27ab9g/1nNjY2GN6P4/H0+K1gUDguGoCALQvXHMFAIg4n332WYvH/fr1kyT1799fq1evVmVlZdP5ZcuWyeVyqU+fPkpMTFSPHj304YcfntKaAQBtHyNXAICw4/P5tHv37qBjbrdbaWlpkqTXX39deXl5Ov/88zVnzhx98cUXev755yVJEydO1P33369JkyZp2rRp+uGHH3TXXXfp+uuvV0ZGhiRp2rRpmjx5sjp16qTRo0ervLxcy5Yt01133XVqPygAoE0hXAEAws57772nrKysoGN9+/bV119/Lcms5Dd37lzdfvvtyszM1Jw5c9S/f39JUlxcnBYuXKhf/OIXOvvssxUXF6cJEyZoxowZTe81adIk1dTU6IknntDdd9+ttLQ0XXXVVafuAwIA2iRWCwQARBTLsvTWW2/pyiuvdLoUAECY4ZorAAAAAAgBwhUAAAAAhADXXAEAIgqz4QEArYWRKwAAAAAIAcIVAAAAAIQA4QoAAAAAQoBwBQAAAAAhQLgCAAAAgBAgXAEAAABACBCuAAAAACAECFcAAAAAEAL/H5TtkGFqSWCBAAAAAElFTkSuQmCC"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Model Evaluation:\n",
      "MSE: 0.5683\n",
      "RMSE: 0.7539\n",
      "MAE: 0.5828\n",
      "R: 0.4004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.5297774 ,  0.33578378],\n",
       "       [ 0.4705608 , -0.430565  ],\n",
       "       [ 0.31108096,  0.05839671],\n",
       "       ...,\n",
       "       [ 0.2815234 ,  0.83397734],\n",
       "       [-0.01789251,  0.2801785 ],\n",
       "       [-0.71108925, -0.572792  ]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
